{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "67e3c25bcfa047308c5733e8489d9625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_dffd9ec1ab3c449fa55aaa4c0086ba61",
            "placeholder": "Paste/type the exact prompt you want the model to see (I will NOT modify it).",
            "rows": null,
            "style": "IPY_MODEL_434825dff58342c896f1dc97114cee12",
            "value": "Extract entities, their relations, and values. Use the format:\n[\n  {\"entity\": \"...\", \"relation\": \"...\", \"value\": \"...\"}\n]\n\nText: \"Albert Einstein was born in Ulm and developed the theory of relativity.\"\nOutput:\n[\n  {\"entity\": \"Albert Einstein\", \"relation\": \"born in\", \"value\": \"Ulm\"},\n  {\"entity\": \"Albert Einstein\", \"relation\": \"developed\", \"value\": \"theory of relativity\"}\n]\n\nText: \"Barack Obama was born in Honolulu and served as the 44th President of the United States.\"\nOutput:\n"
          }
        },
        "dffd9ec1ab3c449fa55aaa4c0086ba61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "120px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "434825dff58342c896f1dc97114cee12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b46e5dc7403d4f78a4e9e91d9848265e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e27f7423d17143348e097bb370a67cac",
              "IPY_MODEL_3a7a042edc6647c1be5a5af5453c8bd8",
              "IPY_MODEL_5a957ee9e51c425fbc45ce22485cb78c"
            ],
            "layout": "IPY_MODEL_5bb205f42cf64551ac23b477c87751d6"
          }
        },
        "e27f7423d17143348e097bb370a67cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "primary",
            "description": "Send → model",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_a1d6d273b95d4f68a4d177d979897cd3",
            "style": "IPY_MODEL_bed5e1d9c27a45e6b5744394e83da8ee",
            "tooltip": ""
          }
        },
        "3a7a042edc6647c1be5a5af5453c8bd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "warning",
            "description": "Clear history",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_f6813eee3cb449bca8b3e687df47bd52",
            "style": "IPY_MODEL_6d040ad0bc5c4ba292551c7bfae29768",
            "tooltip": ""
          }
        },
        "5a957ee9e51c425fbc45ce22485cb78c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Include history (send previous turns)",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_ed285957539b4bfdb19ea31118d56a7b",
            "style": "IPY_MODEL_c2ab7fe2dc4e459894ae75400c06b0b8",
            "value": false
          }
        },
        "5bb205f42cf64551ac23b477c87751d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1d6d273b95d4f68a4d177d979897cd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bed5e1d9c27a45e6b5744394e83da8ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "f6813eee3cb449bca8b3e687df47bd52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d040ad0bc5c4ba292551c7bfae29768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "ed285957539b4bfdb19ea31118d56a7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2ab7fe2dc4e459894ae75400c06b0b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6d2353173d5428dacafb04b9fcdab11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_520705944edc4188bbdbe1ad3e882fd0",
              "IPY_MODEL_35ac410ea2ca4e95bb6597c39bc47272"
            ],
            "layout": "IPY_MODEL_03623a7f848446da9e7ccbd46c537a02"
          }
        },
        "520705944edc4188bbdbe1ad3e882fd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "--temperature",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_4bc7fe727b4e444ca08c76b2c82a67a6",
            "placeholder": "leave empty for default",
            "style": "IPY_MODEL_517cfb13bc6349688da73a77eca192dc",
            "value": ""
          }
        },
        "35ac410ea2ca4e95bb6597c39bc47272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "--num-predict",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_26f1f4abf6274e96b8903327f61f2549",
            "placeholder": "leave empty for default",
            "style": "IPY_MODEL_64ddba703b76458d8305f1461bb9d20a",
            "value": ""
          }
        },
        "03623a7f848446da9e7ccbd46c537a02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bc7fe727b4e444ca08c76b2c82a67a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "517cfb13bc6349688da73a77eca192dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26f1f4abf6274e96b8903327f61f2549": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64ddba703b76458d8305f1461bb9d20a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "310a0c516ba94292916997978f71ad7e": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_23092c0378ef4812971884dc79426705",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Ready. Paste your prompt above and press 'Send → model'.\n",
                  "If you want the model to see previous turns, check 'Include history' (history is stored only after you send a prompt).\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "=== Sending EXACT prompt to model ===\n",
                  "Extract entities, their relations, and values. Use the format:\n",
                  "[\n",
                  "  {\"entity\": \"...\", \"relation\": \"...\", \"value\": \"...\"}\n",
                  "]\n",
                  "\n",
                  "Text: \"Albert Einstein was born in Ulm and developed the theory of relativity.\"\n",
                  "Output:\n",
                  "[\n",
                  "  {\"entity\": \"Albert Einstein\", \"relation\": \"born in\", \"value\": \"Ulm\"},\n",
                  "  {\"entity\": \"Albert Einstein\", \"relation\": \"developed\", \"value\": \"theory of relativity\"}\n",
                  "]\n",
                  "\n",
                  "Text: \"Barack Obama was born in Honolulu and served as the 44th President of the United States.\"\n",
                  "Output:\n",
                  "\n",
                  "=== Model response (raw) ===\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "[\n",
                  "  {\"entity\": \"Barack Obama\", \"relation\": \"born in\", \"value\": \"Honolulu\"},\n",
                  "  {\"entity\": \"Barack Obama\", \"relation\": \"served as\", \"value\": \"the 44th President of the United States\"}\n",
                  "]\n",
                  "\n",
                  "--- (end response) ---\n",
                  "\n"
                ]
              }
            ]
          }
        },
        "23092c0378ef4812971884dc79426705": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "1px solid lightgray",
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQAMFy9Sj490",
        "outputId": "da8abb3a-282c-460c-e71f-01916d6dd115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf4llm in /usr/local/lib/python3.12/dist-packages (0.0.27)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.12/dist-packages (0.11.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: pymupdf>=1.26.3 in /usr/local/lib/python3.12/dist-packages (from pymupdf4llm) (1.26.4)\n",
            "Requirement already satisfied: pdfminer.six==20250506 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (20250506)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (4.30.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.3)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n",
            ">>> Cleaning up old version at /usr/local/lib/ollama\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "######################################################################## 100.0%\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n",
            "✅ Ollama server started in the background.\n",
            "You can now run other cells!\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ],
      "source": [
        "!pip install pymupdf4llm pdfplumber pandas requests\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Start the ollama serve process in the background\n",
        "# We redirect its output to a log file to keep our notebook clean\n",
        "server_process = subprocess.Popen(\n",
        "    [\"ollama\", \"serve\"],\n",
        "    stdout=open(\"ollama_server.log\", \"w\"),\n",
        "    stderr=subprocess.STDOUT\n",
        ")\n",
        "\n",
        "print(\"✅ Ollama server started in the background.\")\n",
        "print(\"You can now run other cells!\")\n",
        "\n",
        "# Give the server a few seconds to start up before you run other commands\n",
        "time.sleep(5)\n",
        "! ollama pull llama3.2:3b"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "trystart"
      ],
      "metadata": {
        "id": "uZNvPOOz-a0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Enhanced Pharmaceutical Knowledge Graph Extractor for Google Colab - Phrase-Based JSON Processing\n",
        "\n",
        "Processes phrase-optimized JSON files from the enhanced pharmaceutical document parser.\n",
        "Optimized for small language models with robust extraction and error handling.\n",
        "Includes detailed logging of prompts and responses for debugging model performance.\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import requests\n",
        "import time\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any, Optional\n",
        "from datetime import datetime\n",
        "import logging\n",
        "from google.colab import drive\n",
        "\n",
        "# ==============================================================================\n",
        "# CORE LOGIC: Enhanced PharmaceuticalKnowledgeExtractor CLASS\n",
        "# ==============================================================================\n",
        "\n",
        "class EnhancedPharmaceuticalKnowledgeExtractor:\n",
        "    def __init__(self,\n",
        "                 model_name: str = \"llama3.2:3b\",\n",
        "                 ollama_url: str = \"http://localhost:11434/api/generate\",\n",
        "                 max_retries: int = 3,\n",
        "                 request_delay: float = 0.5):\n",
        "        \"\"\"\n",
        "        Initialize the enhanced knowledge extractor optimized for phrase-based JSON files.\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.ollama_url = ollama_url\n",
        "        self.max_retries = max_retries\n",
        "        self.request_delay = request_delay\n",
        "\n",
        "        self.stats = {\n",
        "            'files_processed': 0,\n",
        "            'phrase_blocks_processed': 0,\n",
        "            'table_blocks_processed': 0,\n",
        "            'phrases_processed': 0,\n",
        "            'successful_extractions': 0,\n",
        "            'failed_extractions': 0,\n",
        "            'total_triples': 0,\n",
        "            'skipped_irrelevant': 0\n",
        "        }\n",
        "\n",
        "        # Enhanced patterns for better pharmaceutical content detection\n",
        "        self.pharma_keywords = [\n",
        "            'mg', 'ml', 'g/', 'mcg', 'μg', '%', 'dose', 'dosagem', 'posologia',\n",
        "            'comprimido', 'cápsula', 'medicamento', 'fármaco', 'droga',\n",
        "            'indicação', 'indicado', 'tratamento', 'terapia',\n",
        "            'contraindicação', 'contraindicado', 'não usar', 'evitar',\n",
        "            'efeito', 'reação', 'adverso', 'colateral', 'indesejável',\n",
        "            'alergia', 'hipersensibilidade', 'intolerância',\n",
        "            'administração', 'aplicar', 'tomar', 'ingerir',\n",
        "            'composição', 'princípio ativo', 'substância', 'excipiente',\n",
        "            'interação', 'interagir', 'incompatível', 'interferir',\n",
        "            'gravidez', 'gestação', 'lactação', 'amamentação',\n",
        "            'criança', 'pediátrico', 'adulto', 'idoso', 'geriátrico'\n",
        "        ]\n",
        "\n",
        "        self._setup_logging()\n",
        "        self._test_ollama_connection()\n",
        "\n",
        "    def _setup_logging(self):\n",
        "        \"\"\"Setup enhanced logging configuration.\"\"\"\n",
        "        # Remove existing handlers to avoid duplicates in Colab\n",
        "        for handler in logging.root.handlers[:]:\n",
        "            logging.root.removeHandler(handler)\n",
        "\n",
        "        # General logger for progress and errors\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "            handlers=[\n",
        "                logging.FileHandler('enhanced_pharma_extraction.log'),\n",
        "                logging.StreamHandler()\n",
        "            ]\n",
        "        )\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "        # Dedicated logger for prompts and responses\n",
        "        self.prompt_logger = logging.getLogger('prompt_logger')\n",
        "        self.prompt_logger.setLevel(logging.INFO)\n",
        "        prompt_handler = logging.FileHandler('enhanced_prompts_and_responses.log', mode='w')\n",
        "        prompt_formatter = logging.Formatter('%(message)s')\n",
        "        prompt_handler.setFormatter(prompt_formatter)\n",
        "\n",
        "        # Avoid adding handlers if they already exist\n",
        "        if not self.prompt_logger.handlers:\n",
        "            self.prompt_logger.addHandler(prompt_handler)\n",
        "\n",
        "    def _test_ollama_connection(self):\n",
        "        \"\"\"Test connection to Ollama API with enhanced error reporting.\"\"\"\n",
        "        try:\n",
        "            test_payload = {\n",
        "                \"model\": self.model_name,\n",
        "                \"prompt\": \"Teste de conexão. Responda apenas 'OK'.\",\n",
        "                \"stream\": False,\n",
        "                \"format\": \"json\",\n",
        "                \"options\": {\"temperature\": 0.0, \"num_predict\": 10}\n",
        "            }\n",
        "            response = requests.post(self.ollama_url, json=test_payload, timeout=15)\n",
        "            if response.status_code == 200:\n",
        "                self.logger.info(f\"✅ Successfully connected to Ollama with {self.model_name}\")\n",
        "                result = response.json()\n",
        "                self.logger.debug(f\"Test response: {result.get('response', 'No response')}\")\n",
        "            else:\n",
        "                self.logger.warning(f\"⚠️ Ollama connection test failed: {response.status_code} - {response.text}\")\n",
        "        except requests.exceptions.ConnectionError:\n",
        "            self.logger.error(\"❌ Cannot connect to Ollama API. Ensure it's running and accessible from this Colab notebook.\")\n",
        "            raise ConnectionError(\"Cannot connect to Ollama API. Ensure it's running and accessible (e.g., via ngrok).\")\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"❌ Failed to connect to Ollama: {e}\")\n",
        "            raise ConnectionError(f\"Ollama connection failed: {e}\")\n",
        "\n",
        "    def _call_ollama_api(self, prompt: str, max_tokens: int = 200) -> Optional[str]:\n",
        "        \"\"\"Enhanced API call with better error handling and retry logic.\"\"\"\n",
        "        payload = {\n",
        "            \"model\": self.model_name,\n",
        "            \"prompt\": prompt,\n",
        "            \"stream\": False,\n",
        "            \"format\": \"json\",\n",
        "            \"options\": {\n",
        "                \"temperature\": 0.0,  # Deterministic for structured output\n",
        "                \"top_p\": 0.9,\n",
        "                \"top_k\": 20,\n",
        "                \"num_predict\": max_tokens,\n",
        "                \"stop\": [\"\\n\\n\", \"---\", \"Exemplos:\", \"Examples:\", \"Nota:\", \"Note:\"],\n",
        "                \"repeat_penalty\": 1.1,\n",
        "                \"num_ctx\": 2048,  # Context window\n",
        "            }\n",
        "        }\n",
        "\n",
        "        for attempt in range(self.max_retries):\n",
        "            try:\n",
        "                self.logger.debug(f\"API call attempt {attempt + 1}/{self.max_retries}\")\n",
        "                response = requests.post(self.ollama_url, json=payload, timeout=120)\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    result = response.json()\n",
        "                    response_text = result.get('response', '').strip()\n",
        "                    if response_text:\n",
        "                        return response_text\n",
        "                    else:\n",
        "                        self.logger.warning(\"Empty response from API\")\n",
        "                else:\n",
        "                    self.logger.warning(f\"API error {response.status_code}: {response.text[:200]}...\")\n",
        "\n",
        "            except requests.exceptions.Timeout:\n",
        "                self.logger.warning(f\"Request timeout on attempt {attempt + 1}\")\n",
        "            except requests.exceptions.ConnectionError:\n",
        "                self.logger.warning(f\"Connection error on attempt {attempt + 1}\")\n",
        "            except Exception as e:\n",
        "                self.logger.warning(f\"Request error on attempt {attempt + 1}: {e}\")\n",
        "\n",
        "            if attempt < self.max_retries - 1:\n",
        "                wait_time = (2 ** attempt) + self.request_delay\n",
        "                self.logger.debug(f\"Waiting {wait_time:.1f}s before retry...\")\n",
        "                time.sleep(wait_time)\n",
        "\n",
        "        self.logger.error(\"All API call attempts failed\")\n",
        "        return None\n",
        "\n",
        "    def _create_enhanced_extraction_prompt(self, phrase: str, context: Dict, phrase_type: str = None) -> str:\n",
        "        \"\"\"Create an enhanced, more specific prompt for small language models.\"\"\"\n",
        "        section_info = context.get('breadcrumb', 'Seção Desconhecida')\n",
        "        phrase_category = phrase_type or context.get('metadata', {}).get('phrase_type', 'geral')\n",
        "\n",
        "        # Create more specific instructions based on phrase type\n",
        "        specific_instructions = {\n",
        "            'dosage_instruction': 'Foque em doses, quantidades, frequências de administração.',\n",
        "            'indication': 'Extraia para que condições ou doenças o medicamento é indicado.',\n",
        "            'contraindication': 'Identifique quando o medicamento NÃO deve ser usado.',\n",
        "            'side_effect': 'Extraia efeitos adversos, reações indesejáveis.',\n",
        "            'precaution': 'Identifique cuidados, precauções, advertências.',\n",
        "            'numerical_data': 'Extraia dados numéricos relevantes (doses, concentrações).',\n",
        "            'general_information': 'Extraia qualquer informação farmacêutica relevante.'\n",
        "        }\n",
        "\n",
        "        instruction = specific_instructions.get(phrase_category, specific_instructions['general_information'])\n",
        "\n",
        "        return f\"\"\"Você é um especialista em extrair informações farmacêuticas. Analise esta frase e extraia APENAS fatos reais como triplas JSON.\n",
        "\n",
        "CONTEXTO: {section_info}\n",
        "TIPO: {phrase_category}\n",
        "INSTRUÇÃO: {instruction}\n",
        "\n",
        "FRASE: \"{phrase}\"\n",
        "\n",
        "REGRAS IMPORTANTES:\n",
        "1. Extraia SOMENTE informações que estão EXPLÍCITAS na frase\n",
        "2. NÃO invente ou suponha informações\n",
        "3. Use nomes de medicamentos exatos quando mencionados\n",
        "4. Para doses, inclua unidades (mg, ml, etc.)\n",
        "5. Se não há informação farmacêutica específica, retorne []\n",
        "\n",
        "FORMATO: Array JSON de triplas [entidade, relação, valor]\n",
        "\n",
        "EXEMPLOS DE FORMATO (NÃO COPIE O CONTEÚDO):\n",
        "- [[\"Paracetamol\", \"tem_dose\", \"500mg\"]]\n",
        "- [[\"medicamento\", \"é_indicado_para\", \"dor de cabeça\"]]\n",
        "- [[\"substância\", \"pode_causar\", \"náusea\"]]\n",
        "\n",
        "JSON:\"\"\"\n",
        "\n",
        "    def _parse_triples_response_enhanced(self, response: str) -> List[List[str]]:\n",
        "        \"\"\"Enhanced parsing with better error handling and validation.\"\"\"\n",
        "        if not response:\n",
        "            return []\n",
        "\n",
        "        # Clean the response\n",
        "        cleaned = re.sub(r'```json\\s*|```\\s*', '', response.strip())\n",
        "        cleaned = re.sub(r'^[^[]*', '', cleaned)  # Remove text before first [\n",
        "        cleaned = re.sub(r'[^]]*$', ']', cleaned)  # Ensure ends with ]\n",
        "\n",
        "        # Try multiple parsing strategies\n",
        "        strategies = [\n",
        "            self._parse_json_array,\n",
        "            self._parse_regex_triples,\n",
        "            self._parse_fallback_patterns\n",
        "        ]\n",
        "\n",
        "        for strategy in strategies:\n",
        "            try:\n",
        "                triples = strategy(cleaned)\n",
        "                if triples:\n",
        "                    return self._validate_and_filter_triples(triples)\n",
        "            except Exception as e:\n",
        "                self.logger.debug(f\"Parsing strategy failed: {e}\")\n",
        "                continue\n",
        "\n",
        "        self.logger.warning(f\"Could not parse response: {cleaned[:100]}...\")\n",
        "        return []\n",
        "\n",
        "    def _parse_json_array(self, text: str) -> List[List[str]]:\n",
        "        \"\"\"Parse JSON array directly.\"\"\"\n",
        "        # Find the JSON array pattern\n",
        "        array_match = re.search(r'\\[.*?\\]', text, re.DOTALL)\n",
        "        if array_match:\n",
        "            json_str = array_match.group(0)\n",
        "            parsed = json.loads(json_str)\n",
        "            if isinstance(parsed, list):\n",
        "                return parsed\n",
        "        return []\n",
        "\n",
        "    def _parse_regex_triples(self, text: str) -> List[List[str]]:\n",
        "        \"\"\"Parse using regex patterns for triple extraction.\"\"\"\n",
        "        patterns = [\n",
        "            r'\\[\"([^\"]+)\",\\s*\"([^\"]+)\",\\s*\"([^\"]+)\"\\]',  # Standard format\n",
        "            r'\\[\\\"([^\\\"]+)\\\",\\s*\\\"([^\\\"]+)\\\",\\s*\\\"([^\\\"]+)\\\"\\]',  # Escaped quotes\n",
        "            r'<([^>]+)>\\s*,\\s*<([^>]+)>\\s*,\\s*<([^>]+)>'  # Angle bracket format\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            matches = re.findall(pattern, text)\n",
        "            if matches:\n",
        "                return [[str(x).strip() for x in match] for match in matches]\n",
        "        return []\n",
        "\n",
        "    def _parse_fallback_patterns(self, text: str) -> List[List[str]]:\n",
        "        \"\"\"Fallback parsing for malformed but recognizable patterns.\"\"\"\n",
        "        # Look for entity-relation-value patterns\n",
        "        lines = text.split('\\n')\n",
        "        triples = []\n",
        "\n",
        "        for line in lines:\n",
        "            # Pattern: \"entity\" relation \"value\"\n",
        "            pattern = r'\"([^\"]+)\"\\s+(\\w+)\\s+\"([^\"]+)\"'\n",
        "            match = re.search(pattern, line)\n",
        "            if match:\n",
        "                triples.append([match.group(1), match.group(2), match.group(3)])\n",
        "\n",
        "        return triples\n",
        "\n",
        "    def _validate_and_filter_triples(self, triples: List[List[str]]) -> List[List[str]]:\n",
        "        \"\"\"Validate and filter extracted triples for quality.\"\"\"\n",
        "        valid_triples = []\n",
        "\n",
        "        # Filter out common template examples and invalid entries\n",
        "        template_entities = ['medication', 'medicamento', 'paracetamol', 'substância', 'fármaco']\n",
        "        template_values = ['500mg', 'comprimidos', 'dor de cabeça', 'náusea', 'exemplo']\n",
        "\n",
        "        for triple in triples:\n",
        "            if not isinstance(triple, list) or len(triple) != 3:\n",
        "                continue\n",
        "\n",
        "            entity, relation, value = [str(x).strip() for x in triple]\n",
        "\n",
        "            # Skip if any component is empty or too short\n",
        "            if not all([entity, relation, value]) or any(len(x) < 2 for x in [entity, relation, value]):\n",
        "                continue\n",
        "\n",
        "            # Skip template examples\n",
        "            if (entity.lower() in template_entities and\n",
        "                any(tv in value.lower() for tv in template_values)):\n",
        "                continue\n",
        "\n",
        "            # Skip placeholder patterns\n",
        "            if any(x.startswith('<') and x.endswith('>') for x in [entity, relation, value]):\n",
        "                continue\n",
        "\n",
        "            # Skip overly generic relations\n",
        "            generic_relations = ['é', 'tem', 'faz', 'usa']\n",
        "            if relation.lower() in generic_relations and len(value) < 5:\n",
        "                continue\n",
        "\n",
        "            valid_triples.append([entity, relation, value])\n",
        "\n",
        "        return valid_triples\n",
        "\n",
        "    def _should_process_phrase(self, phrase: str, metadata: Dict = None) -> bool:\n",
        "        \"\"\"Enhanced logic to determine if a phrase should be processed.\"\"\"\n",
        "        if len(phrase.strip()) < 15:\n",
        "            return False\n",
        "\n",
        "        phrase_lower = phrase.lower()\n",
        "\n",
        "        # Check for pharmaceutical keywords\n",
        "        has_pharma_content = any(kw in phrase_lower for kw in self.pharma_keywords)\n",
        "\n",
        "        # Check phrase type from metadata\n",
        "        if metadata:\n",
        "            phrase_type = metadata.get('phrase_type', '')\n",
        "            if phrase_type in ['dosage_instruction', 'indication', 'contraindication', 'side_effect']:\n",
        "                return True\n",
        "\n",
        "        # Additional checks for numerical data that might be relevant\n",
        "        has_numbers = bool(re.search(r'\\d', phrase))\n",
        "        has_units = bool(re.search(r'\\d+\\s*(mg|ml|g|%|mcg|μg)', phrase_lower))\n",
        "\n",
        "        return has_pharma_content or has_units or (has_numbers and len(phrase) > 30)\n",
        "\n",
        "    def _extract_phrase_knowledge(self, phrase_data: Dict) -> Dict:\n",
        "        \"\"\"Extract knowledge from a single phrase block with enhanced processing.\"\"\"\n",
        "        phrase_id = phrase_data.get('phrase_id', 'unknown')\n",
        "        phrase_content = phrase_data.get('content', '').strip()\n",
        "        context = phrase_data.get('context', {})\n",
        "        metadata = phrase_data.get('metadata', {})\n",
        "\n",
        "        if not self._should_process_phrase(phrase_content, metadata):\n",
        "            self.stats['skipped_irrelevant'] += 1\n",
        "            return {\n",
        "                'phrase_id': phrase_id,\n",
        "                'triples': [],\n",
        "                'status': 'skipped_irrelevant'\n",
        "            }\n",
        "\n",
        "        self.logger.debug(f\"Processing phrase {phrase_id}: {phrase_content[:50]}...\")\n",
        "        self.stats['phrases_processed'] += 1\n",
        "\n",
        "        try:\n",
        "            phrase_type = metadata.get('phrase_type')\n",
        "            prompt = self._create_enhanced_extraction_prompt(phrase_content, context, phrase_type)\n",
        "\n",
        "            # Log the interaction\n",
        "            self.prompt_logger.info(f\"--- START PHRASE: {phrase_id} ---\")\n",
        "            self.prompt_logger.info(f\"PHRASE TEXT: {phrase_content}\")\n",
        "            self.prompt_logger.info(f\"PHRASE TYPE: {phrase_type}\")\n",
        "            self.prompt_logger.info(f\"CONTEXT: {context.get('breadcrumb', 'N/A')}\")\n",
        "            self.prompt_logger.info(f\"PROMPT SENT:\\n{prompt}\")\n",
        "\n",
        "            response = self._call_ollama_api(prompt, max_tokens=300)\n",
        "\n",
        "            self.prompt_logger.info(f\"RAW RESPONSE RECEIVED:\\n{response}\")\n",
        "            self.prompt_logger.info(f\"--- END PHRASE: {phrase_id} ---\\n\")\n",
        "\n",
        "            if response:\n",
        "                triples = self._parse_triples_response_enhanced(response)\n",
        "                if triples:\n",
        "                    self.stats['successful_extractions'] += 1\n",
        "                    self.stats['total_triples'] += len(triples)\n",
        "                    self.logger.debug(f\"✅ Extracted {len(triples)} triples from phrase {phrase_id}\")\n",
        "                else:\n",
        "                    self.stats['failed_extractions'] += 1\n",
        "\n",
        "                return {\n",
        "                    'phrase_id': phrase_id,\n",
        "                    'phrase_text': phrase_content,\n",
        "                    'phrase_type': phrase_type,\n",
        "                    'context': context.get('breadcrumb'),\n",
        "                    'triples': triples,\n",
        "                    'status': 'success' if triples else 'no_triples_found'\n",
        "                }\n",
        "            else:\n",
        "                self.stats['failed_extractions'] += 1\n",
        "                return {\n",
        "                    'phrase_id': phrase_id,\n",
        "                    'phrase_text': phrase_content,\n",
        "                    'triples': [],\n",
        "                    'status': 'api_failed'\n",
        "                }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error processing phrase {phrase_id}: {e}\")\n",
        "            self.stats['failed_extractions'] += 1\n",
        "            return {\n",
        "                'phrase_id': phrase_id,\n",
        "                'phrase_text': phrase_content,\n",
        "                'triples': [],\n",
        "                'status': f'error: {str(e)}'\n",
        "            }\n",
        "        finally:\n",
        "            time.sleep(self.request_delay)\n",
        "\n",
        "    def _extract_table_knowledge(self, table_data: Dict) -> Dict:\n",
        "        \"\"\"Extract knowledge from table blocks with structured data handling.\"\"\"\n",
        "        table_id = table_data.get('table_id', 'unknown')\n",
        "        content = table_data.get('content', {})\n",
        "        context = table_data.get('context', {})\n",
        "        metadata = table_data.get('metadata', {})\n",
        "\n",
        "        self.logger.info(f\"Processing table {table_id}\")\n",
        "        self.stats['table_blocks_processed'] += 1\n",
        "\n",
        "        # Convert table to text for processing\n",
        "        formatted_text = content.get('formatted_text', '')\n",
        "        header = content.get('header', [])\n",
        "        data_rows = content.get('data_rows', [])\n",
        "\n",
        "        if not formatted_text and not data_rows:\n",
        "            return {\n",
        "                'table_id': table_id,\n",
        "                'triples': [],\n",
        "                'status': 'empty_table'\n",
        "            }\n",
        "\n",
        "        # Process table as structured text\n",
        "        table_text = formatted_text or self._format_table_as_text(header, data_rows)\n",
        "\n",
        "        # Use table-specific processing\n",
        "        try:\n",
        "            prompt = self._create_table_extraction_prompt(table_text, context, metadata)\n",
        "\n",
        "            self.prompt_logger.info(f\"--- START TABLE: {table_id} ---\")\n",
        "            self.prompt_logger.info(f\"TABLE CONTENT:\\n{table_text}\")\n",
        "            self.prompt_logger.info(f\"PROMPT SENT:\\n{prompt}\")\n",
        "\n",
        "            response = self._call_ollama_api(prompt, max_tokens=400)\n",
        "\n",
        "            self.prompt_logger.info(f\"RAW RESPONSE RECEIVED:\\n{response}\")\n",
        "            self.prompt_logger.info(f\"--- END TABLE: {table_id} ---\\n\")\n",
        "\n",
        "            if response:\n",
        "                triples = self._parse_triples_response_enhanced(response)\n",
        "                if triples:\n",
        "                    self.stats['successful_extractions'] += 1\n",
        "                    self.stats['total_triples'] += len(triples)\n",
        "\n",
        "                return {\n",
        "                    'table_id': table_id,\n",
        "                    'table_type': metadata.get('table_type'),\n",
        "                    'context': context.get('breadcrumb'),\n",
        "                    'triples': triples,\n",
        "                    'status': 'success' if triples else 'no_triples_found'\n",
        "                }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error processing table {table_id}: {e}\")\n",
        "            self.stats['failed_extractions'] += 1\n",
        "\n",
        "        return {\n",
        "            'table_id': table_id,\n",
        "            'triples': [],\n",
        "            'status': 'error'\n",
        "        }\n",
        "\n",
        "    def _create_table_extraction_prompt(self, table_text: str, context: Dict, metadata: Dict) -> str:\n",
        "        \"\"\"Create specialized prompt for table data extraction.\"\"\"\n",
        "        table_type = metadata.get('table_type', 'general_data')\n",
        "        section_info = context.get('breadcrumb', 'Tabela')\n",
        "\n",
        "        type_instructions = {\n",
        "            'dosage_schedule': 'Extraia informações de dosagem, horários, frequências.',\n",
        "            'dosage_information': 'Foque em doses, concentrações, quantidades.',\n",
        "            'age_specific_data': 'Extraia dados específicos por idade ou grupo.',\n",
        "            'general_data': 'Extraia qualquer informação farmacêutica estruturada.'\n",
        "        }\n",
        "\n",
        "        instruction = type_instructions.get(table_type, type_instructions['general_data'])\n",
        "\n",
        "        return f\"\"\"Analise esta tabela farmacêutica e extraia informações estruturadas como triplas JSON.\n",
        "\n",
        "CONTEXTO: {section_info}\n",
        "TIPO DE TABELA: {table_type}\n",
        "INSTRUÇÃO: {instruction}\n",
        "\n",
        "TABELA:\n",
        "{table_text}\n",
        "\n",
        "REGRAS:\n",
        "1. Extraia APENAS dados que estão na tabela\n",
        "2. Para doses, mantenha unidades (mg, ml, etc.)\n",
        "3. Preserve nomes de medicamentos exatos\n",
        "4. Se há múltiplas linhas, extraia informação de cada linha relevante\n",
        "5. Use \"linha_N\" ou \"item_N\" para distinguir entradas quando necessário\n",
        "\n",
        "FORMATO: Array JSON de triplas [entidade, relação, valor]\n",
        "\n",
        "JSON:\"\"\"\n",
        "\n",
        "    def _format_table_as_text(self, header: List[str], data_rows: List[List[str]]) -> str:\n",
        "        \"\"\"Format table data as readable text.\"\"\"\n",
        "        if not data_rows:\n",
        "            return \"\"\n",
        "\n",
        "        lines = []\n",
        "        if header:\n",
        "            lines.append(\" | \".join(header))\n",
        "            lines.append(\"-\" * (len(\" | \".join(header))))\n",
        "\n",
        "        for row in data_rows:\n",
        "            lines.append(\" | \".join(str(cell) if cell else \"\" for cell in row))\n",
        "\n",
        "        return \"\\n\".join(lines)\n",
        "\n",
        "    def process_phrase_based_json(self, input_file: Path) -> Optional[Dict]:\n",
        "        \"\"\"Process a phrase-based JSON file from the enhanced parser.\"\"\"\n",
        "        self.logger.info(f\"📄 Processing phrase-based file: {input_file.name}\")\n",
        "\n",
        "        try:\n",
        "            with open(input_file, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to load {input_file}: {e}\")\n",
        "            return None\n",
        "\n",
        "        # Get the document structure\n",
        "        doc_structure = data.get('document_structure', {})\n",
        "        phrase_blocks = doc_structure.get('phrase_blocks', [])\n",
        "        table_blocks = doc_structure.get('table_blocks', [])\n",
        "\n",
        "        if not phrase_blocks and not table_blocks:\n",
        "            self.logger.warning(f\"No phrase_blocks or table_blocks found in {input_file}\")\n",
        "            return None\n",
        "\n",
        "        self.logger.info(f\"Found {len(phrase_blocks)} phrase blocks and {len(table_blocks)} table blocks\")\n",
        "\n",
        "        # Process phrase blocks\n",
        "        phrase_extractions = []\n",
        "        for phrase_data in phrase_blocks:\n",
        "            result = self._extract_phrase_knowledge(phrase_data)\n",
        "            phrase_extractions.append(result)\n",
        "            self.stats['phrase_blocks_processed'] += 1\n",
        "\n",
        "        # Process table blocks\n",
        "        table_extractions = []\n",
        "        for table_data in table_blocks:\n",
        "            result = self._extract_table_knowledge(table_data)\n",
        "            table_extractions.append(result)\n",
        "\n",
        "        # Collect all triples\n",
        "        all_triples = []\n",
        "        for extraction in phrase_extractions + table_extractions:\n",
        "            all_triples.extend(extraction.get('triples', []))\n",
        "\n",
        "        result = {\n",
        "            'document_metadata': data.get('document_metadata', {}),\n",
        "            'extraction_summary': {\n",
        "                'extraction_timestamp': datetime.now().isoformat(),\n",
        "                'model_used': self.model_name,\n",
        "                'processing_method': 'enhanced_phrase_based',\n",
        "                'total_phrase_blocks': len(phrase_blocks),\n",
        "                'total_table_blocks': len(table_blocks),\n",
        "                'total_phrases_processed': self.stats['phrases_processed'],\n",
        "                'total_triples_extracted': len(all_triples),\n",
        "                'successful_extractions': self.stats['successful_extractions'],\n",
        "                'failed_extractions': self.stats['failed_extractions'],\n",
        "                'skipped_irrelevant': self.stats['skipped_irrelevant']\n",
        "            },\n",
        "            'phrase_extractions': phrase_extractions,\n",
        "            'table_extractions': table_extractions,\n",
        "            'all_extracted_triples': all_triples,\n",
        "            'metadata': data.get('metadata', {})\n",
        "        }\n",
        "\n",
        "        self.stats['files_processed'] += 1\n",
        "        self.logger.info(f\"✅ Completed {input_file.name}: {len(all_triples)} total triples extracted\")\n",
        "        return result\n",
        "\n",
        "    def process_directory(self, input_dir: Path, output_dir: Path):\n",
        "        \"\"\"Process all phrase-optimized JSON files in a directory.\"\"\"\n",
        "        if not input_dir.is_dir():\n",
        "            raise FileNotFoundError(f\"Input directory not found: {input_dir}\")\n",
        "        output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Look for phrase-optimized JSON files\n",
        "        json_files = list(input_dir.glob('*_phrase_optimized.json'))\n",
        "        if not json_files:\n",
        "            self.logger.warning(f\"No *_phrase_optimized.json files found in {input_dir}\")\n",
        "            return\n",
        "\n",
        "        self.logger.info(f\"Found {len(json_files)} phrase-optimized files to process\")\n",
        "\n",
        "        for i, json_file in enumerate(json_files):\n",
        "            self.logger.info(f\"\\n📊 Progress: Processing file {i + 1}/{len(json_files)}\")\n",
        "\n",
        "            # Reset per-file counters\n",
        "            prev_phrases = self.stats['phrases_processed']\n",
        "            prev_successful = self.stats['successful_extractions']\n",
        "\n",
        "            result = self.process_phrase_based_json(json_file)\n",
        "\n",
        "            if result:\n",
        "                output_name = json_file.stem.replace('_phrase_optimized', '_enhanced_graph_data') + '.json'\n",
        "                output_file = output_dir / output_name\n",
        "\n",
        "                with open(output_file, 'w', encoding='utf-8') as f:\n",
        "                    json.dump(result, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "                # Log file-specific stats\n",
        "                phrases_this_file = self.stats['phrases_processed'] - prev_phrases\n",
        "                successful_this_file = self.stats['successful_extractions'] - prev_successful\n",
        "\n",
        "                self.logger.info(f\"💾 Saved results to: {output_file}\")\n",
        "                self.logger.info(f\"📊 File stats: {phrases_this_file} phrases processed, {successful_this_file} successful extractions\")\n",
        "\n",
        "        self._generate_enhanced_report(output_dir)\n",
        "\n",
        "    def _generate_enhanced_report(self, output_dir: Path):\n",
        "        \"\"\"Generate comprehensive final report.\"\"\"\n",
        "        report = {\n",
        "            'summary': {\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'model_used': self.model_name,\n",
        "                'processing_method': 'enhanced_phrase_based',\n",
        "                'total_files_processed': self.stats['files_processed'],\n",
        "            },\n",
        "            'detailed_statistics': self.stats,\n",
        "            'performance_metrics': {\n",
        "                'success_rate': (\n",
        "                    self.stats['successful_extractions'] /\n",
        "                    max(self.stats['phrases_processed'], 1) * 100\n",
        "                ),\n",
        "                'avg_triples_per_successful_extraction': (\n",
        "                    self.stats['total_triples'] /\n",
        "                    max(self.stats['successful_extractions'], 1)\n",
        "                ),\n",
        "                'processing_efficiency': {\n",
        "                    'phrases_processed': self.stats['phrases_processed'],\n",
        "                    'relevant_phrases': self.stats['phrases_processed'] - self.stats['skipped_irrelevant'],\n",
        "                    'relevance_rate': (\n",
        "                        (self.stats['phrases_processed'] - self.stats['skipped_irrelevant']) /\n",
        "                        max(self.stats['phrases_processed'], 1) * 100\n",
        "                    )\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        report_file = output_dir / 'enhanced_final_extraction_report.json'\n",
        "        with open(report_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(report, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        self.logger.info(f\"📊 Enhanced final report saved: {report_file}\")\n",
        "        self._print_summary_stats()\n",
        "\n",
        "    def _print_summary_stats(self):\n",
        "        \"\"\"Print summary statistics to console.\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"🎯 EXTRACTION SUMMARY\")\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"📁 Files processed: {self.stats['files_processed']}\")\n",
        "        print(f\"🧩 Phrase blocks processed: {self.stats['phrase_blocks_processed']}\")\n",
        "        print(f\"📋 Table blocks processed: {self.stats['table_blocks_processed']}\")\n",
        "        print(f\"✨ Total phrases analyzed: {self.stats['phrases_processed']}\")\n",
        "        print(f\"✅ Successful extractions: {self.stats['successful_extractions']}\")\n",
        "        print(f\"❌ Failed extractions: {self.stats['failed_extractions']}\")\n",
        "        print(f\"⏭️ Skipped irrelevant: {self.stats['skipped_irrelevant']}\")\n",
        "        print(f\"🔗 Total triples extracted: {self.stats['total_triples']}\")\n",
        "\n",
        "        if self.stats['phrases_processed'] > 0:\n",
        "            success_rate = (self.stats['successful_extractions'] / self.stats['phrases_processed']) * 100\n",
        "            print(f\"📈 Success rate: {success_rate:.1f}%\")\n",
        "\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 🚀 MAIN EXECUTION SECTION\n",
        "# ==============================================================================\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# IMPORTANT: Change these paths to match your Google Drive folders.\n",
        "DRIVE_INPUT_DIR = \"processed_pdfs\"  # Folder with *_phrase_optimized.json files\n",
        "DRIVE_OUTPUT_DIR = \"enhanced_graph_data\"  # Where enhanced results will be saved\n",
        "OLLAMA_MODEL = \"llama3.2:3b\"        # The Ollama model you are running\n",
        "REQUEST_DELAY = 0.5                 # Seconds to wait between API calls\n",
        "MAX_RETRIES = 3                     # Number of times to retry a failed API call\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function with enhanced error handling and logging.\"\"\"\n",
        "    print(\"🚀 Starting Enhanced Pharmaceutical Knowledge Graph Extractor\")\n",
        "    print(\"🧩 Optimized for phrase-based JSON processing\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    try:\n",
        "        # Mount Google Drive\n",
        "        print(\"🔧 Mounting Google Drive...\")\n",
        "        drive.mount('/content/drive', force_remount=True)\n",
        "        print(\"✅ Google Drive mounted successfully.\")\n",
        "\n",
        "        # Define paths\n",
        "        drive_base_path = Path('/content/drive/MyDrive/')\n",
        "        full_input_path = drive_base_path / DRIVE_INPUT_DIR\n",
        "        full_output_path = drive_base_path / DRIVE_OUTPUT_DIR\n",
        "\n",
        "        print(f\"📁 Input Directory: {full_input_path}\")\n",
        "        print(f\"📂 Output Directory: {full_output_path}\")\n",
        "        print(f\"🤖 Model: {OLLAMA_MODEL}\")\n",
        "        print(f\"🧩 Processing Method: Enhanced phrase-by-phrase\")\n",
        "        print(f\"⏱️  Request Delay: {REQUEST_DELAY}s\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # Validate input directory exists\n",
        "        if not full_input_path.exists():\n",
        "            print(f\"❌ ERROR: Input directory not found at '{full_input_path}'\")\n",
        "            print(\"Please ensure you have run the phrase-based document parser first.\")\n",
        "            print(\"The input directory should contain *_phrase_optimized.json files.\")\n",
        "            return\n",
        "\n",
        "        # Check for expected files\n",
        "        json_files = list(full_input_path.glob('*_phrase_optimized.json'))\n",
        "        if not json_files:\n",
        "            print(f\"⚠️  WARNING: No *_phrase_optimized.json files found in {full_input_path}\")\n",
        "            print(\"Please ensure you have run the enhanced document parser to generate phrase-based JSON files.\")\n",
        "\n",
        "            # Show what files are actually there\n",
        "            all_files = list(full_input_path.glob('*.json'))\n",
        "            if all_files:\n",
        "                print(f\"Found {len(all_files)} JSON files:\")\n",
        "                for f in all_files[:5]:  # Show first 5\n",
        "                    print(f\"  - {f.name}\")\n",
        "                if len(all_files) > 5:\n",
        "                    print(f\"  ... and {len(all_files) - 5} more\")\n",
        "            return\n",
        "\n",
        "        print(f\"🔍 Found {len(json_files)} phrase-optimized files to process:\")\n",
        "        for f in json_files:\n",
        "            print(f\"  - {f.name}\")\n",
        "        print()\n",
        "\n",
        "        # Initialize the enhanced extractor\n",
        "        print(\"🤖 Initializing enhanced knowledge extractor...\")\n",
        "        extractor = EnhancedPharmaceuticalKnowledgeExtractor(\n",
        "            model_name=OLLAMA_MODEL,\n",
        "            max_retries=MAX_RETRIES,\n",
        "            request_delay=REQUEST_DELAY\n",
        "        )\n",
        "\n",
        "        # Process all files\n",
        "        print(\"🚀 Starting batch processing...\")\n",
        "        extractor.process_directory(\n",
        "            input_dir=full_input_path,\n",
        "            output_dir=full_output_path\n",
        "        )\n",
        "\n",
        "        print(\"\\n🎉 All files processed successfully!\")\n",
        "        print(f\"📂 Results saved to: {full_output_path}\")\n",
        "        print(\"📊 Check the enhanced_final_extraction_report.json for detailed statistics.\")\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"❌ ERROR: Directory or file not found.\")\n",
        "        print(f\"Details: {e}\")\n",
        "        print(\"\\nTroubleshooting:\")\n",
        "        print(\"1. Ensure Google Drive is properly mounted\")\n",
        "        print(\"2. Check that the input directory path is correct\")\n",
        "        print(\"3. Verify that phrase-optimized JSON files exist\")\n",
        "\n",
        "    except ConnectionError as e:\n",
        "        print(f\"❌ ERROR: Could not connect to the Ollama server.\")\n",
        "        print(\"Please ensure your local Ollama instance is running and accessible.\")\n",
        "        print(\"If using Google Colab, you may need to use ngrok to tunnel the connection.\")\n",
        "        print(f\"Details: {e}\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(f\"\\n⚠️  Processing interrupted by user.\")\n",
        "        print(\"Partial results may have been saved.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ An unexpected error occurred: {e}\")\n",
        "        import traceback\n",
        "        print(\"Full error traceback:\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "GchrqCiMWeBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Pharmaceutical Knowledge Graph Extractor for Google Colab\n",
        "\n",
        "Processes JSON files from a specified Google Drive directory to extract knowledge triples.\n",
        "Optimized for Llama 3.2 3B model limitations with smart batching and focused prompts.\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import requests\n",
        "import time\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any, Optional\n",
        "from datetime import datetime\n",
        "import logging\n",
        "from google.colab import drive\n",
        "\n",
        "# ==============================================================================\n",
        "# CORE LOGIC: PharmaceuticalKnowledgeExtractor CLASS\n",
        "# ==============================================================================\n",
        "\n",
        "class PharmaceuticalKnowledgeExtractor:\n",
        "    def __init__(self,\n",
        "                 model_name: str = \"llama3.2:3b\",\n",
        "                 ollama_url: str = \"http://localhost:11434/api/generate\",\n",
        "                 max_retries: int = 3,\n",
        "                 request_delay: float = 0.5):\n",
        "        \"\"\"\n",
        "        Initialize the knowledge extractor with Llama 3.2 3B optimizations.\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.ollama_url = ollama_url\n",
        "        self.max_retries = max_retries\n",
        "        self.request_delay = request_delay\n",
        "\n",
        "        self.stats = {\n",
        "            'files_processed': 0, 'blocks_processed': 0,\n",
        "            'successful_extractions': 0, 'failed_extractions': 0,\n",
        "            'total_triples': 0\n",
        "        }\n",
        "\n",
        "        self._setup_logging()\n",
        "        self._test_ollama_connection()\n",
        "\n",
        "    def _setup_logging(self):\n",
        "        \"\"\"Setup logging configuration.\"\"\"\n",
        "        # Remove any existing handlers to avoid duplicate logs in Colab\n",
        "        for handler in logging.root.handlers[:]:\n",
        "            logging.root.removeHandler(handler)\n",
        "\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "            handlers=[\n",
        "                logging.FileHandler('pharma_extraction.log'),\n",
        "                logging.StreamHandler()\n",
        "            ]\n",
        "        )\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def _test_ollama_connection(self):\n",
        "        \"\"\"Test connection to Ollama API.\"\"\"\n",
        "        try:\n",
        "            test_payload = {\n",
        "                \"model\": self.model_name, \"prompt\": \"Test connection\",\n",
        "                \"stream\": False, \"format\": \"json\"\n",
        "            }\n",
        "            response = requests.post(self.ollama_url, json=test_payload, timeout=15)\n",
        "            if response.status_code == 200:\n",
        "                self.logger.info(f\"✅ Successfully connected to Ollama with {self.model_name}\")\n",
        "            else:\n",
        "                self.logger.warning(f\"⚠️ Ollama connection test failed: {response.status_code}\")\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"❌ Failed to connect to Ollama: {e}\")\n",
        "            raise ConnectionError(\"Cannot connect to Ollama API. Ensure it's running and accessible from this Colab notebook (e.g., via ngrok).\")\n",
        "\n",
        "    def _call_ollama_api(self, prompt: str, max_tokens: int = 500) -> Optional[str]:\n",
        "        \"\"\"Call Ollama API with retry logic and error handling.\"\"\"\n",
        "        payload = {\n",
        "            \"model\": self.model_name, \"prompt\": prompt,\n",
        "            \"stream\": False, \"format\": \"json\",\n",
        "            \"options\": {\n",
        "                \"temperature\": 0.1, \"top_p\": 0.9,\n",
        "                \"num_predict\": max_tokens,\n",
        "                \"stop\": [\"\\n\\n\", \"---\"],\n",
        "            }\n",
        "        }\n",
        "\n",
        "        for attempt in range(self.max_retries):\n",
        "            try:\n",
        "                self.logger.debug(f\"API call attempt {attempt + 1}/{self.max_retries}\")\n",
        "                response = requests.post(self.ollama_url, json=payload, timeout=120)\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    result = response.json()\n",
        "                    return result.get('response', '').strip()\n",
        "                else:\n",
        "                    self.logger.warning(f\"API error {response.status_code}: {response.text}\")\n",
        "\n",
        "            except requests.exceptions.Timeout:\n",
        "                self.logger.warning(f\"Request timeout on attempt {attempt + 1}\")\n",
        "            except Exception as e:\n",
        "                self.logger.warning(f\"Request error on attempt {attempt + 1}: {e}\")\n",
        "\n",
        "            if attempt < self.max_retries - 1:\n",
        "                wait_time = (2 ** attempt) + self.request_delay\n",
        "                time.sleep(wait_time)\n",
        "\n",
        "        self.logger.error(\"All API call attempts failed\")\n",
        "        return None\n",
        "\n",
        "    def _create_focused_extraction_prompt(self, content: str, context: Dict) -> str:\n",
        "        \"\"\"Create a focused prompt based on section keywords.\"\"\"\n",
        "        content = content[:800].strip() + \"...\" if len(content) > 800 else content.strip()\n",
        "        section = context.get('breadcrumb', 'Unknown Section')\n",
        "\n",
        "        focus_map = {\n",
        "            \"composition\": ['composição', 'composition'],\n",
        "            \"dosage\": ['dosagem', 'posologia', 'como usar'],\n",
        "            \"indication\": ['indicação', 'indication', 'para que'],\n",
        "            \"contraindication\": ['contraindicação', 'contraindication', 'não devo usar'],\n",
        "            \"side_effect\": ['efeito', 'reação', 'adverse', 'males'],\n",
        "            \"interaction\": ['interação', 'interaction']\n",
        "        }\n",
        "\n",
        "        focus_type = \"general\"\n",
        "        for f_type, keywords in focus_map.items():\n",
        "            if any(kw in section.lower() for kw in keywords):\n",
        "                focus_type = f_type\n",
        "                break\n",
        "\n",
        "        return f\"\"\"Extract pharmaceutical facts as JSON triples from this text.\n",
        "\n",
        "Section: {section}\n",
        "Focus: {focus_type}\n",
        "\n",
        "Text: \"{content}\"\n",
        "\n",
        "Extract ONLY factual triples in format [entity, relation, value]. Return a valid JSON array. No explanations.\n",
        "\n",
        "Example:\n",
        "[[\"Amoxicilina\", \"has_dosage\", \"500mg 3x ao dia\"], [\"Amoxicilina\", \"treats\", \"infecções respiratórias\"]]\n",
        "\n",
        "JSON:\"\"\"\n",
        "\n",
        "    def _create_comprehensive_prompt(self, content: str, context: Dict) -> str:\n",
        "        \"\"\"Create a comprehensive prompt for important sections.\"\"\"\n",
        "        content = content[:600].strip() + \"...\" if len(content) > 600 else content.strip()\n",
        "        section = context.get('breadcrumb', 'Unknown Section')\n",
        "\n",
        "        return f\"\"\"Extract all pharmaceutical information from this text as knowledge triples.\n",
        "\n",
        "Section: {section}\n",
        "Content: \"{content}\"\n",
        "\n",
        "Extract triples for medication names, dosages, conditions (indications/contraindications), side effects, and interactions.\n",
        "Format: [[\"entity\", \"relation\", \"value\"], ...]\n",
        "Return only a valid JSON array:\"\"\"\n",
        "\n",
        "    def _parse_triples_response(self, response: str) -> List[List[str]]:\n",
        "        \"\"\"Parse the API response to robustly extract a list of triples.\"\"\"\n",
        "        if not response:\n",
        "            return []\n",
        "\n",
        "        cleaned = re.sub(r'```json\\s*|```\\s*', '', response.strip())\n",
        "\n",
        "        try:\n",
        "            start_idx = cleaned.find('[')\n",
        "            end_idx = cleaned.rfind(']')\n",
        "            if start_idx == -1 or end_idx == -1: return []\n",
        "\n",
        "            json_str = cleaned[start_idx:end_idx + 1]\n",
        "            parsed = json.loads(json_str)\n",
        "\n",
        "            valid_triples = []\n",
        "            if isinstance(parsed, list):\n",
        "                for item in parsed:\n",
        "                    if isinstance(item, list) and len(item) == 3:\n",
        "                        entity, relation, value = [str(x).strip() for x in item]\n",
        "                        if all([entity, relation, value]):\n",
        "                            valid_triples.append([entity, relation, value])\n",
        "            return valid_triples\n",
        "\n",
        "        except json.JSONDecodeError as e:\n",
        "            self.logger.warning(f\"JSON parsing failed: {e}. Falling back to regex.\")\n",
        "            pattern = r'\\[\"([^\"]+)\",\\s*\"([^\"]+)\",\\s*\"([^\"]+)\"\\]'\n",
        "            matches = re.findall(pattern, cleaned)\n",
        "            return [[m[0], m[1], m[2]] for m in matches]\n",
        "\n",
        "    def _should_process_block(self, block: Dict) -> bool:\n",
        "        \"\"\"Determine if a block has relevant content worth processing.\"\"\"\n",
        "        content = block.get('content', '').strip()\n",
        "        if len(content) < 25: return False\n",
        "\n",
        "        pharma_keywords = [\n",
        "            'mg', 'ml', 'dose', 'comprimido', 'cápsula', 'medicamento', 'indicação',\n",
        "            'contraindicação', 'efeito', 'reação', 'alergia', 'administração',\n",
        "            'posologia', 'composição', 'princípio ativo'\n",
        "        ]\n",
        "\n",
        "        return any(kw in content.lower() for kw in pharma_keywords) or len(content) > 150\n",
        "\n",
        "    def _extract_block_knowledge(self, block: Dict, block_index: int) -> Dict:\n",
        "        \"\"\"Extract knowledge from a single block.\"\"\"\n",
        "        block_id = block.get('id', f'block_{block_index}')\n",
        "        if not self._should_process_block(block):\n",
        "            return {\n",
        "                'block_id': block_id, 'triples': [], 'status': 'skipped_irrelevant'\n",
        "            }\n",
        "\n",
        "        content = block.get('content', '').strip()\n",
        "        context = block.get('context', {})\n",
        "        self.logger.info(f\"Processing block {block_id}: {content[:60]}...\")\n",
        "\n",
        "        try:\n",
        "            if len(content) > 500:\n",
        "                prompt = self._create_comprehensive_prompt(content, context)\n",
        "            else:\n",
        "                prompt = self._create_focused_extraction_prompt(content, context)\n",
        "\n",
        "            response = self._call_ollama_api(prompt)\n",
        "\n",
        "            if response:\n",
        "                triples = self._parse_triples_response(response)\n",
        "                self.stats['successful_extractions'] += 1\n",
        "                self.stats['total_triples'] += len(triples)\n",
        "                self.logger.info(f\"✅ Extracted {len(triples)} triples from {block_id}\")\n",
        "                return {\n",
        "                    'block_id': block_id, 'block_type': block.get('type'),\n",
        "                    'breadcrumb': context.get('breadcrumb'), 'triples': triples, 'status': 'success'\n",
        "                }\n",
        "            else:\n",
        "                self.stats['failed_extractions'] += 1\n",
        "                return {\n",
        "                    'block_id': block_id, 'triples': [], 'status': 'api_failed'\n",
        "                }\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in block {block_id}: {e}\")\n",
        "            self.stats['failed_extractions'] += 1\n",
        "            return {\n",
        "                'block_id': block_id, 'triples': [], 'status': f'error: {str(e)}'\n",
        "            }\n",
        "        finally:\n",
        "            time.sleep(self.request_delay)\n",
        "\n",
        "    def process_json_file(self, input_file: Path) -> Optional[Dict]:\n",
        "        \"\"\"Process a single JSON file.\"\"\"\n",
        "        self.logger.info(f\"📄 Processing file: {input_file.name}\")\n",
        "        try:\n",
        "            with open(input_file, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Failed to load {input_file}: {e}\")\n",
        "            return None\n",
        "\n",
        "        blocks = data.get('representations', {}).get('flat_blocks', [])\n",
        "        if not blocks:\n",
        "            self.logger.warning(f\"No flat_blocks found in {input_file}\")\n",
        "            return None\n",
        "\n",
        "        extractions = [self._extract_block_knowledge(block, i) for i, block in enumerate(blocks)]\n",
        "\n",
        "        total_triples = sum(len(e['triples']) for e in extractions)\n",
        "        result = {\n",
        "            'document_metadata': data.get('document_metadata', {}),\n",
        "            'extraction_summary': {\n",
        "                'extraction_timestamp': datetime.now().isoformat(),\n",
        "                'total_triples_extracted': total_triples\n",
        "            },\n",
        "            'graph_extractions': extractions\n",
        "        }\n",
        "\n",
        "        self.stats['files_processed'] += 1\n",
        "        self.logger.info(f\"✅ Completed {input_file.name}: {total_triples} triples extracted.\")\n",
        "        return result\n",
        "\n",
        "    def process_directory(self, input_dir: Path, output_dir: Path):\n",
        "        \"\"\"Process all relevant JSON files in a directory.\"\"\"\n",
        "        if not input_dir.is_dir():\n",
        "            raise FileNotFoundError(f\"Input directory not found: {input_dir}\")\n",
        "        output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        json_files = list(input_dir.glob('*_llm_optimized.json'))\n",
        "        if not json_files:\n",
        "            self.logger.warning(f\"No *_llm_optimized.json files found in {input_dir}\")\n",
        "            return\n",
        "\n",
        "        self.logger.info(f\"Found {len(json_files)} files to process.\")\n",
        "\n",
        "        for i, json_file in enumerate(json_files):\n",
        "            self.logger.info(f\"\\n📊 Progress: Processing file {i + 1}/{len(json_files)}\")\n",
        "            result = self.process_json_file(json_file)\n",
        "\n",
        "            if result:\n",
        "                output_name = json_file.stem.replace('_llm_optimized', '_graph_data') + '.json'\n",
        "                output_file = output_dir / output_name\n",
        "                with open(output_file, 'w', encoding='utf-8') as f:\n",
        "                    json.dump(result, f, indent=2, ensure_ascii=False)\n",
        "                self.logger.info(f\"💾 Saved results to: {output_file}\")\n",
        "\n",
        "        self._generate_final_report(output_dir)\n",
        "\n",
        "    def _generate_final_report(self, output_dir: Path):\n",
        "        \"\"\"Generate and save a final summary report.\"\"\"\n",
        "        report = {\n",
        "            'summary': {\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'model_used': self.model_name,\n",
        "                'total_files_processed': self.stats['files_processed'],\n",
        "            },\n",
        "            'statistics': self.stats,\n",
        "        }\n",
        "        report_file = output_dir / 'final_extraction_report.json'\n",
        "        with open(report_file, 'w') as f:\n",
        "            json.dump(report, f, indent=2, ensure_ascii=False)\n",
        "        self.logger.info(f\"📊 Final report saved: {report_file}\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 🚀 RUN THE EXTRACTION PROCESS\n",
        "# ==============================================================================\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "# IMPORTANT: Change these paths to match your Google Drive folders.\n",
        "DRIVE_INPUT_DIR = \"processed_pdfs\"  # The folder inside 'My Drive' containing your JSONs\n",
        "DRIVE_OUTPUT_DIR = \"graph_data\"     # The folder inside 'My Drive' where results will be saved\n",
        "OLLAMA_MODEL = \"llama3.2:3b\"        # The Ollama model you are running\n",
        "REQUEST_DELAY = 0.5                 # Seconds to wait between API calls\n",
        "MAX_RETRIES = 3                     # Number of times to retry a failed API call\n",
        "\n",
        "# --- 2. SETUP AND EXECUTION ---\n",
        "print(\"🚀 Starting Pharmaceutical Knowledge Graph Extractor\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "try:\n",
        "    # Mount Google Drive\n",
        "    print(\"🔧 Mounting Google Drive...\")\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    print(\"✅ Google Drive mounted successfully.\")\n",
        "\n",
        "    # Define full paths\n",
        "    drive_base_path = Path('/content/drive/MyDrive/')\n",
        "    full_input_path = drive_base_path / DRIVE_INPUT_DIR\n",
        "    full_output_path = drive_base_path / DRIVE_OUTPUT_DIR\n",
        "\n",
        "    print(f\"Input path: {full_input_path}\")\n",
        "    print(f\"Output path: {full_output_path}\")\n",
        "    print(f\"Model: {OLLAMA_MODEL}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Initialize and run the extractor\n",
        "    extractor = PharmaceuticalKnowledgeExtractor(\n",
        "        model_name=OLLAMA_MODEL,\n",
        "        max_retries=MAX_RETRIES,\n",
        "        request_delay=REQUEST_DELAY\n",
        "    )\n",
        "\n",
        "    extractor.process_directory(\n",
        "        input_dir=full_input_path,\n",
        "        output_dir=full_output_path\n",
        "    )\n",
        "\n",
        "    print(\"\\n🎉 All files processed successfully!\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"❌ ERROR: A directory was not found. Please check your paths.\")\n",
        "    print(f\"Details: {e}\")\n",
        "except ConnectionError as e:\n",
        "    print(f\"❌ ERROR: Could not connect to the Ollama server.\")\n",
        "    print(\"Please ensure your local Ollama instance is running and accessible (e.g., via ngrok).\")\n",
        "    print(f\"Details: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNt1PZGG-chr",
        "outputId": "ec8f4100-758d-49ca-fc66-ff57c3dd2bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Starting Pharmaceutical Knowledge Graph Extractor\n",
            "============================================================\n",
            "🔧 Mounting Google Drive...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-09-01 04:10:23,244 - ERROR - ❌ Failed to connect to Ollama: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x79997957f2c0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✅ Google Drive mounted successfully.\n",
            "Input path: /content/drive/MyDrive/processed_pdfs\n",
            "Output path: /content/drive/MyDrive/graph_data\n",
            "Model: llama3.2:3b\n",
            "============================================================\n",
            "❌ ERROR: Could not connect to the Ollama server.\n",
            "Please ensure your local Ollama instance is running and accessible (e.g., via ngrok).\n",
            "Details: Cannot connect to Ollama API. Ensure it's running and accessible from this Colab notebook (e.g., via ngrok).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "start"
      ],
      "metadata": {
        "id": "xFHMdEbI-ZoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell: send EXACT user prompt to local Ollama model (no extra prompt added)\n",
        "# Paste into Colab/Jupyter and run.\n",
        "# Requires ollama CLI available in the environment and model pulled (e.g. !ollama pull llama3.2:3b)\n",
        "# If ollama is not available in Colab, run this in a local notebook where ollama is installed.\n",
        "\n",
        "import subprocess, shlex\n",
        "from IPython.display import display, HTML\n",
        "import ipywidgets as widgets\n",
        "\n",
        "MODEL = \"llama3.2:3b\"  # change if you want another local model ref\n",
        "history = []  # stores tuples (user_prompt, assistant_output) — only used if \"Include history\" is checked\n",
        "\n",
        "# Widgets\n",
        "prompt_box = widgets.Textarea(\n",
        "    placeholder=\"Paste/type the exact prompt you want the model to see (I will NOT modify it).\",\n",
        "    layout=widgets.Layout(width='100%', height='120px')\n",
        ")\n",
        "send_btn = widgets.Button(description=\"Send → model\", button_style=\"primary\")\n",
        "include_history_chk = widgets.Checkbox(value=False, description=\"Include history (send previous turns)\", indent=False)\n",
        "temp_input = widgets.Text(value=\"\", placeholder=\"leave empty for default\", description=\"--temperature\")\n",
        "num_predict_input = widgets.Text(value=\"\", placeholder=\"leave empty for default\", description=\"--num-predict\")\n",
        "clear_hist_btn = widgets.Button(description=\"Clear history\", button_style=\"warning\")\n",
        "output_area = widgets.Output(layout=widgets.Layout(border='1px solid lightgray'))\n",
        "\n",
        "def call_ollama_raw(prompt, extra_flags=\"\"):\n",
        "    \"\"\"Call ollama run MODEL with prompt as stdin. Returns stdout or stderr.\"\"\"\n",
        "    cmd = [\"ollama\", \"run\", MODEL]\n",
        "    if extra_flags:\n",
        "        # split safely\n",
        "        cmd += shlex.split(extra_flags)\n",
        "    try:\n",
        "        proc = subprocess.run(cmd, input=prompt, text=True, capture_output=True, timeout=120)\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(\"`ollama` CLI not found in this environment.\")\n",
        "    except subprocess.TimeoutExpired:\n",
        "        raise RuntimeError(\"ollama call timed out.\")\n",
        "    out = proc.stdout.strip()\n",
        "    if not out:\n",
        "        out = proc.stderr.strip()\n",
        "    return out\n",
        "\n",
        "def on_send(b):\n",
        "    user_prompt = prompt_box.value\n",
        "    if not user_prompt.strip():\n",
        "        with output_area:\n",
        "            print(\"Please paste or type the prompt you want to send to the model.\")\n",
        "        return\n",
        "\n",
        "    # If include-history is checked, build a concatenation of previous turns + current prompt.\n",
        "    if include_history_chk.value and history:\n",
        "        # simple concatenation: previous_user \\n previous_assistant \\n ... then current prompt\n",
        "        parts = []\n",
        "        for u,a in history:\n",
        "            parts.append(u)\n",
        "            parts.append(a)\n",
        "        parts.append(user_prompt)\n",
        "        prompt_to_send = \"\\n\".join(parts)\n",
        "    else:\n",
        "        # send exactly user's prompt (no modifications)\n",
        "        prompt_to_send = user_prompt\n",
        "\n",
        "    # Build extra flags string if provided\n",
        "    extra_flags = \"\"\n",
        "    if temp_input.value.strip():\n",
        "        extra_flags += f\" --temperature {temp_input.value.strip()}\"\n",
        "    if num_predict_input.value.strip():\n",
        "        extra_flags += f\" --num-predict {num_predict_input.value.strip()}\"\n",
        "\n",
        "    with output_area:\n",
        "        print(\"=== Sending EXACT prompt to model ===\")\n",
        "        print(prompt_to_send if len(prompt_to_send) < 3000 else prompt_to_send[:3000] + \"\\n... (truncated preview)\\n\")\n",
        "        print(\"=== Model response (raw) ===\")\n",
        "    try:\n",
        "        response = call_ollama_raw(prompt_to_send, extra_flags=extra_flags)\n",
        "    except FileNotFoundError:\n",
        "        with output_area:\n",
        "            print(\"\\nERROR: `ollama` CLI not found in this environment.\")\n",
        "            print(\"Run this notebook where ollama is installed (local machine) or provide a remote endpoint.\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        with output_area:\n",
        "            print(\"\\nERROR calling ollama:\", str(e))\n",
        "        return\n",
        "\n",
        "    with output_area:\n",
        "        print(response)\n",
        "        print(\"\\n--- (end response) ---\\n\")\n",
        "\n",
        "    # Save to history (so user can choose to include it next time). We store exactly what was sent and received.\n",
        "    history.append((prompt_to_send, response))\n",
        "\n",
        "    # keep history bounded (optional)\n",
        "    if len(history) > 40:\n",
        "        history[:] = history[-40:]\n",
        "\n",
        "def on_clear_history(b):\n",
        "    history.clear()\n",
        "    with output_area:\n",
        "        print(\"History cleared.\")\n",
        "\n",
        "send_btn.on_click(on_send)\n",
        "clear_hist_btn.on_click(on_clear_history)\n",
        "\n",
        "controls = widgets.HBox([send_btn, clear_hist_btn, include_history_chk])\n",
        "flags_row = widgets.HBox([temp_input, num_predict_input])\n",
        "\n",
        "display(HTML(\"<h4>Send EXACT prompt to raw llama3.2:3b (via ollama)</h4>\"))\n",
        "display(HTML(\"<i>I will not modify your prompt. Paste/type it below and press 'Send → model'.</i>\"))\n",
        "display(prompt_box, controls, flags_row, output_area)\n",
        "\n",
        "with output_area:\n",
        "    print(\"Ready. Paste your prompt above and press 'Send → model'.\\n\"\n",
        "          \"If you want the model to see previous turns, check 'Include history' (history is stored only after you send a prompt).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736,
          "referenced_widgets": [
            "67e3c25bcfa047308c5733e8489d9625",
            "dffd9ec1ab3c449fa55aaa4c0086ba61",
            "434825dff58342c896f1dc97114cee12",
            "b46e5dc7403d4f78a4e9e91d9848265e",
            "e27f7423d17143348e097bb370a67cac",
            "3a7a042edc6647c1be5a5af5453c8bd8",
            "5a957ee9e51c425fbc45ce22485cb78c",
            "5bb205f42cf64551ac23b477c87751d6",
            "a1d6d273b95d4f68a4d177d979897cd3",
            "bed5e1d9c27a45e6b5744394e83da8ee",
            "f6813eee3cb449bca8b3e687df47bd52",
            "6d040ad0bc5c4ba292551c7bfae29768",
            "ed285957539b4bfdb19ea31118d56a7b",
            "c2ab7fe2dc4e459894ae75400c06b0b8",
            "f6d2353173d5428dacafb04b9fcdab11",
            "520705944edc4188bbdbe1ad3e882fd0",
            "35ac410ea2ca4e95bb6597c39bc47272",
            "03623a7f848446da9e7ccbd46c537a02",
            "4bc7fe727b4e444ca08c76b2c82a67a6",
            "517cfb13bc6349688da73a77eca192dc",
            "26f1f4abf6274e96b8903327f61f2549",
            "64ddba703b76458d8305f1461bb9d20a",
            "310a0c516ba94292916997978f71ad7e",
            "23092c0378ef4812971884dc79426705"
          ]
        },
        "id": "wnjpsHvdj-Fq",
        "outputId": "ba96d0e9-dd07-452c-cbe1-f52a2ff00ede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h4>Send EXACT prompt to raw llama3.2:3b (via ollama)</h4>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<i>I will not modify your prompt. Paste/type it below and press 'Send → model'.</i>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='', layout=Layout(height='120px', width='100%'), placeholder='Paste/type the exact prompt you w…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67e3c25bcfa047308c5733e8489d9625"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Button(button_style='primary', description='Send → model', style=ButtonStyle()), Button(button_…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b46e5dc7403d4f78a4e9e91d9848265e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Text(value='', description='--temperature', placeholder='leave empty for default'), Text(value=…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6d2353173d5428dacafb04b9fcdab11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output(layout=Layout(border='1px solid lightgray'))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "310a0c516ba94292916997978f71ad7e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "entity extraction"
      ],
      "metadata": {
        "id": "nHz5g_386k1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pymupdf4llm pdfplumber"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnuwVjFY722R",
        "outputId": "1756d16c-17e0-40e5-8fea-52cb02c87967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf4llm in /usr/local/lib/python3.12/dist-packages (0.0.27)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.12/dist-packages (0.11.7)\n",
            "Requirement already satisfied: pymupdf>=1.26.3 in /usr/local/lib/python3.12/dist-packages (from pymupdf4llm) (1.26.4)\n",
            "Requirement already satisfied: pdfminer.six==20250506 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (20250506)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (4.30.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.3)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Automated Pharmaceutical Document Parser with Ollama Integration\n",
        "Automatically processes documents and extracts structured information using local LLM\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import re\n",
        "import subprocess\n",
        "import shlex\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any, Optional\n",
        "from datetime import datetime\n",
        "import pymupdf4llm\n",
        "import pdfplumber\n",
        "\n",
        "class AutomatedPharmaParser:\n",
        "    def __init__(self, model_name: str = \"llama3.2:3b\"):\n",
        "        \"\"\"\n",
        "        Initialize automated parser with Ollama integration\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.raw_content = \"\"\n",
        "        self.structured_data = {}\n",
        "        self.document_loaded = False\n",
        "        self.setup_ollama()\n",
        "\n",
        "    def setup_ollama(self):\n",
        "        \"\"\"Setup Ollama model automatically\"\"\"\n",
        "        print(f\"Setting up Ollama model: {self.model_name}\")\n",
        "\n",
        "        try:\n",
        "            # Check if ollama is available\n",
        "            subprocess.run([\"ollama\", \"--version\"], capture_output=True, check=True)\n",
        "            print(\"✅ Ollama CLI found\")\n",
        "        except (FileNotFoundError, subprocess.CalledProcessError):\n",
        "            raise RuntimeError(\"❌ Ollama CLI not found. Please install Ollama first.\")\n",
        "\n",
        "        try:\n",
        "            # Pull model if not available\n",
        "            print(f\"Pulling model {self.model_name}...\")\n",
        "            result = subprocess.run(\n",
        "                [\"ollama\", \"pull\", self.model_name],\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=300\n",
        "            )\n",
        "            if result.returncode == 0:\n",
        "                print(f\"✅ Model {self.model_name} ready\")\n",
        "            else:\n",
        "                print(f\"⚠️ Pull result: {result.stderr}\")\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(\"⚠️ Model pull timed out, but model might already be available\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error pulling model: {e}\")\n",
        "\n",
        "    def call_ollama_raw(self, prompt: str, extra_flags: str = \"\") -> str:\n",
        "        \"\"\"Call ollama with exact prompt - no modifications\"\"\"\n",
        "        cmd = [\"ollama\", \"run\", self.model_name]\n",
        "        if extra_flags:\n",
        "            cmd += shlex.split(extra_flags)\n",
        "\n",
        "        try:\n",
        "            proc = subprocess.run(\n",
        "                cmd,\n",
        "                input=prompt,\n",
        "                text=True,\n",
        "                capture_output=True,\n",
        "                timeout=120\n",
        "            )\n",
        "            output = proc.stdout.strip()\n",
        "            if not output:\n",
        "                output = proc.stderr.strip()\n",
        "            return output\n",
        "        except subprocess.TimeoutExpired:\n",
        "            raise RuntimeError(\"Ollama call timed out\")\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error calling ollama: {e}\")\n",
        "\n",
        "    def extract_pdf_content(self, pdf_path: str) -> str:\n",
        "        \"\"\"Extract text content from PDF\"\"\"\n",
        "        try:\n",
        "            # Try pdfplumber first\n",
        "            with pdfplumber.open(pdf_path) as pdf:\n",
        "                all_text = []\n",
        "                for page in pdf.pages:\n",
        "                    page_text = page.extract_text()\n",
        "                    if page_text:\n",
        "                        all_text.append(page_text)\n",
        "\n",
        "                if all_text:\n",
        "                    return \"\\n\\n\".join(all_text)\n",
        "        except Exception as e:\n",
        "            print(f\"pdfplumber failed: {e}\")\n",
        "\n",
        "        try:\n",
        "            # Fallback to pymupdf4llm\n",
        "            return pymupdf4llm.to_markdown(pdf_path)\n",
        "        except Exception as e:\n",
        "            print(f\"pymupdf4llm failed: {e}\")\n",
        "            raise Exception(\"All extraction methods failed\")\n",
        "\n",
        "    def create_entity_extraction_prompt(self, text: str, chunk_size: int = 3000) -> List[str]:\n",
        "        \"\"\"Create prompts for entity extraction from pharmaceutical text\"\"\"\n",
        "\n",
        "        # Base prompt for pharmaceutical entity extraction\n",
        "        base_prompt = \"\"\"System: You are a parser. For each Text below, extract entities, relation, value triples as a JSON array.\n",
        "Only output valid JSON. DO NOT include any extra text, commentary, or code fences. Output must be parseable by json.loads().\n",
        "\n",
        "Format:\n",
        "[\n",
        "  {\"entity\": \"...\", \"relation\": \"...\", \"value\": \"...\"},\n",
        "  ...\n",
        "]\n",
        "\n",
        "Focus on pharmaceutical information:\n",
        "- Medication names and active ingredients\n",
        "- Dosages, concentrations, and administration routes\n",
        "- Indications, contraindications, and side effects\n",
        "- Age groups, patient populations\n",
        "- Storage conditions and expiration\n",
        "- Manufacturer information\n",
        "\n",
        "Text: \"\"\"\n",
        "\n",
        "        # Split text into chunks if too long\n",
        "        text_chunks = []\n",
        "        if len(text) <= chunk_size:\n",
        "            text_chunks.append(text)\n",
        "        else:\n",
        "            words = text.split()\n",
        "            current_chunk = []\n",
        "            current_length = 0\n",
        "\n",
        "            for word in words:\n",
        "                if current_length + len(word) + 1 > chunk_size:\n",
        "                    if current_chunk:\n",
        "                        text_chunks.append(\" \".join(current_chunk))\n",
        "                        current_chunk = []\n",
        "                        current_length = 0\n",
        "\n",
        "                current_chunk.append(word)\n",
        "                current_length += len(word) + 1\n",
        "\n",
        "            if current_chunk:\n",
        "                text_chunks.append(\" \".join(current_chunk))\n",
        "\n",
        "        # Create prompts for each chunk\n",
        "        prompts = []\n",
        "        for i, chunk in enumerate(text_chunks):\n",
        "            prompt = f\"{base_prompt}{chunk}\"\n",
        "            prompts.append(prompt)\n",
        "\n",
        "        return prompts\n",
        "\n",
        "    def create_structure_analysis_prompt(self, text: str) -> str:\n",
        "        \"\"\"Create prompt for document structure analysis\"\"\"\n",
        "\n",
        "        structure_prompt = f\"\"\"System: You are a pharmaceutical document analyzer. Analyze the document structure and create a JSON summary.\n",
        "Only output valid JSON. DO NOT include any extra text, commentary, or code fences.\n",
        "\n",
        "Format:\n",
        "{{\n",
        "  \"document_type\": \"...\",\n",
        "  \"main_sections\": [\n",
        "    {{\n",
        "      \"section_number\": \"...\",\n",
        "      \"section_title\": \"...\",\n",
        "      \"content_type\": \"...\",\n",
        "      \"key_points\": [\"...\", \"...\"]\n",
        "    }}\n",
        "  ],\n",
        "  \"medication_info\": {{\n",
        "    \"name\": \"...\",\n",
        "    \"active_ingredient\": \"...\",\n",
        "    \"forms\": [\"...\", \"...\"],\n",
        "    \"concentrations\": [\"...\", \"...\"]\n",
        "  }},\n",
        "  \"critical_information\": {{\n",
        "    \"contraindications\": [\"...\", \"...\"],\n",
        "    \"serious_warnings\": [\"...\", \"...\"],\n",
        "    \"storage_conditions\": \"...\"\n",
        "  }}\n",
        "}}\n",
        "\n",
        "Text: {text[:4000]}\"\"\"\n",
        "\n",
        "        return structure_prompt\n",
        "\n",
        "    def parse_json_response(self, response: str) -> Any:\n",
        "        \"\"\"Parse JSON response, handling common formatting issues\"\"\"\n",
        "        # Clean up response\n",
        "        cleaned = response.strip()\n",
        "\n",
        "        # Remove code fences if present\n",
        "        if cleaned.startswith(\"```\"):\n",
        "            lines = cleaned.split('\\n')\n",
        "            cleaned = '\\n'.join(lines[1:-1] if lines[-1].strip() == \"```\" else lines[1:])\n",
        "\n",
        "        # Remove any leading/trailing text that's not JSON\n",
        "        start_idx = cleaned.find('[') if cleaned.find('[') != -1 else cleaned.find('{')\n",
        "        end_idx = cleaned.rfind(']') if cleaned.rfind(']') != -1 else cleaned.rfind('}')\n",
        "\n",
        "        if start_idx != -1 and end_idx != -1:\n",
        "            cleaned = cleaned[start_idx:end_idx+1]\n",
        "\n",
        "        try:\n",
        "            return json.loads(cleaned)\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"JSON parse error: {e}\")\n",
        "            print(f\"Problematic text: {cleaned[:200]}...\")\n",
        "            return None\n",
        "\n",
        "    def extract_entities_from_document(self, text: str) -> List[Dict]:\n",
        "        \"\"\"Extract entities from entire document\"\"\"\n",
        "        print(\"🔍 Extracting entities using LLM...\")\n",
        "\n",
        "        prompts = self.create_entity_extraction_prompt(text)\n",
        "        all_entities = []\n",
        "\n",
        "        for i, prompt in enumerate(prompts):\n",
        "            print(f\"Processing chunk {i+1}/{len(prompts)}...\")\n",
        "\n",
        "            try:\n",
        "                response = self.call_ollama_raw(prompt)\n",
        "                entities = self.parse_json_response(response)\n",
        "\n",
        "                if entities and isinstance(entities, list):\n",
        "                    all_entities.extend(entities)\n",
        "                    print(f\"  Extracted {len(entities)} entities from chunk {i+1}\")\n",
        "                else:\n",
        "                    print(f\"  No valid entities from chunk {i+1}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  Error processing chunk {i+1}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # Remove duplicates\n",
        "        unique_entities = []\n",
        "        seen = set()\n",
        "        for entity in all_entities:\n",
        "            key = (entity.get('entity', ''), entity.get('relation', ''), entity.get('value', ''))\n",
        "            if key not in seen:\n",
        "                seen.add(key)\n",
        "                unique_entities.append(entity)\n",
        "\n",
        "        print(f\"✅ Total unique entities extracted: {len(unique_entities)}\")\n",
        "        return unique_entities\n",
        "\n",
        "    def analyze_document_structure(self, text: str) -> Dict:\n",
        "        \"\"\"Analyze document structure using LLM\"\"\"\n",
        "        print(\"📋 Analyzing document structure using LLM...\")\n",
        "\n",
        "        prompt = self.create_structure_analysis_prompt(text)\n",
        "\n",
        "        try:\n",
        "            response = self.call_ollama_raw(prompt)\n",
        "            structure = self.parse_json_response(response)\n",
        "\n",
        "            if structure and isinstance(structure, dict):\n",
        "                print(\"✅ Document structure analyzed successfully\")\n",
        "                return structure\n",
        "            else:\n",
        "                print(\"⚠️ Could not parse structure analysis\")\n",
        "                return {}\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error analyzing structure: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def create_summary_prompt(self, entities: List[Dict], structure: Dict) -> str:\n",
        "        \"\"\"Create prompt for generating document summary\"\"\"\n",
        "\n",
        "        entities_text = json.dumps(entities[:50], indent=2)  # Limit to first 50 entities\n",
        "        structure_text = json.dumps(structure, indent=2)\n",
        "\n",
        "        summary_prompt = f\"\"\"System: You are a pharmaceutical document summarizer. Based on the extracted entities and document structure, create a comprehensive summary.\n",
        "Only output valid JSON. DO NOT include any extra text, commentary, or code fences.\n",
        "\n",
        "Format:\n",
        "{{\n",
        "  \"executive_summary\": \"...\",\n",
        "  \"medication_details\": {{\n",
        "    \"name\": \"...\",\n",
        "    \"active_ingredients\": [\"...\", \"...\"],\n",
        "    \"therapeutic_class\": \"...\",\n",
        "    \"indications\": [\"...\", \"...\"],\n",
        "    \"dosage_forms\": [\"...\", \"...\"],\n",
        "    \"key_dosages\": [\"...\", \"...\"]\n",
        "  }},\n",
        "  \"safety_information\": {{\n",
        "    \"contraindications\": [\"...\", \"...\"],\n",
        "    \"warnings\": [\"...\", \"...\"],\n",
        "    \"common_side_effects\": [\"...\", \"...\"],\n",
        "    \"serious_reactions\": [\"...\", \"...\"]\n",
        "  }},\n",
        "  \"administration_info\": {{\n",
        "    \"routes\": [\"...\", \"...\"],\n",
        "    \"dosing_schedule\": \"...\",\n",
        "    \"special_populations\": {{\n",
        "      \"pediatric\": \"...\",\n",
        "      \"geriatric\": \"...\",\n",
        "      \"renal_impairment\": \"...\",\n",
        "      \"hepatic_impairment\": \"...\"\n",
        "    }}\n",
        "  }},\n",
        "  \"storage_and_handling\": \"...\",\n",
        "  \"manufacturer\": \"...\"\n",
        "}}\n",
        "\n",
        "Extracted Entities:\n",
        "{entities_text}\n",
        "\n",
        "Document Structure:\n",
        "{structure_text}\"\"\"\n",
        "\n",
        "        return summary_prompt\n",
        "\n",
        "    def generate_comprehensive_summary(self, entities: List[Dict], structure: Dict) -> Dict:\n",
        "        \"\"\"Generate comprehensive summary using LLM\"\"\"\n",
        "        print(\"📝 Generating comprehensive summary...\")\n",
        "\n",
        "        prompt = self.create_summary_prompt(entities, structure)\n",
        "\n",
        "        try:\n",
        "            response = self.call_ollama_raw(prompt, extra_flags=\"--temperature 0.1\")\n",
        "            summary = self.parse_json_response(response)\n",
        "\n",
        "            if summary and isinstance(summary, dict):\n",
        "                print(\"✅ Summary generated successfully\")\n",
        "                return summary\n",
        "            else:\n",
        "                print(\"⚠️ Could not parse summary\")\n",
        "                return {}\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error generating summary: {e}\")\n",
        "            return {}\n",
        "\n",
        "    def process_document(self, pdf_path: str) -> bool:\n",
        "        \"\"\"Fully automated document processing\"\"\"\n",
        "        print(f\"📄 Processing document: {pdf_path}\")\n",
        "\n",
        "        if not Path(pdf_path).exists():\n",
        "            print(f\"❌ File not found: {pdf_path}\")\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            # Extract text\n",
        "            print(\"📖 Extracting text from PDF...\")\n",
        "            self.raw_content = self.extract_pdf_content(pdf_path)\n",
        "\n",
        "            if not self.raw_content:\n",
        "                print(\"❌ No text content extracted\")\n",
        "                return False\n",
        "\n",
        "            print(f\"✅ Extracted {len(self.raw_content)} characters\")\n",
        "\n",
        "            # Analyze structure\n",
        "            structure = self.analyze_document_structure(self.raw_content)\n",
        "\n",
        "            # Extract entities\n",
        "            entities = self.extract_entities_from_document(self.raw_content)\n",
        "\n",
        "            # Generate summary\n",
        "            summary = self.generate_comprehensive_summary(entities, structure)\n",
        "\n",
        "            # Compile final structure\n",
        "            self.structured_data = {\n",
        "                \"metadata\": {\n",
        "                    \"file_path\": pdf_path,\n",
        "                    \"file_name\": Path(pdf_path).name,\n",
        "                    \"processing_date\": datetime.now().isoformat(),\n",
        "                    \"total_text_length\": len(self.raw_content),\n",
        "                    \"total_entities\": len(entities),\n",
        "                    \"model_used\": self.model_name\n",
        "                },\n",
        "                \"document_structure\": structure,\n",
        "                \"extracted_entities\": entities,\n",
        "                \"comprehensive_summary\": summary,\n",
        "                \"processing_statistics\": {\n",
        "                    \"entities_by_type\": self._count_entities_by_type(entities),\n",
        "                    \"structure_sections\": len(structure.get('main_sections', [])),\n",
        "                    \"processing_method\": \"automated_llm_analysis\"\n",
        "                }\n",
        "            }\n",
        "\n",
        "            self.document_loaded = True\n",
        "            print(\"✅ Document processing completed!\")\n",
        "            self._show_processing_summary()\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error processing document: {e}\")\n",
        "            return False\n",
        "\n",
        "    def _count_entities_by_type(self, entities: List[Dict]) -> Dict[str, int]:\n",
        "        \"\"\"Count entities by relation type\"\"\"\n",
        "        counts = {}\n",
        "        for entity in entities:\n",
        "            relation = entity.get('relation', 'unknown')\n",
        "            counts[relation] = counts.get(relation, 0) + 1\n",
        "        return counts\n",
        "\n",
        "    def _show_processing_summary(self):\n",
        "        \"\"\"Show processing summary\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"📊 PROCESSING SUMMARY\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        metadata = self.structured_data.get(\"metadata\", {})\n",
        "        stats = self.structured_data.get(\"processing_statistics\", {})\n",
        "\n",
        "        print(f\"📁 File: {metadata.get('file_name', 'Unknown')}\")\n",
        "        print(f\"🤖 Model: {metadata.get('model_used', 'Unknown')}\")\n",
        "        print(f\"📝 Text length: {metadata.get('total_text_length', 0):,} characters\")\n",
        "        print(f\"🏷️ Total entities: {metadata.get('total_entities', 0)}\")\n",
        "        print(f\"📋 Structure sections: {stats.get('structure_sections', 0)}\")\n",
        "\n",
        "        print(\"\\n🏷️ Entity distribution:\")\n",
        "        for entity_type, count in stats.get('entities_by_type', {}).items():\n",
        "            print(f\"   {entity_type}: {count}\")\n",
        "\n",
        "        # Show sample entities\n",
        "        entities = self.structured_data.get(\"extracted_entities\", [])\n",
        "        if entities:\n",
        "            print(\"\\n📝 Sample entities:\")\n",
        "            for i, entity in enumerate(entities[:5]):\n",
        "                print(f\"   {i+1}. {entity.get('entity', 'N/A')} -> {entity.get('relation', 'N/A')} -> {entity.get('value', 'N/A')}\")\n",
        "\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "    def save_results(self, output_path: Optional[str] = None) -> str:\n",
        "        \"\"\"Save processing results\"\"\"\n",
        "        if not self.document_loaded:\n",
        "            raise Exception(\"No document processed\")\n",
        "\n",
        "        if not output_path:\n",
        "            file_name = self.structured_data[\"metadata\"][\"file_name\"]\n",
        "            pdf_name = Path(file_name).stem\n",
        "            output_path = f\"{pdf_name}_automated_analysis.json\"\n",
        "\n",
        "        output_file = Path(output_path)\n",
        "        with open(output_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(self.structured_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"\\n📄 Results saved to: {output_file}\")\n",
        "        print(f\"📊 File size: {output_file.stat().st_size:,} bytes\")\n",
        "        return str(output_file)\n",
        "\n",
        "    def query_document(self, question: str) -> str:\n",
        "        \"\"\"Query the processed document\"\"\"\n",
        "        if not self.document_loaded:\n",
        "            return \"❌ No document processed. Please process a document first.\"\n",
        "\n",
        "        # Create context from processed data\n",
        "        context_parts = []\n",
        "\n",
        "        # Add summary\n",
        "        summary = self.structured_data.get(\"comprehensive_summary\", {})\n",
        "        if summary:\n",
        "            context_parts.append(\"DOCUMENT SUMMARY:\")\n",
        "            context_parts.append(json.dumps(summary, indent=2))\n",
        "\n",
        "        # Add relevant entities (simple keyword matching)\n",
        "        entities = self.structured_data.get(\"extracted_entities\", [])\n",
        "        question_words = question.lower().split()\n",
        "        relevant_entities = []\n",
        "\n",
        "        for entity in entities:\n",
        "            entity_text = f\"{entity.get('entity', '')} {entity.get('relation', '')} {entity.get('value', '')}\".lower()\n",
        "            if any(word in entity_text for word in question_words):\n",
        "                relevant_entities.append(entity)\n",
        "\n",
        "        if relevant_entities:\n",
        "            context_parts.append(\"\\nRELEVANT ENTITIES:\")\n",
        "            context_parts.append(json.dumps(relevant_entities[:10], indent=2))\n",
        "\n",
        "        context = \"\\n\".join(context_parts)\n",
        "\n",
        "        # Create query prompt\n",
        "        query_prompt = f\"\"\"System: You are a pharmaceutical document assistant. Answer the question based on the provided document context.\n",
        "Be precise and cite specific information when possible.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Document Context:\n",
        "{context[:6000]}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.call_ollama_raw(query_prompt, extra_flags=\"--temperature 0.1\")\n",
        "            return response.strip()\n",
        "        except Exception as e:\n",
        "            return f\"❌ Error processing query: {e}\"\n",
        "\n",
        "def main():\n",
        "    \"\"\"Demonstrate automated processing\"\"\"\n",
        "    parser = AutomatedPharmaParser(model_name=\"llama3.2:3b\")\n",
        "\n",
        "    # Use the PDF from the documents\n",
        "    pdf_path = \"bula_1755196887789.pdf\"\n",
        "\n",
        "    print(\"🤖 Automated Pharmaceutical Document Parser\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    if parser.process_document(pdf_path):\n",
        "        # Save results\n",
        "        results_file = parser.save_results()\n",
        "\n",
        "        # Test querying\n",
        "        print(f\"\\n🔍 Testing automated querying...\")\n",
        "        test_questions = [\n",
        "            \"Qual é a dosagem recomendada?\",\n",
        "            \"Quais são as contraindicações?\",\n",
        "            \"Como deve ser armazenado o medicamento?\"\n",
        "        ]\n",
        "\n",
        "        for question in test_questions:\n",
        "            print(f\"\\nQ: {question}\")\n",
        "            answer = parser.query_document(question)\n",
        "            print(f\"A: {answer[:200]}...\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33ZQetm96iPl",
        "outputId": "71cddd7f-fe19-4f48-ceca-0f82d7e45abf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up Ollama model: llama3.2:3b\n",
            "✅ Ollama CLI found\n",
            "Pulling model llama3.2:3b...\n",
            "✅ Model llama3.2:3b ready\n",
            "🎯 Sentence-Based Pharmaceutical Document Parser\n",
            "======================================================================\n",
            "📄 Processing document with sentence-based analysis: bula_1755192077396.pdf\n",
            "📖 Extracting text from PDF...\n",
            "✅ Extracted 11936 characters\n",
            "✂️ Splitting text into sentences with abbreviation safeguards...\n",
            "✅ Identified 86 sentences\n",
            "\n",
            "📝 Sample sentences identified:\n",
            "  1. ezetimiba Sandoz do Brasil Ind. Farm. Ltda. Bula do Paciente comprimido 10 mg I) IDENTIFICAÇÃO DO MEDICAMENTO ezetimiba Medicamento genérico, Lei nº 9.787, de 1999 APRESENTAÇÕES ezetimiba comprimido 10 mg. Embalagem contendo 30 ou 60 comprimidos.\n",
            "  2. USO ORAL USO ADULTO E PEDIÁTRICO ACIMA DE 6 ANOS DE IDADE COMPOSIÇÃO Cada comprimido de 10 mg contém: ezetimiba.....................................................\n",
            "  3. 10 mg excipientes q.s.p. .................\n",
            "🔍 Analyzing 86 sentences...\n",
            "Processing sentence 1/86: ezetimiba Sandoz do Brasil Ind. Farm. Ltda. Bula do Paciente...\n",
            "  ✅ Found 4 entities\n",
            "Processing sentence 2/86: USO ORAL USO ADULTO E PEDIÁTRICO ACIMA DE 6 ANOS DE IDADE CO...\n",
            "  ✅ Found 2 entities\n",
            "Processing sentence 3/86: 10 mg excipientes q.s.p. ....................\n",
            "  ✅ Found 1 entities\n",
            "Processing sentence 4/86: 1 comprimido (lactose monoidratada, hipromelose, croscarmelo...\n",
            "  ✅ Found 3 entities\n",
            "Processing sentence 5/86: A ezetimiba é indicada para reduzir a quantidade de colester...\n",
            "  ✅ Found 1 entities\n",
            "Processing sentence 6/86: O colesterol é uma das várias substâncias gordurosas encontr...\n",
            "Processing sentence 7/86: O colesterol total é composto principalmente de colesterol L...\n",
            "  ✅ Found 8 entities\n",
            "Processing sentence 8/86: Eventualmente, essas placas podem causar estreitamento das a...\n",
            "Processing sentence 9/86: Esse bloqueio ao fluxo sanguíneo pode causar ataque cardíaco...\n",
            "  ✅ Found 2 entities\n",
            "Processing sentence 10/86: O colesterol HDL, por sua vez, é frequentemente chamado de “...\n",
            "  ✅ Found 8 entities\n",
            "Processing sentence 11/86: Outra forma de gordura no sangue que pode aumentar o risco d...\n",
            "  ✅ Found 8 entities\n",
            "Processing sentence 12/86: Se você tem sitosterolemia, seu médico prescreveu ezetimiba ...\n",
            "  ✅ Found 2 entities\n",
            "Processing sentence 13/86: 2. COMO ESTE MEDICAMENTO FUNCIONA?...\n",
            "Processing sentence 14/86: A ezetimiba age ao reduzir a absorção do colesterol no intes...\n",
            "  ✅ Found 6 entities\n",
            "Processing sentence 15/86: Portanto, ezetimiba aumenta o efeito redutor do colesterol d...\n",
            "  ✅ Found 3 entities\n",
            "Processing sentence 16/86: O colesterol alto pode ser tratado de duas formas principais...\n",
            "  ✅ Found 2 entities\n",
            "Processing sentence 17/86: Seu médico prescreveu ezetimiba para ajudar a reduzir o seu ...\n",
            "  ✅ Found 2 entities\n",
            "Processing sentence 18/86: 3. QUANDO NÃO DEVO USAR ESTE MEDICAMENTO?...\n",
            "  ✅ Found 2 entities\n",
            "Processing sentence 19/86: Pacientes com hipersensibilidade (alérgicos) a ezetimiba ou ...\n",
            "  ✅ Found 1 entities\n",
            "Processing sentence 20/86: 4. O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO?...\n",
            "Processing sentence 21/86: É importante que continue a tomar ezetimiba diariamente conf...\n",
            "  ✅ Found 2 entities\n",
            "Processing sentence 22/86: Mesmo tomando medicamentos para tratar o colesterol alto, é ...\n",
            "Processing sentence 23/86: Além disso, é importante que você conheça seus níveis atuais...\n",
            "Processing sentence 24/86: Gravidez e Amamentação: se estiver grávida ou planeja engrav...\n",
            "  ✅ Found 1 entities\n",
            "Processing sentence 25/86: Se estiver amamentando, ezetimiba pode passar do seu leite p...\n",
            "  ✅ Found 2 entities\n",
            "Processing sentence 26/86: Este medicamento não deve ser utilizado por mulheres grávida...\n",
            "  ✅ Found 2 entities\n",
            "Processing sentence 27/86: Idosos: não há precauções especiais....\n",
            "Processing sentence 28/86: ezetimiba – VP06 Uso pediátrico: A ezetimiba não é recomenda...\n",
            "  ✅ Found 2 entities\n",
            "Processing sentence 29/86: Dirigir ou Operar Máquinas: foram relatados efeitos adversos...\n",
            "  ✅ Found 3 entities\n",
            "Processing sentence 30/86: As respostas individuais a ezetimiba podem variar (veja o it...\n",
            "Processing sentence 31/86: QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?...\n",
            "Processing sentence 32/86: Problemas Clínicos ou Alergias: informe ao seu médico quaisq...\n",
            "Processing sentence 33/86: Interações Medicamentosas: Você deve sempre informar seu méd...\n",
            "Processing sentence 34/86: Informe ao seu médico ou cirurgião-dentista se você está faz...\n",
            "Processing sentence 35/86: Não use medicamento sem o conhecimento do seu médico....\n",
            "  ✅ Found 2 entities\n",
            "Processing sentence 36/86: Pode ser perigoso para a sua saúde....\n",
            "Processing sentence 37/86: Esse medicamento não é recomendado para crianças com menos d...\n",
            "  ✅ Found 3 entities\n",
            "Processing sentence 38/86: 5. ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAME...\n",
            "  ✅ Found 1 entities\n",
            "Processing sentence 39/86: Mantenha em temperatura ambiente (temperatura entre 15 e 30º...\n",
            "Processing sentence 40/86: Proteger da umidade....\n",
            "Processing sentence 41/86: Número de lote e datas de fabricação e validade: vide embala...\n",
            "Processing sentence 42/86: Não use medicamento com o prazo de validade vencido....\n",
            "Processing sentence 43/86: Guarde-o em sua embalagem original....\n",
            "Processing sentence 44/86: Aparência: A ezetimiba é um comprimido oval branco a quase b...\n",
            "  ✅ Found 1 entities\n",
            "Processing sentence 45/86: Caso ele esteja no prazo de validade e você observe alguma m...\n",
            "Processing sentence 46/86: Todo medicamento deve ser mantido fora do alcance das crianç...\n",
            "Processing sentence 47/86: 6. COMO DEVO USAR ESTE MEDICAMENTO?...\n",
            "Processing sentence 48/86: Adultos e crianças acima de 6 anos de idade: Tome um comprim...\n",
            "  ✅ Found 3 entities\n",
            "Processing sentence 49/86: Seu médico pode ter falado para você tomar ezetimiba com out...\n",
            "  ✅ Found 3 entities\n",
            "Processing sentence 50/86: Se seu médico prescreveu ezetimiba com colestiramina (um seq...\n",
            "  ✅ Found 2 entities\n",
            "Processing sentence 51/86: A ezetimiba deve ser tomada conforme seu médico orientou....\n",
            "  ✅ Found 1 entities\n",
            "Processing sentence 52/86: Continue a tomar outros medicamentos redutores de colesterol...\n",
            "  ✅ Found 1 entities\n",
            "Processing sentence 53/86: Siga a orientação de seu médico, respeitando sempre os horár...\n",
            "Processing sentence 54/86: Não interrompa o tratamento sem o conhecimento do seu médico...\n",
            "Processing sentence 55/86: 7. O QUE DEVO FAZER QUANDO EU ME ESQUECER DE USAR ESTE MEDIC...\n",
            "  ✅ Found 1 entities\n",
            "Processing sentence 56/86: Tente tomar ezetimiba conforme prescrito....\n",
            "  ✅ Found 1 entities\n",
            "Processing sentence 57/86: Entretanto, se esquecer de tomar uma dose, reinicie o esquem...\n",
            "  ✅ Found 2 entities\n",
            "Processing sentence 58/86: 8. QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?...\n",
            "  ✅ Found 1 entities\n",
            "Processing sentence 59/86: Nos estudos clínicos, a ezetimiba foi em geral bem tolerada....\n",
            "  ✅ Found 1 entities\n",
            "Processing sentence 60/86: Os efeitos adversos geralmente foram leves e semelhantes em ...\n",
            "  ✅ Found 2 entities\n",
            "Processing sentence 61/86: Em geral, os efeitos adversos não provocaram a interrupção d...\n",
            "  ✅ Found 1 entities\n",
            "Processing sentence 62/86: Quando ezetimiba foi usada isoladamente, foram relatados os ...\n",
            "  ✅ Found 2 entities\n",
            "Processing sentence 63/86: Incomuns: elevações nos exames de sangue da função hepática ...\n",
            "  ✅ Found 2 entities\n",
            "Processing sentence 64/86: Além disso, quando tomado com uma estatina, foram relatados ...\n",
            "  ✅ Found 2 entities\n",
            "Processing sentence 65/86: Incomuns: sensação de formigamento; boca seca; coceira; erup...\n",
            "  ✅ Found 2 entities\n",
            "Processing sentence 66/86: Ao ser utilizado com fenofibratos, o seguinte efeito adverso...\n",
            "  ✅ Found 1 entities\n",
            "Processing sentence 67/86: Além disso, foram relatados os seguintes efeitos adversos no...\n",
            "JSON parse error for: {\n",
            "  \"entities\": [\n",
            "    {\"type\": \"side_effect\", \"value\": \"rea\\u00cdes al\\u00e9rgicas (que podem exigir...\n",
            "Processing sentence 68/86: ezetimiba – VP06 Procure seu médico imediatamente se sentir ...\n",
            "  ✅ Found 2 entities\n",
            "Processing sentence 69/86: Embora raramente, esses problemas musculares podem ser grave...\n",
            "  ✅ Found 2 entities\n",
            "Processing sentence 70/86: Se ezetimiba foi prescrita para ser tomado com uma estatina,...\n",
            "  ✅ Found 1 entities\n",
            "Processing sentence 71/86: Informe ao seu médico, cirurgião-dentista ou farmacêutico o ...\n",
            "Processing sentence 72/86: Informe também à empresa através do seu serviço de atendimen...\n",
            "Processing sentence 73/86: 9. O QUE FAZER SE ALGUÉM USAR UMA QUANTIDADE MAIOR DO QUE A ...\n",
            "  ✅ Found 1 entities\n",
            "Processing sentence 74/86: Tome ezetimiba apenas conforme prescrito....\n",
            "  ✅ Found 1 entities\n",
            "Processing sentence 75/86: Se tomar mais ezetimiba do que o prescrito, entre em contato...\n",
            "  ✅ Found 1 entities\n",
            "Processing sentence 76/86: Em caso de uso de grande quantidade deste medicamento, procu...\n",
            "Processing sentence 77/86: Ligue para 0800 722 6001, se você precisar de mais orientaçõ...\n",
            "Processing sentence 78/86: III) DIZERES LEGAIS VENDA SOB PRESCRIÇÃO MÉDICA Reg. M.S.: 1...\n",
            "Processing sentence 79/86: 0538 Farm. Resp.: Cláudia Larissa S. Montanher CRF-PR nº 17....\n",
            "Processing sentence 80/86: 379 Esta bula foi aprovada pela Anvisa em 21/07/2023....\n",
            "Processing sentence 81/86: Fabricado por: Lek Pharmaceuticals, d.d. Ljubljana - Eslovên...\n",
            "  ✅ Found 5 entities\n",
            "Processing sentence 82/86: 647/0001-16 Indústria Brasileira Ou Fabricado por: Lek Pharm...\n",
            "JSON parse error for: {\n",
            "  \"entities\": [\n",
            "    {\"type\": \"manufacturer\", \"value\": \"Lek Pharmaceuticals, d.d. Ljubljana - Eslov...\n",
            "Processing sentence 83/86: 647/0001-16 Indústria Brasileira ezetimiba – VP06 Histórico ...\n",
            "  ✅ Found 3 entities\n",
            "Processing sentence 84/86: RDC 60/12 -6....\n",
            "  ✅ Found 1 entities\n",
            "Processing sentence 85/86: Como devo usar este medicamento?...\n",
            "  ✅ Found 1 entities\n",
            "Processing sentence 86/86: Notificação de Inclusão de local de Alteração de 10 mg 15/04...\n",
            "  ✅ Found 2 entities\n",
            "✅ Completed analysis: 54/86 sentences with entities\n",
            "📊 Aggregating entities into structured format...\n",
            "❌ Error processing document: 'NoneType' object has no attribute 'strip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "neeewww"
      ],
      "metadata": {
        "id": "kZuBl25x3f-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Section-Aware Pharmaceutical Document Parser\n",
        "Processes documents sentence by sentence while tracking document sections/headers\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import re\n",
        "import subprocess\n",
        "import shlex\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "from datetime import datetime\n",
        "import pymupdf4llm\n",
        "import pdfplumber\n",
        "\n",
        "class SectionAwarePharmaParser:\n",
        "    def __init__(self, model_name: str = \"llama3:8b\"):\n",
        "        \"\"\"\n",
        "        Initialize section-aware parser with header tracking\n",
        "        \"\"\"\n",
        "        self.model_name = model_name\n",
        "        self.raw_content = \"\"\n",
        "        self.structured_data = {}\n",
        "        self.document_loaded = False\n",
        "\n",
        "        # Common pharmaceutical abbreviations that should NOT end sentences\n",
        "        self.pharma_abbreviations = {\n",
        "            'mg', 'ml', 'mcg', 'kg', 'g', 'l', 'dl', 'mmol', 'mol',  # Units\n",
        "            'q.s.p', 'c.q.s', 'q.s', 'c.s.p',  # Pharmaceutical Latin\n",
        "            'ltda', 'ltd', 'inc', 'corp', 'sa', 'co',  # Company abbreviations\n",
        "            'dr', 'dra', 'prof', 'sr', 'sra',  # Titles\n",
        "            'etc', 'ex', 'vs', 'e.g', 'i.e',  # Common abbreviations\n",
        "            'cnpj', 'cpf', 'rg', 'crf', 'crm',  # Brazilian document types\n",
        "            'anvisa', 'ms', 'rdc', 'vp', 'vps',  # Brazilian regulatory\n",
        "            'd.d', 'p.ex', 'n°', 'nº'  # Other common abbreviations\n",
        "        }\n",
        "\n",
        "        # Brazilian pharmaceutical document section patterns\n",
        "        self.section_patterns = {\n",
        "            # Primary numbered sections\n",
        "            r'^\\s*I+\\)\\s*(.+)$': 'primary_section',  # I), II), III)\n",
        "            r'^\\s*\\d+\\.\\s*(.+)$': 'numbered_section',  # 1., 2., 3.\n",
        "\n",
        "            # Common pharmaceutical sections\n",
        "            r'^\\s*(IDENTIFICAÇÃO|IDENTIFICACAO)\\s*(DO\\s*MEDICAMENTO)?\\s*$': 'identification',\n",
        "            r'^\\s*(INFORMAÇÕES|INFORMACOES)\\s*(AO\\s*PACIENTE)?\\s*$': 'patient_info',\n",
        "            r'^\\s*(COMPOSIÇÃO|COMPOSICAO)\\s*$': 'composition',\n",
        "            r'^\\s*(APRESENTAÇÕES|APRESENTACOES)\\s*$': 'presentations',\n",
        "            r'^\\s*(INDICAÇÕES|INDICACOES)\\s*$': 'indications',\n",
        "            r'^\\s*(CONTRAINDICAÇÕES|CONTRAINDICACOES)\\s*$': 'contraindications',\n",
        "            r'^\\s*(PRECAUÇÕES|PRECAUCOES)\\s*$': 'precautions',\n",
        "            r'^\\s*(REAÇÕES\\s*ADVERSAS|REACOES\\s*ADVERSAS|EFEITOS\\s*ADVERSOS)\\s*$': 'adverse_effects',\n",
        "            r'^\\s*(INTERAÇÕES|INTERACOES)\\s*(MEDICAMENTOSAS)?\\s*$': 'drug_interactions',\n",
        "            r'^\\s*(POSOLOGIA|DOSAGEM)\\s*$': 'dosage',\n",
        "            r'^\\s*(SUPERDOSAGEM|SUPERDOSE)\\s*$': 'overdose',\n",
        "            r'^\\s*ARMAZENAMENTO\\s*$': 'storage',\n",
        "            r'^\\s*DIZERES\\s*LEGAIS\\s*$': 'legal_info',\n",
        "\n",
        "            # Question-style headers\n",
        "            r'^\\s*\\d+\\.\\s*(PARA\\s*QUE|O\\s*QUE|COMO|QUANDO|ONDE|QUAIS)\\s*.*\\?\\s*$': 'question_header'\n",
        "        }\n",
        "\n",
        "        self.setup_ollama()\n",
        "\n",
        "    def setup_ollama(self):\n",
        "        \"\"\"Setup Ollama model automatically\"\"\"\n",
        "        print(f\"Setting up Ollama model: {self.model_name}\")\n",
        "        try:\n",
        "            subprocess.run([\"ollama\", \"--version\"], capture_output=True, check=True)\n",
        "            print(\"✅ Ollama CLI found\")\n",
        "        except (FileNotFoundError, subprocess.CalledProcessError):\n",
        "            raise RuntimeError(\"❌ Ollama CLI not found. Please install Ollama first.\")\n",
        "\n",
        "        try:\n",
        "            print(f\"Pulling model {self.model_name}...\")\n",
        "            result = subprocess.run(\n",
        "                [\"ollama\", \"pull\", self.model_name],\n",
        "                capture_output=True, text=True, timeout=300\n",
        "            )\n",
        "            if result.returncode == 0:\n",
        "                print(f\"✅ Model {self.model_name} ready\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error with model setup: {e}\")\n",
        "\n",
        "    def call_ollama_raw(self, prompt: str, extra_flags: str = \"\") -> str:\n",
        "        \"\"\"Call ollama with exact prompt\"\"\"\n",
        "        cmd = [\"ollama\", \"run\", self.model_name]\n",
        "        if extra_flags:\n",
        "            cmd += shlex.split(extra_flags)\n",
        "\n",
        "        try:\n",
        "            proc = subprocess.run(\n",
        "                cmd, input=prompt, text=True, capture_output=True, timeout=60\n",
        "            )\n",
        "            return proc.stdout.strip() or proc.stderr.strip()\n",
        "        except subprocess.TimeoutExpired:\n",
        "            raise RuntimeError(\"Ollama call timed out\")\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error calling ollama: {e}\")\n",
        "\n",
        "    def extract_pdf_content(self, pdf_path: str) -> str:\n",
        "        \"\"\"Extract text content from PDF\"\"\"\n",
        "        try:\n",
        "            with pdfplumber.open(pdf_path) as pdf:\n",
        "                all_text = []\n",
        "                for page in pdf.pages:\n",
        "                    page_text = page.extract_text()\n",
        "                    if page_text:\n",
        "                        all_text.append(page_text)\n",
        "                if all_text:\n",
        "                    return \"\\n\\n\".join(all_text)\n",
        "        except Exception as e:\n",
        "            print(f\"pdfplumber failed: {e}\")\n",
        "\n",
        "        try:\n",
        "            return pymupdf4llm.to_markdown(pdf_path)\n",
        "        except Exception as e:\n",
        "            print(f\"pymupdf4llm failed: {e}\")\n",
        "            raise Exception(\"All extraction methods failed\")\n",
        "\n",
        "    def detect_section_header(self, text: str) -> Tuple[Optional[str], Optional[str]]:\n",
        "        \"\"\"\n",
        "        Detect if text is a section header and return (section_type, section_title)\n",
        "        \"\"\"\n",
        "        text_clean = text.strip()\n",
        "\n",
        "        # Skip very short lines\n",
        "        if len(text_clean) < 3:\n",
        "            return None, None\n",
        "\n",
        "        # Check against section patterns\n",
        "        for pattern, section_type in self.section_patterns.items():\n",
        "            match = re.match(pattern, text_clean, re.IGNORECASE)\n",
        "            if match:\n",
        "                if section_type == 'primary_section' or section_type == 'numbered_section':\n",
        "                    section_title = match.group(1).strip()\n",
        "                else:\n",
        "                    section_title = text_clean\n",
        "                return section_type, section_title\n",
        "\n",
        "        # Check for all-caps headers (common in pharmaceutical docs)\n",
        "        if (text_clean.isupper() and\n",
        "            len(text_clean) > 5 and\n",
        "            len(text_clean) < 100 and\n",
        "            not re.search(r'\\d{2,}', text_clean)):  # Not just numbers\n",
        "            return 'caps_header', text_clean\n",
        "\n",
        "        return None, None\n",
        "\n",
        "    def is_likely_abbreviation(self, text: str) -> bool:\n",
        "        \"\"\"Check if text ending with period is likely an abbreviation\"\"\"\n",
        "        if not text or len(text) < 2:\n",
        "            return False\n",
        "\n",
        "        word = text.rstrip('.').lower()\n",
        "\n",
        "        if word in self.pharma_abbreviations:\n",
        "            return True\n",
        "\n",
        "        patterns = [\n",
        "            r'^[a-z]{1,4}$',  # Short lowercase words\n",
        "            r'^[A-Z]{2,6}$',  # All caps short words\n",
        "            r'^[A-Z][a-z]{1,3}$',  # Capitalized short words\n",
        "            r'^\\d+[a-z]+$',  # Numbers with letters\n",
        "            r'^[a-z]\\.[a-z]',  # Pattern like q.s.p\n",
        "            r'[0-9]$'  # Ends with number\n",
        "        ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            if re.match(pattern, word):\n",
        "                return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def smart_sentence_split_with_sections(self, text: str) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Split text into sentences with section awareness\n",
        "        Returns list of dicts with sentence and section info\n",
        "        \"\"\"\n",
        "        print(\"📋 Splitting text with section tracking...\")\n",
        "\n",
        "        # First split by lines to identify headers\n",
        "        lines = text.split('\\n')\n",
        "\n",
        "        current_section_type = 'unknown'\n",
        "        current_section_title = 'Document Start'\n",
        "        sentence_data = []\n",
        "        current_sentence = \"\"\n",
        "\n",
        "        for line_num, line in enumerate(lines):\n",
        "            line = line.strip()\n",
        "\n",
        "            if not line:  # Skip empty lines\n",
        "                continue\n",
        "\n",
        "            # Check if this line is a section header\n",
        "            section_type, section_title = self.detect_section_header(line)\n",
        "\n",
        "            if section_type and section_title:\n",
        "                # This is a header - finish current sentence if any\n",
        "                if current_sentence.strip():\n",
        "                    sentences = self._split_sentence_safely(current_sentence)\n",
        "                    for sent in sentences:\n",
        "                        if sent.strip() and len(sent.strip()) > 10:\n",
        "                            sentence_data.append({\n",
        "                                'sentence': sent.strip(),\n",
        "                                'section_type': current_section_type,\n",
        "                                'section_title': current_section_title,\n",
        "                                'line_number': line_num,\n",
        "                                'is_header': False\n",
        "                            })\n",
        "                    current_sentence = \"\"\n",
        "\n",
        "                # Update current section\n",
        "                current_section_type = section_type\n",
        "                current_section_title = section_title\n",
        "\n",
        "                # Add header as special sentence\n",
        "                sentence_data.append({\n",
        "                    'sentence': line,\n",
        "                    'section_type': section_type,\n",
        "                    'section_title': section_title,\n",
        "                    'line_number': line_num,\n",
        "                    'is_header': True\n",
        "                })\n",
        "\n",
        "                print(f\"📍 Section detected: {section_type} - {section_title}\")\n",
        "\n",
        "            else:\n",
        "                # Regular content line - add to current sentence\n",
        "                if current_sentence:\n",
        "                    current_sentence += \" \" + line\n",
        "                else:\n",
        "                    current_sentence = line\n",
        "\n",
        "        # Process any remaining sentence\n",
        "        if current_sentence.strip():\n",
        "            sentences = self._split_sentence_safely(current_sentence)\n",
        "            for sent in sentences:\n",
        "                if sent.strip() and len(sent.strip()) > 10:\n",
        "                    sentence_data.append({\n",
        "                        'sentence': sent.strip(),\n",
        "                        'section_type': current_section_type,\n",
        "                        'section_title': current_section_title,\n",
        "                        'line_number': len(lines),\n",
        "                        'is_header': False\n",
        "                    })\n",
        "\n",
        "        # Filter out headers from regular processing\n",
        "        content_sentences = [s for s in sentence_data if not s['is_header']]\n",
        "\n",
        "        print(f\"✅ Found {len(sentence_data)} total items ({len(content_sentences)} content sentences)\")\n",
        "        print(f\"📊 Sections identified: {len(set(s['section_title'] for s in sentence_data))}\")\n",
        "\n",
        "        return content_sentences\n",
        "\n",
        "    def _split_sentence_safely(self, text: str) -> List[str]:\n",
        "        \"\"\"Split text into sentences with abbreviation awareness\"\"\"\n",
        "        sentences = []\n",
        "        current_sentence = \"\"\n",
        "\n",
        "        # Split by potential sentence endings\n",
        "        parts = re.split(r'([.!?]+)', text)\n",
        "\n",
        "        i = 0\n",
        "        while i < len(parts):\n",
        "            if i % 2 == 0:  # Text part\n",
        "                current_sentence += parts[i]\n",
        "            else:  # Punctuation part\n",
        "                punctuation = parts[i]\n",
        "                current_sentence += punctuation\n",
        "\n",
        "                if '.' in punctuation:\n",
        "                    words = current_sentence.split()\n",
        "                    if words:\n",
        "                        last_word = words[-1]\n",
        "                        if not self.is_likely_abbreviation(last_word):\n",
        "                            if current_sentence.strip():\n",
        "                                sentences.append(current_sentence.strip())\n",
        "                            current_sentence = \"\"\n",
        "                    else:\n",
        "                        if current_sentence.strip():\n",
        "                            sentences.append(current_sentence.strip())\n",
        "                        current_sentence = \"\"\n",
        "                else:\n",
        "                    # ! or ? - definitely sentence endings\n",
        "                    if current_sentence.strip():\n",
        "                        sentences.append(current_sentence.strip())\n",
        "                    current_sentence = \"\"\n",
        "            i += 1\n",
        "\n",
        "        # Add any remaining sentence\n",
        "        if current_sentence.strip():\n",
        "            sentences.append(current_sentence.strip())\n",
        "\n",
        "        return [s for s in sentences if s.strip() and len(s.strip()) > 10]\n",
        "\n",
        "    def create_section_aware_prompt(self, sentence_data: Dict) -> str:\n",
        "        \"\"\"Create a prompt that includes section context\"\"\"\n",
        "        sentence = sentence_data['sentence']\n",
        "        section_type = sentence_data['section_type']\n",
        "        section_title = sentence_data['section_title']\n",
        "\n",
        "        prompt = f\"\"\"Analyze this sentence from a Brazilian pharmaceutical document. The sentence comes from the \"{section_title}\" section.\n",
        "\n",
        "RESPOND ONLY WITH VALID JSON. No explanations, no markdown.\n",
        "\n",
        "Context: This sentence is from the {section_type} section titled \"{section_title}\".\n",
        "\n",
        "Extract relevant pharmaceutical information considering the section context.\n",
        "\n",
        "Format:\n",
        "{{\n",
        "  \"entities\": [\n",
        "    {{\"type\": \"medication_name\", \"value\": \"...\", \"confidence\": \"high|medium|low\"}},\n",
        "    {{\"type\": \"dosage\", \"value\": \"...\", \"confidence\": \"high|medium|low\"}},\n",
        "    {{\"type\": \"indication\", \"value\": \"...\", \"confidence\": \"high|medium|low\"}},\n",
        "    {{\"type\": \"contraindication\", \"value\": \"...\", \"confidence\": \"high|medium|low\"}},\n",
        "    {{\"type\": \"side_effect\", \"value\": \"...\", \"confidence\": \"high|medium|low\"}},\n",
        "    {{\"type\": \"manufacturer\", \"value\": \"...\", \"confidence\": \"high|medium|low\"}},\n",
        "    {{\"type\": \"storage\", \"value\": \"...\", \"confidence\": \"high|medium|low\"}},\n",
        "    {{\"type\": \"administration\", \"value\": \"...\", \"confidence\": \"high|medium|low\"}}\n",
        "  ],\n",
        "  \"section_relevance\": \"high|medium|low\",\n",
        "  \"key_info_found\": true/false\n",
        "}}\n",
        "\n",
        "Sentence: \"{sentence}\"\n",
        "\n",
        "JSON:\"\"\"\n",
        "\n",
        "        return prompt\n",
        "\n",
        "    def parse_json_response(self, response: str) -> Any:\n",
        "        \"\"\"Enhanced JSON parsing with better error handling\"\"\"\n",
        "        if not response or not response.strip():\n",
        "            return None\n",
        "\n",
        "        cleaned = response.strip()\n",
        "\n",
        "        # Remove markdown code blocks\n",
        "        if \"```json\" in cleaned:\n",
        "            start = cleaned.find(\"```json\") + 7\n",
        "            end = cleaned.rfind(\"```\")\n",
        "            if start < end:\n",
        "                cleaned = cleaned[start:end].strip()\n",
        "        elif \"```\" in cleaned:\n",
        "            start = cleaned.find(\"```\") + 3\n",
        "            end = cleaned.rfind(\"```\")\n",
        "            if start < end:\n",
        "                cleaned = cleaned[start:end].strip()\n",
        "\n",
        "        # Find JSON boundaries\n",
        "        json_start = cleaned.find('{')\n",
        "        json_end = cleaned.rfind('}') + 1\n",
        "\n",
        "        if json_start != -1 and json_end > json_start:\n",
        "            cleaned = cleaned[json_start:json_end]\n",
        "\n",
        "        try:\n",
        "            return json.loads(cleaned)\n",
        "        except json.JSONDecodeError as e:\n",
        "            try:\n",
        "                # Fix common issues\n",
        "                fixed = re.sub(r',(\\s*[}\\]])', r'\\1', cleaned)\n",
        "                fixed = re.sub(r'(?<!\\\\)\"(?=[^,}\\]]*[,}\\]])', r'\\\\\"', fixed)\n",
        "                return json.loads(fixed)\n",
        "            except:\n",
        "                print(f\"JSON parse error: {cleaned[:100]}...\")\n",
        "                return None\n",
        "\n",
        "    def analyze_sentence_with_context(self, sentence_data: Dict, index: int) -> Dict:\n",
        "        \"\"\"Analyze a sentence with section context\"\"\"\n",
        "        try:\n",
        "            prompt = self.create_section_aware_prompt(sentence_data)\n",
        "            response = self.call_ollama_raw(prompt)\n",
        "\n",
        "            result = self.parse_json_response(response)\n",
        "\n",
        "            if result and isinstance(result, dict):\n",
        "                # Add metadata with null checks\n",
        "                result['sentence_index'] = index\n",
        "                result['original_sentence'] = sentence_data.get('sentence', '')\n",
        "                result['section_type'] = sentence_data.get('section_type', 'unknown')\n",
        "                result['section_title'] = sentence_data.get('section_title', 'Unknown Section')\n",
        "                result['line_number'] = sentence_data.get('line_number', 0)\n",
        "                return result\n",
        "            else:\n",
        "                return self._create_empty_result(sentence_data, index, 'parsing_error')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error analyzing sentence {index}: {e}\")\n",
        "            return self._create_empty_result(sentence_data, index, f'analysis_error: {e}')\n",
        "\n",
        "    def _create_empty_result(self, sentence_data: Dict, index: int, error_type: str = None) -> Dict:\n",
        "        \"\"\"Create empty result structure with safe defaults\"\"\"\n",
        "        return {\n",
        "            'entities': [],\n",
        "            'section_relevance': 'low',\n",
        "            'key_info_found': False,\n",
        "            'sentence_index': index,\n",
        "            'original_sentence': sentence_data.get('sentence', ''),\n",
        "            'section_type': sentence_data.get('section_type', 'unknown'),\n",
        "            'section_title': sentence_data.get('section_title', 'Unknown Section'),\n",
        "            'line_number': sentence_data.get('line_number', 0),\n",
        "            'error': error_type\n",
        "        }\n",
        "\n",
        "    def process_sentences_with_context(self, sentence_data_list: List[Dict]) -> List[Dict]:\n",
        "        \"\"\"Process all sentences with section context\"\"\"\n",
        "        print(f\"🔍 Analyzing {len(sentence_data_list)} sentences with section context...\")\n",
        "\n",
        "        analyses = []\n",
        "        successful_analyses = 0\n",
        "\n",
        "        for i, sentence_data in enumerate(sentence_data_list):\n",
        "            sentence = sentence_data.get('sentence', '')[:60]\n",
        "            section = sentence_data.get('section_title', 'Unknown')\n",
        "\n",
        "            print(f\"Processing {i+1}/{len(sentence_data_list)} in [{section}]: {sentence}...\")\n",
        "\n",
        "            analysis = self.analyze_sentence_with_context(sentence_data, i)\n",
        "            analyses.append(analysis)\n",
        "\n",
        "            if analysis.get('key_info_found') and not analysis.get('error'):\n",
        "                successful_analyses += 1\n",
        "                entity_count = len(analysis.get('entities', []))\n",
        "                if entity_count > 0:\n",
        "                    print(f\"  ✅ Found {entity_count} entities\")\n",
        "\n",
        "            import time\n",
        "            time.sleep(0.1)\n",
        "\n",
        "        print(f\"✅ Completed analysis: {successful_analyses}/{len(sentence_data_list)} sentences with entities\")\n",
        "        return analyses\n",
        "\n",
        "    def aggregate_entities_by_section(self, analyses: List[Dict]) -> Dict:\n",
        "        \"\"\"Aggregate entities by section with null-safe processing\"\"\"\n",
        "        print(\"📊 Aggregating entities by section...\")\n",
        "\n",
        "        section_entities = {}\n",
        "        all_entities = []\n",
        "        section_stats = {}\n",
        "\n",
        "        for analysis in analyses:\n",
        "            if not analysis or analysis.get('error'):\n",
        "                continue\n",
        "\n",
        "            section_title = analysis.get('section_title', 'Unknown Section')\n",
        "\n",
        "            # Initialize section if not exists\n",
        "            if section_title not in section_entities:\n",
        "                section_entities[section_title] = {\n",
        "                    'medication_names': set(), 'dosages': set(), 'indications': set(),\n",
        "                    'contraindications': set(), 'side_effects': set(), 'manufacturers': set(),\n",
        "                    'storage_conditions': set(), 'administration_info': set()\n",
        "                }\n",
        "                section_stats[section_title] = {'sentences': 0, 'entities': 0}\n",
        "\n",
        "            section_stats[section_title]['sentences'] += 1\n",
        "\n",
        "            entities = analysis.get('entities', [])\n",
        "            if not entities:\n",
        "                continue\n",
        "\n",
        "            section_stats[section_title]['entities'] += len(entities)\n",
        "\n",
        "            for entity in entities:\n",
        "                # --- START: FIX ---\n",
        "                # 1. Check if the entity is a valid dictionary\n",
        "                if not isinstance(entity, dict):\n",
        "                    continue\n",
        "\n",
        "                # 2. Get the type and value, which could be None\n",
        "                entity_type = entity.get('type')\n",
        "                entity_value = entity.get('value')\n",
        "\n",
        "                # 3. Ensure both type and value are not None or empty before stripping\n",
        "                if not entity_type or not entity_value:\n",
        "                    continue\n",
        "\n",
        "                entity_type = entity_type.strip()\n",
        "                entity_value = str(entity_value).strip() # Convert to string to be safe\n",
        "                # --- END: FIX ---\n",
        "\n",
        "                type_mapping = {\n",
        "                    'medication_name': 'medication_names', 'dosage': 'dosages',\n",
        "                    'indication': 'indications', 'contraindication': 'contraindications',\n",
        "                    'side_effect': 'side_effects', 'manufacturer': 'manufacturers',\n",
        "                    'storage': 'storage_conditions', 'administration': 'administration_info'\n",
        "                }\n",
        "\n",
        "                if entity_type in type_mapping:\n",
        "                    collection_key = type_mapping[entity_type]\n",
        "                    section_entities[section_title][collection_key].add(entity_value)\n",
        "\n",
        "                    all_entities.append({\n",
        "                        'type': entity_type, 'value': entity_value,\n",
        "                        'section': section_title,\n",
        "                        'confidence': entity.get('confidence', 'medium'),\n",
        "                        'sentence_index': analysis.get('sentence_index', -1)\n",
        "                    })\n",
        "\n",
        "        # Convert sets to lists for JSON serialization\n",
        "        for section in section_entities:\n",
        "            for entity_type in section_entities[section]:\n",
        "                section_entities[section][entity_type] = list(section_entities[section][entity_type])\n",
        "\n",
        "        result = {\n",
        "            'entities_by_section': section_entities, 'all_entities': all_entities,\n",
        "            'section_statistics': section_stats, 'total_entities': len(all_entities),\n",
        "            'sections_processed': len(section_entities)\n",
        "        }\n",
        "\n",
        "        print(f\"✅ Aggregated {len(all_entities)} entities across {len(section_entities)} sections\")\n",
        "        return result\n",
        "\n",
        "    def process_document(self, pdf_path: str) -> bool:\n",
        "        \"\"\"Main document processing with section awareness\"\"\"\n",
        "        print(f\"📄 Processing document with section-aware analysis: {pdf_path}\")\n",
        "\n",
        "        if not Path(pdf_path).exists():\n",
        "            print(f\"❌ File not found: {pdf_path}\")\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            # Extract text\n",
        "            print(\"📖 Extracting text from PDF...\")\n",
        "            self.raw_content = self.extract_pdf_content(pdf_path)\n",
        "\n",
        "            if not self.raw_content:\n",
        "                print(\"❌ No text content extracted\")\n",
        "                return False\n",
        "\n",
        "            print(f\"✅ Extracted {len(self.raw_content)} characters\")\n",
        "\n",
        "            # Split with section awareness\n",
        "            sentence_data_list = self.smart_sentence_split_with_sections(self.raw_content)\n",
        "\n",
        "            # Process sentences with context\n",
        "            analyses = self.process_sentences_with_context(sentence_data_list)\n",
        "\n",
        "            # Aggregate by sections\n",
        "            aggregated_data = self.aggregate_entities_by_section(analyses)\n",
        "\n",
        "            # Compile results\n",
        "            self.structured_data = {\n",
        "                \"metadata\": {\n",
        "                    \"file_path\": pdf_path,\n",
        "                    \"file_name\": Path(pdf_path).name,\n",
        "                    \"processing_date\": datetime.now().isoformat(),\n",
        "                    \"total_text_length\": len(self.raw_content),\n",
        "                    \"model_used\": self.model_name,\n",
        "                    \"extraction_method\": \"section_aware_sentence_analysis\"\n",
        "                },\n",
        "                \"sentence_analyses\": analyses,\n",
        "                \"section_entities\": aggregated_data,\n",
        "                \"processing_statistics\": {\n",
        "                    \"total_sentences\": len(sentence_data_list),\n",
        "                    \"sentences_with_entities\": len([a for a in analyses if a.get('key_info_found')]),\n",
        "                    \"total_entities_found\": aggregated_data.get('total_entities', 0),\n",
        "                    \"sections_identified\": aggregated_data.get('sections_processed', 0)\n",
        "                }\n",
        "            }\n",
        "\n",
        "            self.document_loaded = True\n",
        "            print(\"✅ Section-aware document processing completed!\")\n",
        "            self._show_processing_summary()\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error processing document: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return False\n",
        "\n",
        "    def _show_processing_summary(self):\n",
        "        \"\"\"Show processing summary with section information\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"📊 SECTION-AWARE PROCESSING SUMMARY\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        metadata = self.structured_data.get(\"metadata\", {})\n",
        "        stats = self.structured_data.get(\"processing_statistics\", {})\n",
        "        section_data = self.structured_data.get(\"section_entities\", {})\n",
        "\n",
        "        print(f\"📁 File: {metadata.get('file_name', 'Unknown')}\")\n",
        "        print(f\"📝 Text length: {metadata.get('total_text_length', 0):,} characters\")\n",
        "        print(f\"✂️ Total sentences: {stats.get('total_sentences', 0)}\")\n",
        "        print(f\"🏷️ Sentences with entities: {stats.get('sentences_with_entities', 0)}\")\n",
        "        print(f\"🔢 Total entities found: {stats.get('total_entities_found', 0)}\")\n",
        "        print(f\"📋 Sections identified: {stats.get('sections_identified', 0)}\")\n",
        "\n",
        "        # Show section statistics\n",
        "        section_stats = section_data.get('section_statistics', {})\n",
        "        if section_stats:\n",
        "            print(f\"\\n📊 Entity Distribution by Section:\")\n",
        "            for section, stat in section_stats.items():\n",
        "                print(f\"   {section}: {stat['entities']} entities from {stat['sentences']} sentences\")\n",
        "\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "    def save_results(self, output_path: Optional[str] = None) -> str:\n",
        "        \"\"\"Save processing results\"\"\"\n",
        "        if not self.document_loaded:\n",
        "            raise Exception(\"No document processed\")\n",
        "\n",
        "        if not output_path:\n",
        "            file_name = self.structured_data[\"metadata\"][\"file_name\"]\n",
        "            pdf_name = Path(file_name).stem\n",
        "            output_path = f\"{pdf_name}_section_aware_analysis.json\"\n",
        "\n",
        "        output_file = Path(output_path)\n",
        "        with open(output_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(self.structured_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"\\n📄 Results saved to: {output_file}\")\n",
        "        print(f\"📊 File size: {output_file.stat().st_size:,} bytes\")\n",
        "        return str(output_file)\n",
        "\n",
        "    def query_document(self, question: str) -> str:\n",
        "        \"\"\"Query with section context\"\"\"\n",
        "        if not self.document_loaded:\n",
        "            return \"❌ No document processed.\"\n",
        "\n",
        "        section_entities = self.structured_data.get(\"section_entities\", {}).get(\"entities_by_section\", {})\n",
        "\n",
        "        context_parts = [\"MEDICATION INFORMATION BY SECTION:\\n\"]\n",
        "\n",
        "        for section, entities in section_entities.items():\n",
        "            if any(entities.values()):  # Only show sections with entities\n",
        "                context_parts.append(f\"[{section}]\")\n",
        "                for entity_type, values in entities.items():\n",
        "                    if values:\n",
        "                        context_parts.append(f\"  {entity_type}: {', '.join(values[:3])}\")\n",
        "                context_parts.append(\"\")\n",
        "\n",
        "        context = \"\\n\".join(context_parts)\n",
        "\n",
        "        query_prompt = f\"\"\"Answer about this medication based on the section-organized information.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Available Information:\n",
        "{context[:4000]}\n",
        "\n",
        "Provide a clear answer in Portuguese, mentioning the relevant sections when appropriate.\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.call_ollama_raw(query_prompt)\n",
        "            return response.strip() if response else \"No response received\"\n",
        "        except Exception as e:\n",
        "            return f\"❌ Error: {e}\"\n",
        "\n",
        "def main():\n",
        "    \"\"\"Demonstrate section-aware processing\"\"\"\n",
        "    parser = SectionAwarePharmaParser(model_name=\"llama3:8b\")\n",
        "\n",
        "    pdf_path = \"bula_1755192077396.pdf\"\n",
        "\n",
        "    print(\"🎯 Section-Aware Pharmaceutical Document Parser\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    if parser.process_document(pdf_path):\n",
        "        results_file = parser.save_results()\n",
        "\n",
        "        print(f\"\\n🔍 Testing section-aware querying...\")\n",
        "        test_questions = [\n",
        "            \"Qual é o nome do medicamento e sua concentração?\",\n",
        "            \"Quais são as contraindicações principais?\",\n",
        "            \"Como deve ser administrado?\",\n",
        "            \"Quais são os efeitos adversos mais comuns?\",\n",
        "            \"Quem é o fabricante?\"\n",
        "        ]\n",
        "\n",
        "        for question in test_questions:\n",
        "            print(f\"\\n❓ {question}\")\n",
        "            answer = parser.query_document(question)\n",
        "            print(f\"💡 {answer}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUhvJFf73fqP",
        "outputId": "7901c379-a0af-43d9-c9ab-0f446a8f3f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up Ollama model: llama3.2:3b\n",
            "✅ Ollama CLI found\n",
            "Pulling model llama3.2:3b...\n",
            "✅ Model llama3.2:3b ready\n",
            "🎯 Section-Aware Pharmaceutical Document Parser\n",
            "======================================================================\n",
            "📄 Processing document with section-aware analysis: bula_1755192077396.pdf\n",
            "📖 Extracting text from PDF...\n",
            "✅ Extracted 11936 characters\n",
            "📋 Splitting text with section tracking...\n",
            "📍 Section detected: primary_section - IDENTIFICAÇÃO DO MEDICAMENTO\n",
            "📍 Section detected: presentations - APRESENTAÇÕES\n",
            "📍 Section detected: caps_header - USO ORAL\n",
            "📍 Section detected: caps_header - USO ADULTO E PEDIÁTRICO ACIMA DE 6 ANOS DE IDADE\n",
            "📍 Section detected: composition - COMPOSIÇÃO\n",
            "📍 Section detected: primary_section - INFORMAÇÕES AO PACIENTE\n",
            "📍 Section detected: numbered_section - PARA QUE ESTE MEDICAMENTO É INDICADO?\n",
            "📍 Section detected: numbered_section - COMO ESTE MEDICAMENTO FUNCIONA?\n",
            "📍 Section detected: numbered_section - QUANDO NÃO DEVO USAR ESTE MEDICAMENTO?\n",
            "📍 Section detected: numbered_section - O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO?\n",
            "📍 Section detected: caps_header - QUE ESTE MEDICAMENTO PODE ME CAUSAR? ”).\n",
            "📍 Section detected: numbered_section - ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAMENTO?\n",
            "📍 Section detected: numbered_section - COMO DEVO USAR ESTE MEDICAMENTO?\n",
            "📍 Section detected: numbered_section - O QUE DEVO FAZER QUANDO EU ME ESQUECER DE USAR ESTE MEDICAMENTO?\n",
            "📍 Section detected: numbered_section - QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?\n",
            "📍 Section detected: numbered_section - O QUE FAZER SE ALGUÉM USAR UMA QUANTIDADE MAIOR DO QUE A INDICADA DESTE\n",
            "📍 Section detected: caps_header - MEDICAMENTO?\n",
            "📍 Section detected: primary_section - DIZERES LEGAIS\n",
            "📍 Section detected: caps_header - VENDA SOB PRESCRIÇÃO MÉDICA\n",
            "✅ Found 99 total items (80 content sentences)\n",
            "📊 Sections identified: 20\n",
            "🔍 Analyzing 80 sentences with section context...\n",
            "Processing 1/80 in [Document Start]: ezetimiba Sandoz do Brasil Ind. Farm. Ltda. Bula do Paciente...\n",
            "  ✅ Found 3 entities\n",
            "Processing 2/80 in [IDENTIFICAÇÃO DO MEDICAMENTO]: ezetimiba Medicamento genérico, Lei nº 9.787, de 1999...\n",
            "  ✅ Found 3 entities\n",
            "Processing 3/80 in [APRESENTAÇÕES]: ezetimiba comprimido 10 mg. Embalagem contendo 30 ou 60 comp...\n",
            "  ✅ Found 4 entities\n",
            "Processing 4/80 in [COMPOSIÇÃO]: Cada comprimido de 10 mg contém: ezetimiba.....................\n",
            "  ✅ Found 2 entities\n",
            "Processing 5/80 in [COMPOSIÇÃO]: 10 mg excipientes q.s.p. ....................\n",
            "  ✅ Found 2 entities\n",
            "Processing 6/80 in [COMPOSIÇÃO]: 1 comprimido (lactose monoidratada, hipromelose, croscarmelo...\n",
            "Processing 7/80 in [PARA QUE ESTE MEDICAMENTO É INDICADO?]: A ezetimiba é indicada para reduzir a quantidade de colester...\n",
            "  ✅ Found 3 entities\n",
            "Processing 8/80 in [PARA QUE ESTE MEDICAMENTO É INDICADO?]: O colesterol é uma das várias substâncias gordurosas encontr...\n",
            "Processing 9/80 in [PARA QUE ESTE MEDICAMENTO É INDICADO?]: O colesterol total é composto principalmente de colesterol L...\n",
            "Processing 10/80 in [PARA QUE ESTE MEDICAMENTO É INDICADO?]: Eventualmente, essas placas podem causar estreitamento das a...\n",
            "  ✅ Found 3 entities\n",
            "Processing 11/80 in [PARA QUE ESTE MEDICAMENTO É INDICADO?]: Esse bloqueio ao fluxo sanguíneo pode causar ataque cardíaco...\n",
            "  ✅ Found 2 entities\n",
            "Processing 12/80 in [PARA QUE ESTE MEDICAMENTO É INDICADO?]: O colesterol HDL, por sua vez, é frequentemente chamado de “...\n",
            "Processing 13/80 in [PARA QUE ESTE MEDICAMENTO É INDICADO?]: Outra forma de gordura no sangue que pode aumentar o risco d...\n",
            "  ✅ Found 8 entities\n",
            "Processing 14/80 in [PARA QUE ESTE MEDICAMENTO É INDICADO?]: Se você tem sitosterolemia, seu médico prescreveu ezetimiba ...\n",
            "  ✅ Found 9 entities\n",
            "Processing 15/80 in [COMO ESTE MEDICAMENTO FUNCIONA?]: A ezetimiba age ao reduzir a absorção do colesterol no intes...\n",
            "  ✅ Found 8 entities\n",
            "Processing 16/80 in [COMO ESTE MEDICAMENTO FUNCIONA?]: Portanto, ezetimiba aumenta o efeito redutor do colesterol d...\n",
            "JSON parse error: {\n",
            "  \"entities\": [\n",
            "    {\"type\": \"medication_name\", \"value\": \"ezetimiba\", \"confidence\": \"high\"},\n",
            "    {...\n",
            "Processing 17/80 in [COMO ESTE MEDICAMENTO FUNCIONA?]: O colesterol alto pode ser tratado de duas formas principais...\n",
            "  ✅ Found 8 entities\n",
            "Processing 18/80 in [COMO ESTE MEDICAMENTO FUNCIONA?]: Seu médico prescreveu ezetimiba para ajudar a reduzir o seu ...\n",
            "  ✅ Found 3 entities\n",
            "Processing 19/80 in [QUANDO NÃO DEVO USAR ESTE MEDICAMENTO?]: Pacientes com hipersensibilidade (alérgicos) a ezetimiba ou ...\n",
            "JSON parse error: {\n",
            "  \"entities\": [\n",
            "    {\"type\": \"contraindication\", \"value\": \"Hipersensibilidade (al\\u00e9rgico) a ez...\n",
            "Processing 20/80 in [O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO?]: É importante que continue a tomar ezetimiba diariamente conf...\n",
            "  ✅ Found 3 entities\n",
            "Processing 21/80 in [O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO?]: Mesmo tomando medicamentos para tratar o colesterol alto, é ...\n",
            "  ✅ Found 8 entities\n",
            "Processing 22/80 in [O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO?]: Além disso, é importante que você conheça seus níveis atuais...\n",
            "Processing 23/80 in [O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO?]: Gravidez e Amamentação: se estiver grávida ou planeja engrav...\n",
            "Processing 24/80 in [O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO?]: Se estiver amamentando, ezetimiba pode passar do seu leite p...\n",
            "  ✅ Found 3 entities\n",
            "Processing 25/80 in [O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO?]: Este medicamento não deve ser utilizado por mulheres grávida...\n",
            "  ✅ Found 2 entities\n",
            "Processing 26/80 in [O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO?]: Idosos: não há precauções especiais....\n",
            "  ✅ Found 2 entities\n",
            "Processing 27/80 in [O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO?]: ezetimiba – VP06 Uso pediátrico: A ezetimiba não é recomenda...\n",
            "JSON parse error: {\n",
            "  \"entities\": [\n",
            "    {\"type\": \"medication_name\", \"value\": \"ezetimiba\", \"confidence\": \"high\"},\n",
            "    {...\n",
            "Processing 28/80 in [O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO?]: Dirigir ou Operar Máquinas: foram relatados efeitos adversos...\n",
            "  ✅ Found 2 entities\n",
            "Processing 29/80 in [O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO?]: As respostas individuais a ezetimiba podem variar (veja o it...\n",
            "Processing 30/80 in [O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO?]: QUAIS OS MALES...\n",
            "Processing 31/80 in [QUE ESTE MEDICAMENTO PODE ME CAUSAR? ”).]: Problemas Clínicos ou Alergias: informe ao seu médico quaisq...\n",
            "Processing 32/80 in [QUE ESTE MEDICAMENTO PODE ME CAUSAR? ”).]: Interações Medicamentosas: Você deve sempre informar seu méd...\n",
            "  ✅ Found 8 entities\n",
            "Processing 33/80 in [QUE ESTE MEDICAMENTO PODE ME CAUSAR? ”).]: Informe ao seu médico ou cirurgião-dentista se você está faz...\n",
            "  ✅ Found 1 entities\n",
            "Processing 34/80 in [QUE ESTE MEDICAMENTO PODE ME CAUSAR? ”).]: Não use medicamento sem o conhecimento do seu médico....\n",
            "Processing 35/80 in [QUE ESTE MEDICAMENTO PODE ME CAUSAR? ”).]: Pode ser perigoso para a sua saúde....\n",
            "Processing 36/80 in [QUE ESTE MEDICAMENTO PODE ME CAUSAR? ”).]: Esse medicamento não é recomendado para crianças com menos d...\n",
            "  ✅ Found 4 entities\n",
            "Processing 37/80 in [ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAMENTO?]: Mantenha em temperatura ambiente (temperatura entre 15 e 30º...\n",
            "  ✅ Found 1 entities\n",
            "Processing 38/80 in [ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAMENTO?]: Proteger da umidade....\n",
            "  ✅ Found 1 entities\n",
            "Processing 39/80 in [ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAMENTO?]: Número de lote e datas de fabricação e validade: vide embala...\n",
            "  ✅ Found 1 entities\n",
            "Processing 40/80 in [ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAMENTO?]: Não use medicamento com o prazo de validade vencido....\n",
            "  ✅ Found 1 entities\n",
            "Processing 41/80 in [ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAMENTO?]: Guarde-o em sua embalagem original....\n",
            "  ✅ Found 1 entities\n",
            "Processing 42/80 in [ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAMENTO?]: Aparência: A ezetimiba é um comprimido oval branco a quase b...\n",
            "JSON parse error: {\n",
            "  \"entities\": [\n",
            "    {\"type\": \"medication_name\", \"value\": \"ezetimiba\", \"confidence\": \"high\"},\n",
            "    {...\n",
            "Processing 43/80 in [ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAMENTO?]: Caso ele esteja no prazo de validade e você observe alguma m...\n",
            "  ✅ Found 2 entities\n",
            "Processing 44/80 in [ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAMENTO?]: Todo medicamento deve ser mantido fora do alcance das crianç...\n",
            "  ✅ Found 2 entities\n",
            "Processing 45/80 in [COMO DEVO USAR ESTE MEDICAMENTO?]: Adultos e crianças acima de 6 anos de idade: Tome um comprim...\n",
            "JSON parse error: {\n",
            "  \"entities\": [\n",
            "    {\"type\": \"medication_name\", \"value\": \"ezetimiba\", \"confidence\": \"high\"},\n",
            "    {...\n",
            "Processing 46/80 in [COMO DEVO USAR ESTE MEDICAMENTO?]: Seu médico pode ter falado para você tomar ezetimiba com out...\n",
            "  ✅ Found 5 entities\n",
            "Processing 47/80 in [COMO DEVO USAR ESTE MEDICAMENTO?]: Se seu médico prescreveu ezetimiba com colestiramina (um seq...\n",
            "  ✅ Found 9 entities\n",
            "Processing 48/80 in [COMO DEVO USAR ESTE MEDICAMENTO?]: A ezetimiba deve ser tomada conforme seu médico orientou....\n",
            "  ✅ Found 8 entities\n",
            "Processing 49/80 in [COMO DEVO USAR ESTE MEDICAMENTO?]: Continue a tomar outros medicamentos redutores de colesterol...\n",
            "  ✅ Found 2 entities\n",
            "Processing 50/80 in [COMO DEVO USAR ESTE MEDICAMENTO?]: Siga a orientação de seu médico, respeitando sempre os horár...\n",
            "  ✅ Found 8 entities\n",
            "Processing 51/80 in [COMO DEVO USAR ESTE MEDICAMENTO?]: Não interrompa o tratamento sem o conhecimento do seu médico...\n",
            "  ✅ Found 2 entities\n",
            "Processing 52/80 in [O QUE DEVO FAZER QUANDO EU ME ESQUECER DE USAR ESTE MEDICAMENTO?]: Tente tomar ezetimiba conforme prescrito....\n",
            "  ✅ Found 8 entities\n",
            "Processing 53/80 in [O QUE DEVO FAZER QUANDO EU ME ESQUECER DE USAR ESTE MEDICAMENTO?]: Entretanto, se esquecer de tomar uma dose, reinicie o esquem...\n",
            "  ✅ Found 7 entities\n",
            "Processing 54/80 in [QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?]: Nos estudos clínicos, a ezetimiba foi em geral bem tolerada....\n",
            "  ✅ Found 8 entities\n",
            "Processing 55/80 in [QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?]: Os efeitos adversos geralmente foram leves e semelhantes em ...\n",
            "  ✅ Found 2 entities\n",
            "Processing 56/80 in [QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?]: Em geral, os efeitos adversos não provocaram a interrupção d...\n",
            "  ✅ Found 3 entities\n",
            "Processing 57/80 in [QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?]: Quando ezetimiba foi usada isoladamente, foram relatados os ...\n",
            "  ✅ Found 2 entities\n",
            "Processing 58/80 in [QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?]: Incomuns: elevações nos exames de sangue da função hepática ...\n",
            "JSON parse error: {\n",
            "  \"entities\": [\n",
            "    {\"type\": \"side_effect\", \"value\": \"elev\\u00e1o nas transaminases, CK, tosse, in...\n",
            "Processing 59/80 in [QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?]: Além disso, quando tomado com uma estatina, foram relatados ...\n",
            "JSON parse error: {\n",
            "  \"entities\": [\n",
            "    {\"type\": \"side_effect\", \"value\": \"elev\\u00e3ncias nos exames de sangue da fun\\...\n",
            "Processing 60/80 in [QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?]: Incomuns: sensação de formigamento; boca seca; coceira; erup...\n",
            "JSON parse error: {\n",
            "  \"entities\": [\n",
            "    {\"type\": \"side_effect\", \"value\": \"sens\\u00e1o de formigamento; boca seca; coce...\n",
            "Processing 61/80 in [QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?]: Ao ser utilizado com fenofibratos, o seguinte efeito adverso...\n",
            "  ✅ Found 2 entities\n",
            "Processing 62/80 in [QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?]: Além disso, foram relatados os seguintes efeitos adversos no...\n",
            "  ✅ Found 14 entities\n",
            "Processing 63/80 in [QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?]: ezetimiba – VP06 Procure seu médico imediatamente se sentir ...\n",
            "  ✅ Found 2 entities\n",
            "Processing 64/80 in [QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?]: Embora raramente, esses problemas musculares podem ser grave...\n",
            "JSON parse error: {\"entities\": [{\"type\": \"side_effect\", \"value\": \"Problemas musculares graves, destr\\u00fao do m\\u00eu...\n",
            "Processing 65/80 in [QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?]: Se ezetimiba foi prescrita para ser tomado com uma estatina,...\n",
            "  ✅ Found 8 entities\n",
            "Processing 66/80 in [QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?]: Informe ao seu médico, cirurgião-dentista ou farmacêutico o ...\n",
            "JSON parse error: {\n",
            "  \"entities\": [\n",
            "    {\"type\": \"side_effect\", \"value\": \"re\\u00e1oes indesej\\u00e3veis\", \"confidence\"...\n",
            "Processing 67/80 in [QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?]: Informe também à empresa através do seu serviço de atendimen...\n",
            "Processing 68/80 in [MEDICAMENTO?]: Tome ezetimiba apenas conforme prescrito....\n",
            "Processing 69/80 in [MEDICAMENTO?]: Se tomar mais ezetimiba do que o prescrito, entre em contato...\n",
            "  ✅ Found 4 entities\n",
            "Processing 70/80 in [MEDICAMENTO?]: Em caso de uso de grande quantidade deste medicamento, procu...\n",
            "  ✅ Found 7 entities\n",
            "Processing 71/80 in [MEDICAMENTO?]: Ligue para 0800 722 6001, se você precisar de mais orientaçõ...\n",
            "Processing 72/80 in [VENDA SOB PRESCRIÇÃO MÉDICA]: Reg. M.S.: 1.0047....\n",
            "  ✅ Found 1 entities\n",
            "Processing 73/80 in [VENDA SOB PRESCRIÇÃO MÉDICA]: 0538 Farm. Resp.: Cláudia Larissa S. Montanher CRF-PR nº 17....\n",
            "  ✅ Found 2 entities\n",
            "Processing 74/80 in [VENDA SOB PRESCRIÇÃO MÉDICA]: 379 Esta bula foi aprovada pela Anvisa em 21/07/2023....\n",
            "  ✅ Found 2 entities\n",
            "Processing 75/80 in [VENDA SOB PRESCRIÇÃO MÉDICA]: Fabricado por: Lek Pharmaceuticals, d.d. Ljubljana - Eslovên...\n",
            "JSON parse error: {\n",
            "  \"entities\": [\n",
            "    {\"type\": \"manufacturer\", \"value\": \"Lek Pharmaceuticals, d.d. Ljubljana - Eslov...\n",
            "Processing 76/80 in [VENDA SOB PRESCRIÇÃO MÉDICA]: 647/0001-16 Indústria Brasileira Ou Fabricado por: Lek Pharm...\n",
            "  ✅ Found 4 entities\n",
            "Processing 77/80 in [VENDA SOB PRESCRIÇÃO MÉDICA]: 647/0001-16 Indústria Brasileira ezetimiba – VP06 Histórico ...\n",
            "  ✅ Found 2 entities\n",
            "Processing 78/80 in [VENDA SOB PRESCRIÇÃO MÉDICA]: RDC 60/12 -6....\n",
            "  ✅ Found 2 entities\n",
            "Processing 79/80 in [VENDA SOB PRESCRIÇÃO MÉDICA]: Como devo usar este medicamento?...\n",
            "Processing 80/80 in [VENDA SOB PRESCRIÇÃO MÉDICA]: Notificação de Inclusão de local de Alteração de 10 mg 15/04...\n",
            "  ✅ Found 8 entities\n",
            "✅ Completed analysis: 54/80 sentences with entities\n",
            "📊 Aggregating entities by section...\n",
            "✅ Aggregated 158 entities across 14 sections\n",
            "✅ Section-aware document processing completed!\n",
            "\n",
            "======================================================================\n",
            "📊 SECTION-AWARE PROCESSING SUMMARY\n",
            "======================================================================\n",
            "📁 File: bula_1755192077396.pdf\n",
            "📝 Text length: 11,936 characters\n",
            "✂️ Total sentences: 80\n",
            "🏷️ Sentences with entities: 54\n",
            "🔢 Total entities found: 158\n",
            "📋 Sections identified: 14\n",
            "\n",
            "📊 Entity Distribution by Section:\n",
            "   Document Start: 3 entities from 1 sentences\n",
            "   IDENTIFICAÇÃO DO MEDICAMENTO: 3 entities from 1 sentences\n",
            "   APRESENTAÇÕES: 4 entities from 1 sentences\n",
            "   COMPOSIÇÃO: 12 entities from 3 sentences\n",
            "   PARA QUE ESTE MEDICAMENTO É INDICADO?: 42 entities from 8 sentences\n",
            "   COMO ESTE MEDICAMENTO FUNCIONA?: 19 entities from 3 sentences\n",
            "   O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO?: 34 entities from 10 sentences\n",
            "   QUE ESTE MEDICAMENTO PODE ME CAUSAR? ”).: 18 entities from 6 sentences\n",
            "   ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAMENTO?: 9 entities from 7 sentences\n",
            "   COMO DEVO USAR ESTE MEDICAMENTO?: 34 entities from 6 sentences\n",
            "   O QUE DEVO FAZER QUANDO EU ME ESQUECER DE USAR ESTE MEDICAMENTO?: 15 entities from 2 sentences\n",
            "   QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?: 41 entities from 9 sentences\n",
            "   MEDICAMENTO?: 12 entities from 4 sentences\n",
            "   VENDA SOB PRESCRIÇÃO MÉDICA: 29 entities from 8 sentences\n",
            "======================================================================\n",
            "\n",
            "📄 Results saved to: bula_1755192077396_section_aware_analysis.json\n",
            "📊 File size: 116,059 bytes\n",
            "\n",
            "🔍 Testing section-aware querying...\n",
            "\n",
            "❓ Qual é o nome do medicamento e sua concentração?\n",
            "💡 O nome do medicamento é Ezetimiba e sua concentração é de 10 mg. Este medicamento é indicado para reduzir a quantidade de colesterol e triglicérides no sangue e reduzir os níveis de esteroides vegetais no sangue. Ele também é usado para tratar doenças cardíacas.\n",
            "\n",
            "A concentração de 10 mg é mencionada no section \"[APRESENTAÇÕES]\". Além disso, o section \"[COMPOSIÇÃO]\" informa que a ezetimiba é um medicamento composto por excipientes e tem uma dose de 10 mg em cada comprimido.\n",
            "\n",
            "É importante notar que a ezetimiba pode causar efeitos colaterais, como bloqueio ao fluxo sanguíneo e aumento do risco de doenças cardíacas. Portanto, é fundamental seguir as instruções do médico e não exceder a dose prescrita.\n",
            "\n",
            "O section \"[COMO ESTE MEDICAMENTO FUNCIONA?]\" informa que a ezetimiba funciona reduzindo a absorção de colesterol no intestino, o que ajuda a reduzir os níveis de colesterol no sangue.\n",
            "\n",
            "O section \"[QUE ESTE MEDICAMENTO PODE ME CAUSAR?\"] menciona que a ezetimiba pode causar erupções cutâneas, urticária e dor abdominal, especialmente quando tomada em conjunto com outros medicamentos. Além disso, o section \"[O QUE DEVO FAZER QUANDO EU ME ESQUECER DE USAR ESTE MEDICAMENTO?]\" informa que é fundamental tomar a dose esquecida assim que se lembrar, e não exceder a dose prescrita.\n",
            "\n",
            "Em resumo, o ezetimiba é um medicamento indicado para reduzir a quantidade de colesterol e triglicérides no sangue e reduzir os níveis de esteroides vegetais no sangue. Ele pode causar efeitos colaterais, como bloqueio ao fluxo sanguíneo e aumento do risco de doenças cardíacas. É fundamental seguir as instruções do médico e não exceder a dose prescrita.\n",
            "--------------------------------------------------\n",
            "\n",
            "❓ Quais são as contraindicações principais?\n",
            "💡 As contraindicações principais para o medicamento Ezetimiba são:\n",
            "\n",
            "* Doenças hepáticas ou problemas hepáticos (segundo a seção \"COMPOSIÇÃO\" e \"QUE ESTE MEDICAMENTO PODE ME CAUSAR?\")\n",
            "* Crianças com menos de 6 anos de idade (segundo a seção \"QUE ESTE MEDICAMENTO PODE ME CAUSAR?\")\n",
            "\n",
            "Além disso, é importante evitar o uso deste medicamento em conjunto com outros medicamentos reduzores de colesterol (segundo a seção \"COMO DEVO USAR ESTE MEDICAMENTO?\" e \"QUE ESTE MEDICAMENTO PODE ME CAUSAR?\").\n",
            "\n",
            "É fundamental consultar um médico antes de iniciar ou continuar o tratamento com Ezetimiba, especialmente se você tem alguma condição de saúde subjacente.\n",
            "--------------------------------------------------\n",
            "\n",
            "❓ Como deve ser administrado?\n",
            "💡 Para administrar o medicamento Ezetimiba, é importante seguir as instruções fornecidas pelo seu médico e as informações disponíveis no rótulo do medicamento.\n",
            "\n",
            "De acordo com a seção \"COMO ESTE MEDICAMENTO FUNCIONA?\" não há informações específicas sobre a administração do medicamento.\n",
            "\n",
            "No entanto, a seção \"O QUE DEVO FAZER QUANDO EU ME ESQUECER DE USAR ESTE MEDICAMENTO?\" fornece algumas orientações importantes:\n",
            "\n",
            "* Tomar o medicamento por via oral, uma vez ao dia antes das refeições.\n",
            "* Não dividir em doses menores.\n",
            "\n",
            "Além disso, a seção \"PARA QUE ESTE MEDICAMENTO É INDICADO?\" informa que o Ezetimiba é indicado para reduzir a quantidade de colesterol e triglicérides no seu sangue, além de reduzir os níveis de esteroides vegetais em seu sangue.\n",
            "\n",
            "É importante lembrar que o Ezetimiba não deve ser administrado com outros medicamentos reduzores de colesterol, como mencionado na seção \"COMO DEVO USAR ESTE MEDICAMENTO?\".\n",
            "\n",
            "Em resumo, é importante seguir as instruções do seu médico e administrar o medicamento conforme indicado, sem dividir em doses menores e evitar a administração com outros medicamentos reduzores de colesterol.\n",
            "--------------------------------------------------\n",
            "\n",
            "❓ Quais são os efeitos adversos mais comuns?\n",
            "💡 Os efeitos adversos mais comuns do medicamento Ezetimiba incluem:\n",
            "\n",
            "* Bloqueio ao fluxo sanguíneo (ver seção \"PARA QUE ESTE MEDICAMENTO É INDICADO?\")\n",
            "* Aumento de risco de doenças cardíacas (ver seção \"PARA QUE ESTE MEDICAMENTO É INDICADO?\")\n",
            "\n",
            "Além disso, é importante notar que o medicamento pode causar efeitos adversos não comuns, como:\n",
            "\n",
            "* Diarreia\n",
            "* Constipação\n",
            "* Náuseas\n",
            "* Vômitos (ver seção \"O QUE DEVO FAZER QUANDO EU ME ESQUECER DE USAR ESTE MEDICAMENTO?\")\n",
            "\n",
            "É fundamental lembrar que esses efeitos adversos podem variar dependendo da dosagem e do período de uso do medicamento. Se você experimenta qualquer um desses sintomas, é importante consultar seu médico imediatamente.\n",
            "\n",
            "Além disso, é importante notar que o Ezetimiba não deve ser usado em pessoas com certas condições de saúde, como doenças hepáticas ou problemas hepáticos (ver seção \"QUE ESTE MEDICAMENTO PODE ME CAUSAR?\").\n",
            "--------------------------------------------------\n",
            "\n",
            "❓ Quem é o fabricante?\n",
            "💡 O fabricante do medicamento Ezetimiba é Sandoz do Brasil Ind. Farm. Ltda., conforme mencionado na seção \"MANUFACTURERS\" (Fabricantes) da documentação do medicamento.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}