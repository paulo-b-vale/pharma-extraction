{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install pymupdf4llm pdfplumber pandas requests -q\n",
        "\n",
        "# Download and install Ollama\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Start the ollama server process in the background\n",
        "# Its output will be redirected to a log file\n",
        "server_process = subprocess.Popen(\n",
        "    [\"ollama\", \"serve\"],\n",
        "    stdout=open(\"ollama_server.log\", \"w\"),\n",
        "    stderr=subprocess.STDOUT\n",
        ")\n",
        "\n",
        "print(\"✅ Ollama server started in the background.\")\n",
        "time.sleep(5) # Give the server a moment to initialize\n",
        "\n",
        "# --- CHANGE MADE HERE ---\n",
        "# Pull the Llama 3 8B model instead of the 3B version.\n",
        "print(\"📥 Pulling the Llama 3 8B model. This may take a few minutes...\")\n",
        "!ollama pull llama3.1:8b\n",
        "print(\"✅ Model download complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbv4W4MoalCa",
        "outputId": "9235a3cc-aa31-4728-bec8-e6f160d6dbfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Cleaning up old version at /usr/local/lib/ollama\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "######################################################################## 100.0%\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n",
            "✅ Ollama server started in the background.\n",
            "📥 Pulling the Llama 3 8B model. This may take a few minutes...\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "✅ Model download complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WG9ivIdaSFl",
        "outputId": "3b1e7835-7c22-4200-f97a-5b7adcd081ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up Ollama model: llama3:8b\n",
            "Ollama CLI found\n",
            "Pulling model llama3:8b...\n",
            "Model llama3:8b ready\n",
            "Graph Database Entity-Relation-Value Extractor\n",
            "============================================================\n",
            "Processing pharmaceutical document: bula_1755192077396.pdf\n",
            "Extracting text from PDF...\n",
            "Extracted 11936 characters\n",
            "Splitting document into sections...\n",
            "Section detected: I) IDENTIFICAÇÃO DO MEDICAMENTO\n",
            "Section detected: APRESENTAÇÕES\n",
            "Section detected: USO ORAL\n",
            "Section detected: USO ADULTO E PEDIÁTRICO ACIMA DE 6 ANOS DE IDADE\n",
            "Section detected: COMPOSIÇÃO\n",
            "Section detected: II) INFORMAÇÕES AO PACIENTE\n",
            "Section detected: 1. PARA QUE ESTE MEDICAMENTO É INDICADO?\n",
            "Section detected: 2. COMO ESTE MEDICAMENTO FUNCIONA?\n",
            "Section detected: 3. QUANDO NÃO DEVO USAR ESTE MEDICAMENTO?\n",
            "Section detected: 4. O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO?\n",
            "Section detected: QUE ESTE MEDICAMENTO PODE ME CAUSAR? ”).\n",
            "Section detected: Interações Medicamentosas: Você deve sempre informar seu médico sobre todos os medicamentos que estiver\n",
            "Section detected: 5. ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAMENTO?\n",
            "Section detected: 6. COMO DEVO USAR ESTE MEDICAMENTO?\n",
            "Section detected: 7. O QUE DEVO FAZER QUANDO EU ME ESQUECER DE USAR ESTE MEDICAMENTO?\n",
            "Section detected: 8. QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAUSAR?\n",
            "Section detected: 9. O QUE FAZER SE ALGUÉM USAR UMA QUANTIDADE MAIOR DO QUE A INDICADA DESTE\n",
            "Section detected: MEDICAMENTO?\n",
            "Section detected: III) DIZERES LEGAIS\n",
            "Section detected: VENDA SOB PRESCRIÇÃO MÉDICA\n",
            "Section detected: RDC 60/12 60/12\n",
            "Section detected: RDC 60/12\n",
            "Section detected: RDC 60/12\n",
            "Section detected: RDC 60/12\n",
            "Section detected: RDC 60/12\n",
            "Found 21 sections\n",
            "Extracting from section: document_start...\n",
            "  Extracted 4 valid triples\n",
            "Extracting from section: I) IDENTIFICAÇÃO DO MEDICAMENTO...\n",
            "  Extracted 1 valid triples\n",
            "Extracting from section: APRESENTAÇÕES...\n",
            "  Extracted 3 valid triples\n",
            "Extracting from section: COMPOSIÇÃO...\n",
            "  Extracted 3 valid triples\n",
            "Extracting from section: 1. PARA QUE ESTE MEDICAMENTO É INDICADO?...\n",
            "  Extracted 6 valid triples\n",
            "Extracting from section: 2. COMO ESTE MEDICAMENTO FUNCIONA?...\n",
            "  Extracted 1 valid triples\n",
            "Extracting from section: 3. QUANDO NÃO DEVO USAR ESTE MEDICAMENTO?...\n",
            "  Extracted 1 valid triples\n",
            "Extracting from section: 4. O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO...\n",
            "  Extracted 4 valid triples\n",
            "Extracting from section: QUE ESTE MEDICAMENTO PODE ME CAUSAR? ”)....\n",
            "  Extracted 4 valid triples\n",
            "Extracting from section: Interações Medicamentosas: Você deve sempre inform...\n",
            "  Extracted 0 valid triples\n",
            "Extracting from section: 5. ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR EST...\n",
            "  Extracted 2 valid triples\n",
            "Extracting from section: 6. COMO DEVO USAR ESTE MEDICAMENTO?...\n",
            "  Extracted 9 valid triples\n",
            "Extracting from section: 7. O QUE DEVO FAZER QUANDO EU ME ESQUECER DE USAR ...\n",
            "  Extracted 4 valid triples\n",
            "Extracting from section: 8. QUAIS OS MALES QUE ESTE MEDICAMENTO PODE ME CAU...\n",
            "  Extracted 7 valid triples\n",
            "Extracting from section: MEDICAMENTO?...\n",
            "  Extracted 3 valid triples\n",
            "Extracting from section: VENDA SOB PRESCRIÇÃO MÉDICA...\n",
            "  Extracted 1 valid triples\n",
            "Extracting from section: RDC 60/12 60/12...\n",
            "  Extracted 1 valid triples\n",
            "Extracting from section: RDC 60/12...\n",
            "  Extracted 1 valid triples\n",
            "Extracting from section: RDC 60/12...\n",
            "  Extracted 0 valid triples\n",
            "Extracting from section: RDC 60/12...\n",
            "  Extracted 0 valid triples\n",
            "Extracting from section: RDC 60/12...\n",
            "  Extracted 2 valid triples\n",
            "Extraction completed: 57 triples, 52 entities, 52 relations\n",
            "Results saved to: bula_1755192077396_graph_data.json\n",
            "File size: 49,400 bytes\n",
            "Neo4j import files created in: neo4j_import\n",
            "\n",
            "EXTRACTION SUMMARY:\n",
            "Total triples: 57\n",
            "Unique entities: 52\n",
            "Unique relations: 52\n",
            "\n",
            "Entity types found:\n",
            "  MEDICATION: 53\n",
            "  ACTIVE_INGREDIENT: 17\n",
            "  MANUFACTURER: 9\n",
            "  PRESENTATION: 3\n",
            "  DOSAGE: 3\n",
            "  INDICATION: 15\n",
            "  SIDE_EFFECT: 7\n",
            "  CONTRAINDICATION: 2\n",
            "  STORAGE_CONDITION: 2\n",
            "  INTERACTION: 2\n",
            "  MECHANISM: 1\n",
            "\n",
            "Relation types found:\n",
            "  CONTAINS: 14\n",
            "  MANUFACTURED_BY: 9\n",
            "  AVAILABLE_AS: 2\n",
            "  HAS_DOSAGE: 3\n",
            "  TREATS: 8\n",
            "  CAUSES: 11\n",
            "  CONTRAINDICATED_FOR: 2\n",
            "  STORED_AS: 3\n",
            "  INTERACTS_WITH: 4\n",
            "  WORKS_BY: 1\n",
            "\n",
            "Files created:\n",
            "  JSON: bula_1755192077396_graph_data.json\n",
            "  Neo4j entities: neo4j_import/entities.csv\n",
            "  Neo4j relations: neo4j_import/relations.csv\n",
            "\n",
            "Sample triples:\n",
            "  1. ezetimiba --CONTAINS--> ACTIVE_INGREDIENT\n",
            "  2. ezetimiba --MANUFACTURED_BY--> Sandoz do Brasil Ind. Farm. Ltda.\n",
            "  3. ezetimiba --AVAILABLE_AS--> comprimido\n",
            "  4. ezetimiba --HAS_DOSAGE--> 10 mg\n",
            "  5. Ezetimiba --CONTAINS--> Active Ingredient\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Graph Database Entity-Relation-Value Extractor for Pharmaceutical Documents\n",
        "Extracts structured data from bula PDFs in a format optimized for graph databases\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import re\n",
        "import subprocess\n",
        "import shlex\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "from datetime import datetime\n",
        "import pymupdf4llm\n",
        "import pdfplumber\n",
        "from dataclasses import dataclass\n",
        "from enum import Enum\n",
        "import uuid\n",
        "\n",
        "@dataclass\n",
        "class GraphTriple:\n",
        "    \"\"\"Represents an entity-relation-value triple for graph database\"\"\"\n",
        "    source_entity: str\n",
        "    source_type: str\n",
        "    relation: str\n",
        "    target_entity: str\n",
        "    target_type: str\n",
        "    properties: Dict[str, Any] = None\n",
        "    confidence: float = 0.8\n",
        "    source_section: str = \"\"\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            'source_entity': self.source_entity,\n",
        "            'source_type': self.source_type,\n",
        "            'relation': self.relation,\n",
        "            'target_entity': self.target_entity,\n",
        "            'target_type': self.target_type,\n",
        "            'properties': self.properties or {},\n",
        "            'confidence': self.confidence,\n",
        "            'source_section': self.source_section\n",
        "        }\n",
        "\n",
        "class GraphEntityExtractor:\n",
        "    def __init__(self, model_name: str = \"llama3:8b\"):\n",
        "        self.model_name = model_name\n",
        "\n",
        "        # Graph schema for pharmaceutical documents\n",
        "        self.entity_types = {\n",
        "            'MEDICATION': 'Main pharmaceutical product',\n",
        "            'ACTIVE_INGREDIENT': 'Chemical compound that provides therapeutic effect',\n",
        "            'MANUFACTURER': 'Company that produces the medication',\n",
        "            'INDICATION': 'Medical condition treated by the medication',\n",
        "            'CONTRAINDICATION': 'Condition where medication should not be used',\n",
        "            'SIDE_EFFECT': 'Unwanted reaction caused by medication',\n",
        "            'DOSAGE': 'Amount and frequency of medication administration',\n",
        "            'INTERACTION': 'Other substances that affect medication behavior',\n",
        "            'STORAGE_CONDITION': 'Requirements for proper medication storage',\n",
        "            'PRESENTATION': 'Physical form and packaging of medication',\n",
        "            'MECHANISM': 'How the medication works in the body',\n",
        "            'PATIENT_GROUP': 'Specific population affected by medication use'\n",
        "        }\n",
        "\n",
        "        # Relation types for pharmaceutical graph\n",
        "        self.relation_types = {\n",
        "            'CONTAINS': 'medication contains active ingredient',\n",
        "            'MANUFACTURED_BY': 'medication is made by company',\n",
        "            'TREATS': 'medication treats condition',\n",
        "            'CONTRAINDICATED_FOR': 'medication should not be used for condition',\n",
        "            'CAUSES': 'medication may cause side effect',\n",
        "            'HAS_DOSAGE': 'medication has specific dosage',\n",
        "            'INTERACTS_WITH': 'medication interacts with substance',\n",
        "            'STORED_AS': 'medication requires storage condition',\n",
        "            'AVAILABLE_AS': 'medication comes in presentation form',\n",
        "            'WORKS_BY': 'medication functions through mechanism',\n",
        "            'AFFECTS': 'medication specifically affects patient group',\n",
        "            'HAS_FREQUENCY': 'side effect occurs with specific frequency'\n",
        "        }\n",
        "\n",
        "        # Section patterns for Brazilian pharmaceutical documents\n",
        "        self.section_patterns = {\n",
        "            r'^\\s*I+\\)\\s*(.+)$': 'primary_section',\n",
        "            r'^\\s*\\d+\\.\\s*(.+)$': 'numbered_section',\n",
        "            r'^\\s*(IDENTIFICAÇÃO|IDENTIFICACAO)': 'identification',\n",
        "            r'^\\s*(INFORMAÇÕES|INFORMACOES).*PACIENTE': 'patient_info',\n",
        "            r'^\\s*(COMPOSIÇÃO|COMPOSICAO)': 'composition',\n",
        "            r'^\\s*(APRESENTAÇÕES|APRESENTACOES)': 'presentations',\n",
        "            r'^\\s*(INDICAÇÕES|INDICACOES)': 'indications',\n",
        "            r'^\\s*(CONTRAINDICAÇÕES|CONTRAINDICACOES)': 'contraindications',\n",
        "            r'^\\s*(PRECAUÇÕES|PRECAUCOES)': 'precautions',\n",
        "            r'^\\s*(REAÇÕES.*ADVERSAS|REACOES.*ADVERSAS|EFEITOS.*ADVERSOS)': 'adverse_effects',\n",
        "            r'^\\s*(INTERAÇÕES|INTERACOES)': 'drug_interactions',\n",
        "            r'^\\s*(POSOLOGIA|DOSAGEM)': 'dosage',\n",
        "            r'^\\s*(SUPERDOSAGEM|SUPERDOSE)': 'overdose',\n",
        "            r'^\\s*ARMAZENAMENTO': 'storage',\n",
        "            r'^\\s*DIZERES.*LEGAIS': 'legal_info'\n",
        "        }\n",
        "\n",
        "        self.setup_ollama()\n",
        "\n",
        "    def setup_ollama(self):\n",
        "        \"\"\"Setup Ollama model\"\"\"\n",
        "        print(f\"Setting up Ollama model: {self.model_name}\")\n",
        "        try:\n",
        "            subprocess.run([\"ollama\", \"--version\"], capture_output=True, check=True)\n",
        "            print(\"Ollama CLI found\")\n",
        "        except (FileNotFoundError, subprocess.CalledProcessError):\n",
        "            raise RuntimeError(\"Ollama CLI not found. Please install Ollama first.\")\n",
        "\n",
        "        try:\n",
        "            print(f\"Pulling model {self.model_name}...\")\n",
        "            result = subprocess.run(\n",
        "                [\"ollama\", \"pull\", self.model_name],\n",
        "                capture_output=True, text=True, timeout=300\n",
        "            )\n",
        "            if result.returncode == 0:\n",
        "                print(f\"Model {self.model_name} ready\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error with model setup: {e}\")\n",
        "\n",
        "    def call_ollama_raw(self, prompt: str) -> str:\n",
        "        \"\"\"Call ollama with exact prompt\"\"\"\n",
        "        cmd = [\"ollama\", \"run\", self.model_name]\n",
        "        try:\n",
        "            proc = subprocess.run(\n",
        "                cmd, input=prompt, text=True, capture_output=True, timeout=120\n",
        "            )\n",
        "            return proc.stdout.strip() or proc.stderr.strip()\n",
        "        except subprocess.TimeoutExpired:\n",
        "            raise RuntimeError(\"Ollama call timed out\")\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error calling ollama: {e}\")\n",
        "\n",
        "    def extract_pdf_content(self, pdf_path: str) -> str:\n",
        "        \"\"\"Extract text content from PDF\"\"\"\n",
        "        try:\n",
        "            with pdfplumber.open(pdf_path) as pdf:\n",
        "                all_text = []\n",
        "                for page in pdf.pages:\n",
        "                    page_text = page.extract_text()\n",
        "                    if page_text:\n",
        "                        all_text.append(page_text)\n",
        "                if all_text:\n",
        "                    return \"\\n\\n\".join(all_text)\n",
        "        except Exception as e:\n",
        "            print(f\"pdfplumber failed: {e}\")\n",
        "\n",
        "        try:\n",
        "            return pymupdf4llm.to_markdown(pdf_path)\n",
        "        except Exception as e:\n",
        "            print(f\"pymupdf4llm failed: {e}\")\n",
        "            raise Exception(\"All extraction methods failed\")\n",
        "\n",
        "    def detect_section(self, text: str) -> Tuple[Optional[str], Optional[str]]:\n",
        "        \"\"\"Detect document section\"\"\"\n",
        "        text_clean = text.strip()\n",
        "        if len(text_clean) < 3:\n",
        "            return None, None\n",
        "\n",
        "        for pattern, section_type in self.section_patterns.items():\n",
        "            if re.match(pattern, text_clean, re.IGNORECASE):\n",
        "                return section_type, text_clean\n",
        "\n",
        "        if (text_clean.isupper() and 5 < len(text_clean) < 100\n",
        "            and not re.search(r'\\d{3,}', text_clean)):\n",
        "            return 'caps_header', text_clean\n",
        "\n",
        "        return None, None\n",
        "\n",
        "    def split_into_sections(self, text: str) -> List[Dict[str, str]]:\n",
        "        \"\"\"Split document into sections with content\"\"\"\n",
        "        lines = text.split('\\n')\n",
        "        sections = []\n",
        "        current_section = 'document_start'\n",
        "        current_content = []\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            section_type, section_title = self.detect_section(line)\n",
        "\n",
        "            if section_type and section_title:\n",
        "                # Save previous section\n",
        "                if current_content:\n",
        "                    sections.append({\n",
        "                        'section': current_section,\n",
        "                        'content': '\\n'.join(current_content)\n",
        "                    })\n",
        "\n",
        "                current_section = section_title\n",
        "                current_content = []\n",
        "                print(f\"Section detected: {section_title}\")\n",
        "            else:\n",
        "                current_content.append(line)\n",
        "\n",
        "        # Add final section\n",
        "        if current_content:\n",
        "            sections.append({\n",
        "                'section': current_section,\n",
        "                'content': '\\n'.join(current_content)\n",
        "            })\n",
        "\n",
        "        return sections\n",
        "\n",
        "    def create_extraction_prompt(self, section_data: Dict[str, str]) -> str:\n",
        "        \"\"\"Create prompt for extracting graph triples from section\"\"\"\n",
        "        section = section_data['section']\n",
        "        content = section_data['content']\n",
        "\n",
        "        entity_types_str = '\\n'.join([f\"- {k}: {v}\" for k, v in self.entity_types.items()])\n",
        "        relation_types_str = '\\n'.join([f\"- {k}: {v}\" for k, v in self.relation_types.items()])\n",
        "\n",
        "        prompt = f\"\"\"Extract pharmaceutical information as graph triples (Entity-Relation-Value) from this Brazilian pharmaceutical document section.\n",
        "\n",
        "SECTION: {section}\n",
        "\n",
        "ENTITY TYPES:\n",
        "{entity_types_str}\n",
        "\n",
        "RELATION TYPES:\n",
        "{relation_types_str}\n",
        "\n",
        "EXTRACTION RULES:\n",
        "1. Extract ONLY information explicitly stated in the text\n",
        "2. Each triple must have: source_entity, relation, target_entity\n",
        "3. Use entity types from the list above\n",
        "4. Use relation types from the list above\n",
        "5. Extract exact values, don't paraphrase\n",
        "6. Include confidence (0.1-1.0) based on clarity\n",
        "\n",
        "RESPOND WITH VALID JSON ONLY:\n",
        "{{\n",
        "  \"triples\": [\n",
        "    {{\n",
        "      \"source_entity\": \"exact_name_from_text\",\n",
        "      \"source_type\": \"ENTITY_TYPE\",\n",
        "      \"relation\": \"RELATION_TYPE\",\n",
        "      \"target_entity\": \"exact_value_from_text\",\n",
        "      \"target_type\": \"ENTITY_TYPE\",\n",
        "      \"confidence\": 0.9,\n",
        "      \"properties\": {{\"frequency\": \"common\", \"severity\": \"mild\"}}\n",
        "    }}\n",
        "  ]\n",
        "}}\n",
        "\n",
        "TEXT TO ANALYZE:\n",
        "{content[:2000]}\n",
        "\n",
        "JSON:\"\"\"\n",
        "\n",
        "        return prompt\n",
        "\n",
        "    def parse_extraction_response(self, response: str) -> List[Dict]:\n",
        "        \"\"\"Parse LLM response into structured triples\"\"\"\n",
        "        if not response or not response.strip():\n",
        "            return []\n",
        "\n",
        "        cleaned = response.strip()\n",
        "\n",
        "        # Remove markdown blocks\n",
        "        if \"```json\" in cleaned:\n",
        "            start = cleaned.find(\"```json\") + 7\n",
        "            end = cleaned.rfind(\"```\")\n",
        "            if start < end:\n",
        "                cleaned = cleaned[start:end].strip()\n",
        "        elif \"```\" in cleaned:\n",
        "            start = cleaned.find(\"```\") + 3\n",
        "            end = cleaned.rfind(\"```\")\n",
        "            if start < end:\n",
        "                cleaned = cleaned[start:end].strip()\n",
        "\n",
        "        # Extract JSON object\n",
        "        json_start = cleaned.find('{')\n",
        "        json_end = cleaned.rfind('}') + 1\n",
        "\n",
        "        if json_start != -1 and json_end > json_start:\n",
        "            cleaned = cleaned[json_start:json_end]\n",
        "\n",
        "        try:\n",
        "            parsed = json.loads(cleaned)\n",
        "            if isinstance(parsed, dict) and 'triples' in parsed:\n",
        "                return parsed['triples']\n",
        "        except json.JSONDecodeError:\n",
        "            pass\n",
        "\n",
        "        return []\n",
        "\n",
        "    def validate_triple(self, triple_dict: Dict) -> Optional[GraphTriple]:\n",
        "        \"\"\"Validate and create GraphTriple from dictionary\"\"\"\n",
        "        try:\n",
        "            required_fields = ['source_entity', 'source_type', 'relation', 'target_entity', 'target_type']\n",
        "\n",
        "            # Check required fields\n",
        "            for field in required_fields:\n",
        "                if field not in triple_dict or not str(triple_dict[field]).strip():\n",
        "                    return None\n",
        "\n",
        "            # Validate entity types\n",
        "            source_type = triple_dict['source_type'].strip().upper()\n",
        "            target_type = triple_dict['target_type'].strip().upper()\n",
        "\n",
        "            if source_type not in self.entity_types:\n",
        "                return None\n",
        "            if target_type not in self.entity_types:\n",
        "                return None\n",
        "\n",
        "            # Validate relation type\n",
        "            relation = triple_dict['relation'].strip().upper()\n",
        "            if relation not in self.relation_types:\n",
        "                return None\n",
        "\n",
        "            # Clean values\n",
        "            source_entity = str(triple_dict['source_entity']).strip()\n",
        "            target_entity = str(triple_dict['target_entity']).strip()\n",
        "\n",
        "            if len(source_entity) < 2 or len(target_entity) < 2:\n",
        "                return None\n",
        "\n",
        "            confidence = float(triple_dict.get('confidence', 0.8))\n",
        "            if not (0.0 <= confidence <= 1.0):\n",
        "                confidence = 0.8\n",
        "\n",
        "            return GraphTriple(\n",
        "                source_entity=source_entity,\n",
        "                source_type=source_type,\n",
        "                relation=relation,\n",
        "                target_entity=target_entity,\n",
        "                target_type=target_type,\n",
        "                properties=triple_dict.get('properties', {}),\n",
        "                confidence=confidence\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error validating triple {triple_dict}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def extract_graph_triples_from_section(self, section_data: Dict[str, str]) -> List[GraphTriple]:\n",
        "        \"\"\"Extract graph triples from a document section\"\"\"\n",
        "        print(f\"Extracting from section: {section_data['section'][:50]}...\")\n",
        "\n",
        "        try:\n",
        "            prompt = self.create_extraction_prompt(section_data)\n",
        "            response = self.call_ollama_raw(prompt)\n",
        "            raw_triples = self.parse_extraction_response(response)\n",
        "\n",
        "            validated_triples = []\n",
        "            for triple_dict in raw_triples:\n",
        "                triple = self.validate_triple(triple_dict)\n",
        "                if triple:\n",
        "                    triple.source_section = section_data['section']\n",
        "                    validated_triples.append(triple)\n",
        "\n",
        "            print(f\"  Extracted {len(validated_triples)} valid triples\")\n",
        "            return validated_triples\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting from section: {e}\")\n",
        "            return []\n",
        "\n",
        "    def process_document(self, pdf_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"Main processing function - extracts all graph data from PDF\"\"\"\n",
        "        print(f\"Processing pharmaceutical document: {pdf_path}\")\n",
        "\n",
        "        if not Path(pdf_path).exists():\n",
        "            raise FileNotFoundError(f\"File not found: {pdf_path}\")\n",
        "\n",
        "        # Extract text content\n",
        "        print(\"Extracting text from PDF...\")\n",
        "        raw_text = self.extract_pdf_content(pdf_path)\n",
        "\n",
        "        if not raw_text:\n",
        "            raise ValueError(\"No text content extracted from PDF\")\n",
        "\n",
        "        print(f\"Extracted {len(raw_text)} characters\")\n",
        "\n",
        "        # Split into sections\n",
        "        print(\"Splitting document into sections...\")\n",
        "        sections = self.split_into_sections(raw_text)\n",
        "        print(f\"Found {len(sections)} sections\")\n",
        "\n",
        "        # Extract triples from each section\n",
        "        all_triples = []\n",
        "        for section_data in sections:\n",
        "            section_triples = self.extract_graph_triples_from_section(section_data)\n",
        "            all_triples.extend(section_triples)\n",
        "\n",
        "        # Generate unique entities and relations\n",
        "        entities = self.generate_entity_list(all_triples)\n",
        "        relations = self.generate_relation_list(all_triples)\n",
        "\n",
        "        # Compile results\n",
        "        result = {\n",
        "            'metadata': {\n",
        "                'file_path': pdf_path,\n",
        "                'file_name': Path(pdf_path).name,\n",
        "                'processing_date': datetime.now().isoformat(),\n",
        "                'total_text_length': len(raw_text),\n",
        "                'sections_processed': len(sections),\n",
        "                'model_used': self.model_name\n",
        "            },\n",
        "            'graph_data': {\n",
        "                'entities': entities,\n",
        "                'relations': relations,\n",
        "                'triples': [triple.to_dict() for triple in all_triples]\n",
        "            },\n",
        "            'statistics': {\n",
        "                'total_triples': len(all_triples),\n",
        "                'unique_entities': len(entities),\n",
        "                'unique_relations': len(relations),\n",
        "                'entity_type_distribution': self.get_entity_type_stats(all_triples),\n",
        "                'relation_type_distribution': self.get_relation_type_stats(all_triples)\n",
        "            }\n",
        "        }\n",
        "\n",
        "        print(f\"Extraction completed: {len(all_triples)} triples, {len(entities)} entities, {len(relations)} relations\")\n",
        "        return result\n",
        "\n",
        "    def generate_entity_list(self, triples: List[GraphTriple]) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Generate unique entity list from triples\"\"\"\n",
        "        entity_dict = {}\n",
        "\n",
        "        for triple in triples:\n",
        "            # Add source entity\n",
        "            if triple.source_entity not in entity_dict:\n",
        "                entity_dict[triple.source_entity] = {\n",
        "                    'id': str(uuid.uuid4()),\n",
        "                    'name': triple.source_entity,\n",
        "                    'type': triple.source_type,\n",
        "                    'mentioned_in_sections': set()\n",
        "                }\n",
        "            entity_dict[triple.source_entity]['mentioned_in_sections'].add(triple.source_section)\n",
        "\n",
        "            # Add target entity\n",
        "            if triple.target_entity not in entity_dict:\n",
        "                entity_dict[triple.target_entity] = {\n",
        "                    'id': str(uuid.uuid4()),\n",
        "                    'name': triple.target_entity,\n",
        "                    'type': triple.target_type,\n",
        "                    'mentioned_in_sections': set()\n",
        "                }\n",
        "            entity_dict[triple.target_entity]['mentioned_in_sections'].add(triple.source_section)\n",
        "\n",
        "        # Convert sets to lists for JSON serialization\n",
        "        entities = []\n",
        "        for entity_data in entity_dict.values():\n",
        "            entity_data['mentioned_in_sections'] = list(entity_data['mentioned_in_sections'])\n",
        "            entities.append(entity_data)\n",
        "\n",
        "        return entities\n",
        "\n",
        "    def generate_relation_list(self, triples: List[GraphTriple]) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Generate unique relation list from triples\"\"\"\n",
        "        relation_dict = {}\n",
        "\n",
        "        for triple in triples:\n",
        "            relation_key = f\"{triple.source_entity}_{triple.relation}_{triple.target_entity}\"\n",
        "\n",
        "            if relation_key not in relation_dict:\n",
        "                relation_dict[relation_key] = {\n",
        "                    'id': str(uuid.uuid4()),\n",
        "                    'source_entity': triple.source_entity,\n",
        "                    'relation_type': triple.relation,\n",
        "                    'target_entity': triple.target_entity,\n",
        "                    'properties': triple.properties,\n",
        "                    'confidence': triple.confidence,\n",
        "                    'source_section': triple.source_section\n",
        "                }\n",
        "\n",
        "        return list(relation_dict.values())\n",
        "\n",
        "    def get_entity_type_stats(self, triples: List[GraphTriple]) -> Dict[str, int]:\n",
        "        \"\"\"Get statistics on entity types\"\"\"\n",
        "        stats = {}\n",
        "        for triple in triples:\n",
        "            stats[triple.source_type] = stats.get(triple.source_type, 0) + 1\n",
        "            stats[triple.target_type] = stats.get(triple.target_type, 0) + 1\n",
        "        return stats\n",
        "\n",
        "    def get_relation_type_stats(self, triples: List[GraphTriple]) -> Dict[str, int]:\n",
        "        \"\"\"Get statistics on relation types\"\"\"\n",
        "        stats = {}\n",
        "        for triple in triples:\n",
        "            stats[triple.relation] = stats.get(triple.relation, 0) + 1\n",
        "        return stats\n",
        "\n",
        "    def save_results(self, results: Dict[str, Any], output_path: Optional[str] = None) -> str:\n",
        "        \"\"\"Save extraction results to JSON file\"\"\"\n",
        "        if not output_path:\n",
        "            file_name = results['metadata']['file_name']\n",
        "            pdf_name = Path(file_name).stem\n",
        "            output_path = f\"{pdf_name}_graph_data.json\"\n",
        "\n",
        "        output_file = Path(output_path)\n",
        "        with open(output_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"Results saved to: {output_file}\")\n",
        "        print(f\"File size: {output_file.stat().st_size:,} bytes\")\n",
        "        return str(output_file)\n",
        "\n",
        "    def export_for_neo4j(self, results: Dict[str, Any], output_dir: str = \"neo4j_import\") -> Dict[str, str]:\n",
        "        \"\"\"Export data in Neo4j import format\"\"\"\n",
        "        output_path = Path(output_dir)\n",
        "        output_path.mkdir(exist_ok=True)\n",
        "\n",
        "        files_created = {}\n",
        "\n",
        "        # Export entities\n",
        "        entities_file = output_path / \"entities.csv\"\n",
        "        with open(entities_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"id,name,type,sections\\n\")\n",
        "            for entity in results['graph_data']['entities']:\n",
        "                sections = '|'.join(entity['mentioned_in_sections'])\n",
        "                f.write(f\"{entity['id']},{entity['name']},{entity['type']},{sections}\\n\")\n",
        "        files_created['entities'] = str(entities_file)\n",
        "\n",
        "        # Export relations\n",
        "        relations_file = output_path / \"relations.csv\"\n",
        "        with open(relations_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"id,source_entity,relation_type,target_entity,confidence,section,properties\\n\")\n",
        "            for relation in results['graph_data']['relations']:\n",
        "                props = json.dumps(relation.get('properties', {}))\n",
        "                f.write(f\"{relation['id']},{relation['source_entity']},{relation['relation_type']},{relation['target_entity']},{relation['confidence']},{relation['source_section']},{props}\\n\")\n",
        "        files_created['relations'] = str(relations_file)\n",
        "\n",
        "        print(f\"Neo4j import files created in: {output_dir}\")\n",
        "        return files_created\n",
        "\n",
        "def main():\n",
        "    \"\"\"Demonstrate graph entity extraction\"\"\"\n",
        "    extractor = GraphEntityExtractor(model_name=\"llama3:8b\")\n",
        "\n",
        "    pdf_path = \"bula_1755192077396.pdf\"  # Update with your PDF path\n",
        "\n",
        "    print(\"Graph Database Entity-Relation-Value Extractor\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    try:\n",
        "        # Process document\n",
        "        results = extractor.process_document(pdf_path)\n",
        "\n",
        "        # Save JSON results\n",
        "        json_file = extractor.save_results(results)\n",
        "\n",
        "        # Export for Neo4j\n",
        "        neo4j_files = extractor.export_for_neo4j(results)\n",
        "\n",
        "        # Show summary\n",
        "        stats = results['statistics']\n",
        "        print(\"\\nEXTRACTION SUMMARY:\")\n",
        "        print(f\"Total triples: {stats['total_triples']}\")\n",
        "        print(f\"Unique entities: {stats['unique_entities']}\")\n",
        "        print(f\"Unique relations: {stats['unique_relations']}\")\n",
        "\n",
        "        print(\"\\nEntity types found:\")\n",
        "        for entity_type, count in stats['entity_type_distribution'].items():\n",
        "            print(f\"  {entity_type}: {count}\")\n",
        "\n",
        "        print(\"\\nRelation types found:\")\n",
        "        for relation_type, count in stats['relation_type_distribution'].items():\n",
        "            print(f\"  {relation_type}: {count}\")\n",
        "\n",
        "        print(f\"\\nFiles created:\")\n",
        "        print(f\"  JSON: {json_file}\")\n",
        "        print(f\"  Neo4j entities: {neo4j_files['entities']}\")\n",
        "        print(f\"  Neo4j relations: {neo4j_files['relations']}\")\n",
        "\n",
        "        # Show sample triples\n",
        "        print(\"\\nSample triples:\")\n",
        "        for i, triple in enumerate(results['graph_data']['triples'][:5]):\n",
        "            print(f\"  {i+1}. {triple['source_entity']} --{triple['relation']}--> {triple['target_entity']}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "LLM-Enhanced Bula Entity-Relation Extractor (Portuguese Optimized)\n",
        "Optimized for small LLMs (8B parameters) processing Brazilian medical texts\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import requests\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Any, Optional, Union\n",
        "from dataclasses import dataclass, field, asdict\n",
        "from datetime import datetime\n",
        "import hashlib\n",
        "import logging\n",
        "import time\n",
        "from enum import Enum\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class ConfidenceLevel(Enum):\n",
        "    \"\"\"Confidence levels for extracted entities\"\"\"\n",
        "    LOW = \"low\"\n",
        "    MEDIUM = \"medium\"\n",
        "    HIGH = \"high\"\n",
        "    VERY_HIGH = \"very_high\"\n",
        "\n",
        "@dataclass\n",
        "class Entity:\n",
        "    \"\"\"Enhanced entity with LLM-derived properties\"\"\"\n",
        "    id: str\n",
        "    type: str\n",
        "    properties: Dict[str, Any]\n",
        "    source_text: str = \"\"\n",
        "    source_section: str = \"\"\n",
        "    confidence: ConfidenceLevel = ConfidenceLevel.MEDIUM\n",
        "    llm_reasoning: str = \"\"\n",
        "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
        "\n",
        "    def to_dict(self) -> Dict[str, Any]:\n",
        "        result = asdict(self)\n",
        "        result['confidence'] = self.confidence.value\n",
        "        return result\n",
        "\n",
        "@dataclass\n",
        "class Relation:\n",
        "    \"\"\"Enhanced relation with LLM-derived reasoning\"\"\"\n",
        "    source_entity_id: str\n",
        "    target_entity_id: str\n",
        "    relation_type: str\n",
        "    properties: Dict[str, Any] = field(default_factory=dict)\n",
        "    confidence: ConfidenceLevel = ConfidenceLevel.MEDIUM\n",
        "    llm_reasoning: str = \"\"\n",
        "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
        "\n",
        "    def to_dict(self) -> Dict[str, Any]:\n",
        "        result = asdict(self)\n",
        "        result['confidence'] = self.confidence.value\n",
        "        return result\n",
        "\n",
        "class LLMClient:\n",
        "    \"\"\"Client for interacting with LLM APIs (Ollama)\"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = \"llama3.1:8b\", base_url: str = \"http://localhost:11434\"):\n",
        "        self.model_name = model_name\n",
        "        self.base_url = base_url\n",
        "        self.session = requests.Session()\n",
        "\n",
        "    def generate(self, prompt: str, max_tokens: int = 800, temperature: float = 0.1) -> str:\n",
        "        \"\"\"Generate response from LLM\"\"\"\n",
        "        try:\n",
        "            response = self.session.post(\n",
        "                f\"{self.base_url}/api/generate\",\n",
        "                json={\n",
        "                    \"model\": self.model_name,\n",
        "                    \"prompt\": prompt,\n",
        "                    \"stream\": False,\n",
        "                    \"options\": {\n",
        "                        \"temperature\": temperature,\n",
        "                        \"num_predict\": max_tokens\n",
        "                    }\n",
        "                },\n",
        "                timeout=60\n",
        "            )\n",
        "            response.raise_for_status()\n",
        "            return response.json()[\"response\"]\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            logger.error(f\"Erro de conexão LLM: {e}\")\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Erro na API LLM: {e}\")\n",
        "            raise\n",
        "\n",
        "class OptimizedBulaExtractor:\n",
        "    \"\"\"Extrator otimizado para LLMs pequenos processando textos médicos brasileiros\"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = \"llama3.1:8b\", base_url: str = \"http://localhost:11434\"):\n",
        "        self.llm = LLMClient(model_name, base_url)\n",
        "        self.entities: Dict[str, Entity] = {}\n",
        "        self.relations: List[Relation] = []\n",
        "        self.medication_entity_id: Optional[str] = None\n",
        "        self.document_metadata = {}\n",
        "        self.processing_stats = {\n",
        "            'frases_processadas': 0,\n",
        "            'chamadas_llm': 0,\n",
        "            'entidades_criadas': 0,\n",
        "            'relacoes_criadas': 0,\n",
        "            'tempo_processamento': 0\n",
        "        }\n",
        "\n",
        "    def generate_entity_id(self, entity_type: str, value: str) -> str:\n",
        "        \"\"\"Generate deterministic entity ID\"\"\"\n",
        "        clean_value = re.sub(r'[^\\w\\s-]', '', value.lower())\n",
        "        clean_value = re.sub(r'\\s+', '_', clean_value.strip())\n",
        "        hash_input = f\"{entity_type}:{value}\".encode('utf-8')\n",
        "        hash_suffix = hashlib.sha256(hash_input).hexdigest()[:8]\n",
        "        return f\"{entity_type.lower()}_{clean_value}_{hash_suffix}\"\n",
        "\n",
        "    def extract_entities_and_relations_from_sentence(self, sentence: str, section: str) -> Dict[str, Any]:\n",
        "        \"\"\"Extrai entidades E relações de uma frase - otimizado para LLM pequeno\"\"\"\n",
        "\n",
        "        # Prompt em português, focado e conciso\n",
        "        prompt = f\"\"\"Você é um especialista em medicamentos brasileiros. Analise esta frase de bula médica e extraia informações importantes:\n",
        "\n",
        "FRASE: \"{sentence}\"\n",
        "SEÇÃO: {section}\n",
        "\n",
        "Extraia apenas informações médicas relevantes e suas relações. Responda APENAS em JSON:\n",
        "\n",
        "{{\n",
        "  \"entidades\": [\n",
        "    {{\"tipo\": \"MEDICAMENTO|DOSAGEM|INDICACAO|CONTRAINDICACAO|EFEITO_ADVERSO|POPULACAO|FABRICANTE\", \"valor\": \"texto exato\", \"confianca\": \"alta|media|baixa\"}}\n",
        "  ],\n",
        "  \"relacoes\": [\n",
        "    {{\"origem\": \"valor_entidade1\", \"destino\": \"valor_entidade2\", \"tipo\": \"TRATA|TEM_DOSE|CONTRAINDICADO_PARA|CAUSA|ADEQUADO_PARA\", \"confianca\": \"alta|media|baixa\"}}\n",
        "  ]\n",
        "}}\n",
        "\n",
        "Regras:\n",
        "- Só extraia termos médicos específicos (nomes de medicamentos, doenças, doses)\n",
        "- Não extraia palavras genéricas como \"tratamento\", \"paciente\"\n",
        "- Seja preciso com dosagens (ex: \"10 mg\", \"uma vez ao dia\")\n",
        "- Crie relações lógicas entre entidades\n",
        "- Máximo 5 entidades e 3 relações por frase\"\"\"\n",
        "\n",
        "        try:\n",
        "            self.processing_stats['chamadas_llm'] += 1\n",
        "            response = self.llm.generate(prompt, max_tokens=600, temperature=0.1)\n",
        "\n",
        "            # Limpa e extrai JSON\n",
        "            json_start = response.find('{')\n",
        "            json_end = response.rfind('}') + 1\n",
        "\n",
        "            if json_start == -1 or json_end == 0:\n",
        "                return {\"entidades\": [], \"relacoes\": []}\n",
        "\n",
        "            json_str = response[json_start:json_end]\n",
        "            result = json.loads(json_str)\n",
        "\n",
        "            return {\n",
        "                \"entidades\": result.get(\"entidades\", []),\n",
        "                \"relacoes\": result.get(\"relacoes\", [])\n",
        "            }\n",
        "\n",
        "        except json.JSONDecodeError as e:\n",
        "            logger.warning(f\"Erro ao parsear JSON do LLM: {e}\")\n",
        "            return {\"entidades\": [], \"relacoes\": []}\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Erro na extração: {e}\")\n",
        "            return {\"entidades\": [], \"relacoes\": []}\n",
        "\n",
        "    def split_into_sentences(self, text: str) -> List[str]:\n",
        "        \"\"\"Divide texto em frases significativas para LLM pequeno\"\"\"\n",
        "        # Limpa o texto\n",
        "        text = re.sub(r'\\s+', ' ', text.strip())\n",
        "\n",
        "        # Divide em frases usando pontuação\n",
        "        sentences = re.split(r'[.!?;]\\s+', text)\n",
        "\n",
        "        # Filtra frases muito curtas ou muito longas\n",
        "        meaningful_sentences = []\n",
        "        for sentence in sentences:\n",
        "            if 20 <= len(sentence) <= 200 and any(keyword in sentence.lower() for keyword in\n",
        "                ['ezetimiba', 'mg', 'dose', 'indicado', 'contraindicado', 'efeito', 'paciente']):\n",
        "                meaningful_sentences.append(sentence.strip())\n",
        "\n",
        "        return meaningful_sentences\n",
        "\n",
        "    def create_entity_from_llm(self, entity_data: Dict, source_text: str, section: str) -> Optional[Entity]:\n",
        "        \"\"\"Cria entidade a partir dos dados do LLM\"\"\"\n",
        "        try:\n",
        "            value = entity_data.get('valor', '').strip()\n",
        "            if not value or len(value) < 3:\n",
        "                return None\n",
        "\n",
        "            # Mapeia tipos em português para inglês\n",
        "            type_mapping = {\n",
        "                'MEDICAMENTO': 'Medication',\n",
        "                'DOSAGEM': 'Dosage',\n",
        "                'INDICACAO': 'Indication',\n",
        "                'CONTRAINDICACAO': 'Contraindication',\n",
        "                'EFEITO_ADVERSO': 'SideEffect',\n",
        "                'POPULACAO': 'PatientPopulation',\n",
        "                'FABRICANTE': 'Manufacturer'\n",
        "            }\n",
        "\n",
        "            entity_type = type_mapping.get(entity_data.get('tipo', ''), 'Unknown')\n",
        "\n",
        "            # Mapeia confiança\n",
        "            confidence_mapping = {\n",
        "                'alta': ConfidenceLevel.HIGH,\n",
        "                'media': ConfidenceLevel.MEDIUM,\n",
        "                'baixa': ConfidenceLevel.LOW\n",
        "            }\n",
        "            confidence = confidence_mapping.get(entity_data.get('confianca', 'media'), ConfidenceLevel.MEDIUM)\n",
        "\n",
        "            entity_id = self.generate_entity_id(entity_type, value)\n",
        "\n",
        "            # Evita duplicatas\n",
        "            if entity_id in self.entities:\n",
        "                return None\n",
        "\n",
        "            return Entity(\n",
        "                id=entity_id,\n",
        "                type=entity_type,\n",
        "                properties={'value': value, 'extraction_method': 'llm_otimizado'},\n",
        "                source_text=source_text[:300],\n",
        "                source_section=section,\n",
        "                confidence=confidence,\n",
        "                llm_reasoning=f\"Extraído de: {section}\",\n",
        "                metadata={'llm_model': self.llm.model_name}\n",
        "            )\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Erro ao criar entidade: {e}\")\n",
        "            return None\n",
        "\n",
        "    def create_relation_from_llm(self, relation_data: Dict, entities_map: Dict[str, str]) -> Optional[Relation]:\n",
        "        \"\"\"Cria relação a partir dos dados do LLM\"\"\"\n",
        "        try:\n",
        "            origem_value = relation_data.get('origem', '').strip()\n",
        "            destino_value = relation_data.get('destino', '').strip()\n",
        "\n",
        "            # Encontra IDs das entidades pelos valores\n",
        "            origem_id = entities_map.get(origem_value)\n",
        "            destino_id = entities_map.get(destino_value)\n",
        "\n",
        "            if not origem_id or not destino_id or origem_id == destino_id:\n",
        "                return None\n",
        "\n",
        "            # Mapeia tipos de relação\n",
        "            relation_mapping = {\n",
        "                'TRATA': 'INDICATED_FOR',\n",
        "                'TEM_DOSE': 'HAS_DOSAGE',\n",
        "                'CONTRAINDICADO_PARA': 'CONTRAINDICATED_FOR',\n",
        "                'CAUSA': 'MAY_CAUSE',\n",
        "                'ADEQUADO_PARA': 'SUITABLE_FOR'\n",
        "            }\n",
        "\n",
        "            relation_type = relation_mapping.get(relation_data.get('tipo', ''), 'RELATED_TO')\n",
        "\n",
        "            confidence_mapping = {\n",
        "                'alta': ConfidenceLevel.HIGH,\n",
        "                'media': ConfidenceLevel.MEDIUM,\n",
        "                'baixa': ConfidenceLevel.LOW\n",
        "            }\n",
        "            confidence = confidence_mapping.get(relation_data.get('confianca', 'media'), ConfidenceLevel.MEDIUM)\n",
        "\n",
        "            return Relation(\n",
        "                source_entity_id=origem_id,\n",
        "                target_entity_id=destino_id,\n",
        "                relation_type=relation_type,\n",
        "                confidence=confidence,\n",
        "                llm_reasoning=f\"Relação identificada pelo LLM\",\n",
        "                metadata={'llm_model': self.llm.model_name}\n",
        "            )\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Erro ao criar relação: {e}\")\n",
        "            return None\n",
        "\n",
        "    def process_bula_json(self, json_file_path: Union[str, Path]) -> Dict[str, Any]:\n",
        "        \"\"\"Processamento principal otimizado\"\"\"\n",
        "        json_path = Path(json_file_path)\n",
        "        logger.info(f\"🚀 Iniciando processamento otimizado: {json_path}\")\n",
        "\n",
        "        start_time = datetime.now()\n",
        "\n",
        "        try:\n",
        "            with open(json_path, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            self.document_metadata = data.get('document_metadata', {})\n",
        "            self.document_metadata['source_file'] = str(json_path)\n",
        "\n",
        "            flat_blocks = data.get('representations', {}).get('flat_blocks', [])\n",
        "            if not flat_blocks:\n",
        "                raise ValueError(\"Nenhum flat_blocks encontrado no JSON\")\n",
        "\n",
        "            # Agrupa blocos por seção\n",
        "            sections = self._group_blocks_by_section(flat_blocks)\n",
        "\n",
        "            # Mapa para encontrar entidades por valor\n",
        "            entities_value_map = {}\n",
        "\n",
        "            print(f\"\\n📊 Processando {len(sections)} seções...\")\n",
        "\n",
        "            # Processa cada seção\n",
        "            for section_name, blocks in tqdm(sections.items(), desc=\"Seções\", unit=\"seção\"):\n",
        "                section_content = self._combine_blocks_content(blocks)\n",
        "\n",
        "                if len(section_content.strip()) < 50:\n",
        "                    continue\n",
        "\n",
        "                # Divide em frases menores\n",
        "                sentences = self.split_into_sentences(section_content)\n",
        "\n",
        "                if not sentences:\n",
        "                    continue\n",
        "\n",
        "                print(f\"  🔍 {section_name}: {len(sentences)} frases\")\n",
        "\n",
        "                # Processa cada frase\n",
        "                for sentence in tqdm(sentences, desc=f\"Processando {section_name}\", leave=False):\n",
        "                    result = self.extract_entities_and_relations_from_sentence(sentence, section_name)\n",
        "\n",
        "                    # Cria entidades\n",
        "                    for entity_data in result.get('entidades', []):\n",
        "                        entity = self.create_entity_from_llm(entity_data, sentence, section_name)\n",
        "                        if entity and entity.id not in self.entities:\n",
        "                            self.entities[entity.id] = entity\n",
        "                            entities_value_map[entity.properties['value']] = entity.id\n",
        "                            self.processing_stats['entidades_criadas'] += 1\n",
        "\n",
        "                    # Cria relações\n",
        "                    for relation_data in result.get('relacoes', []):\n",
        "                        relation = self.create_relation_from_llm(relation_data, entities_value_map)\n",
        "                        if relation:\n",
        "                            self.relations.append(relation)\n",
        "                            self.processing_stats['relacoes_criadas'] += 1\n",
        "\n",
        "                    self.processing_stats['frases_processadas'] += 1\n",
        "                    time.sleep(0.05)  # Evita sobrecarregar a API\n",
        "\n",
        "            # Identifica medicamento principal\n",
        "            self._identify_main_medication()\n",
        "\n",
        "            end_time = datetime.now()\n",
        "            self.processing_stats['tempo_processamento'] = (end_time - start_time).total_seconds()\n",
        "\n",
        "            print(f\"\\n✅ Processamento concluído!\")\n",
        "            print(f\"   📊 {len(self.entities)} entidades | 🔗 {len(self.relations)} relações\")\n",
        "            print(f\"   ⏱️ {self.processing_stats['tempo_processamento']:.2f}s | 📞 {self.processing_stats['chamadas_llm']} chamadas LLM\")\n",
        "\n",
        "            return self._generate_output()\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Erro no processamento: {e}\", exc_info=True)\n",
        "            raise\n",
        "\n",
        "    def _group_blocks_by_section(self, flat_blocks: List[Dict]) -> Dict[str, List[Dict]]:\n",
        "        \"\"\"Agrupa blocos por seção\"\"\"\n",
        "        sections = {}\n",
        "        for block in flat_blocks:\n",
        "            section_title = block.get('context', {}).get('section_title', 'Geral')\n",
        "            sections.setdefault(section_title, []).append(block)\n",
        "        return sections\n",
        "\n",
        "    def _combine_blocks_content(self, blocks: List[Dict]) -> str:\n",
        "        \"\"\"Combina conteúdo dos blocos de uma seção\"\"\"\n",
        "        contents = []\n",
        "        for block in blocks:\n",
        "            content = block.get('content', '').strip()\n",
        "            if len(content) > 20:\n",
        "                contents.append(content)\n",
        "        return ' '.join(contents)\n",
        "\n",
        "    def _identify_main_medication(self):\n",
        "        \"\"\"Identifica o medicamento principal\"\"\"\n",
        "        med_entities = [e for e in self.entities.values() if e.type == 'Medication']\n",
        "\n",
        "        if not med_entities:\n",
        "            logger.warning(\"Nenhuma entidade de medicamento encontrada\")\n",
        "            return\n",
        "\n",
        "        # Prioriza 'ezetimiba'\n",
        "        for entity in med_entities:\n",
        "            if 'ezetimiba' in entity.properties.get('value', '').lower():\n",
        "                self.medication_entity_id = entity.id\n",
        "                logger.info(f\"Medicamento principal: {entity.properties['value']}\")\n",
        "                return\n",
        "\n",
        "        # Fallback para o de maior confiança\n",
        "        confidence_order = {\n",
        "            ConfidenceLevel.LOW: 1,\n",
        "            ConfidenceLevel.MEDIUM: 2,\n",
        "            ConfidenceLevel.HIGH: 3,\n",
        "            ConfidenceLevel.VERY_HIGH: 4\n",
        "        }\n",
        "\n",
        "        main_med = max(med_entities, key=lambda e: confidence_order.get(e.confidence, 0))\n",
        "        self.medication_entity_id = main_med.id\n",
        "        logger.info(f\"Medicamento principal (fallback): {main_med.properties['value']}\")\n",
        "\n",
        "    def _generate_output(self) -> Dict[str, Any]:\n",
        "        \"\"\"Gera saída estruturada para alimentar o banco de grafos\"\"\"\n",
        "\n",
        "        # Organiza entidades por tipo para facilitar consultas\n",
        "        entities_by_type = {}\n",
        "        for entity in self.entities.values():\n",
        "            entities_by_type.setdefault(entity.type, []).append(entity.to_dict())\n",
        "\n",
        "        # Organiza relações por tipo\n",
        "        relations_by_type = {}\n",
        "        for relation in self.relations:\n",
        "            relations_by_type.setdefault(relation.relation_type, []).append(relation.to_dict())\n",
        "\n",
        "        return {\n",
        "            'metadata': {\n",
        "                'data_extracao': datetime.now().isoformat(),\n",
        "                'arquivo_fonte': self.document_metadata.get('source_file', 'desconhecido'),\n",
        "                'total_entidades': len(self.entities),\n",
        "                'total_relacoes': len(self.relations),\n",
        "                'medicamento_principal_id': self.medication_entity_id,\n",
        "                'estatisticas_processamento': self.processing_stats,\n",
        "                'modelo_llm': self.llm.model_name,\n",
        "                'metodo_extracao': 'llm_otimizado_portugues'\n",
        "            },\n",
        "\n",
        "            # Dados estruturados para o grafo\n",
        "            'entidades_por_tipo': entities_by_type,\n",
        "            'relacoes_por_tipo': relations_by_type,\n",
        "\n",
        "            # Dados completos (compatibilidade)\n",
        "            'entidades': [entity.to_dict() for entity in self.entities.values()],\n",
        "            'relacoes': [relation.to_dict() for relation in self.relations],\n",
        "\n",
        "            # Estatísticas úteis\n",
        "            'estatisticas': {\n",
        "                'distribuicao_entidades': {tipo: len(lista) for tipo, lista in entities_by_type.items()},\n",
        "                'distribuicao_relacoes': {tipo: len(lista) for tipo, lista in relations_by_type.items()},\n",
        "                'estatisticas_llm': {\n",
        "                    'total_chamadas_llm': self.processing_stats['chamadas_llm'],\n",
        "                    'tempo_processamento': self.processing_stats['tempo_processamento'],\n",
        "                    'frases_por_segundo': self.processing_stats['frases_processadas'] / max(self.processing_stats['tempo_processamento'], 1)\n",
        "                }\n",
        "            },\n",
        "\n",
        "            # Queries Cypher otimizadas para Neo4j\n",
        "            'queries_neo4j': self._generate_optimized_cypher()\n",
        "        }\n",
        "\n",
        "    def _generate_optimized_cypher(self) -> Dict[str, List[str]]:\n",
        "        \"\"\"Gera queries Cypher otimizadas e organizadas\"\"\"\n",
        "\n",
        "        queries = {\n",
        "            'constraints': [],\n",
        "            'indexes': [],\n",
        "            'entities': [],\n",
        "            'relations': []\n",
        "        }\n",
        "\n",
        "        # Constraints únicos por tipo de entidade\n",
        "        entity_types = {entity.type for entity in self.entities.values()}\n",
        "        for entity_type in entity_types:\n",
        "            queries['constraints'].append(\n",
        "                f\"CREATE CONSTRAINT {entity_type.lower()}_id_unique IF NOT EXISTS FOR (n:{entity_type}) REQUIRE n.id IS UNIQUE;\"\n",
        "            )\n",
        "            queries['indexes'].append(\n",
        "                f\"CREATE INDEX {entity_type.lower()}_value_idx IF NOT EXISTS FOR (n:{entity_type}) ON (n.value);\"\n",
        "            )\n",
        "\n",
        "        # Queries de entidades otimizadas\n",
        "        for entity in self.entities.values():\n",
        "            props = {\n",
        "                'id': entity.id,\n",
        "                'value': entity.properties.get('value', '').replace(\"'\", \"\\\\'\"),\n",
        "                'confidence': entity.confidence.value,\n",
        "                'source_section': entity.source_section.replace(\"'\", \"\\\\'\")\n",
        "            }\n",
        "\n",
        "            props_cypher = ', '.join([f\"{k}: '{v}'\" for k, v in props.items()])\n",
        "\n",
        "            queries['entities'].append(\n",
        "                f\"MERGE (n:{entity.type} {{{props_cypher}}});\"\n",
        "            )\n",
        "\n",
        "        # Queries de relações\n",
        "        for relation in self.relations:\n",
        "            queries['relations'].append(\n",
        "                f\"MATCH (a {{id: '{relation.source_entity_id}'}}), (b {{id: '{relation.target_entity_id}'}}) \"\n",
        "                f\"MERGE (a)-[r:{relation.relation_type} {{confidence: '{relation.confidence.value}'}}]->(b);\"\n",
        "            )\n",
        "\n",
        "        return queries\n",
        "\n",
        "    def save_results(self, output_data: Dict[str, Any], output_path: Optional[str] = None) -> str:\n",
        "        \"\"\"Salva resultados otimizados\"\"\"\n",
        "        if not output_path:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            source_name = Path(self.document_metadata.get('source_file', 'unknown')).stem\n",
        "            output_path = f\"bula_otimizada_{source_name}_{timestamp}.json\"\n",
        "\n",
        "        output_file = Path(output_path)\n",
        "        output_file.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Salva JSON principal\n",
        "        with open(output_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        # Salva queries Cypher organizadas\n",
        "        cypher_queries = output_data['queries_neo4j']\n",
        "        queries_path = output_file.with_suffix('.cypher')\n",
        "\n",
        "        with open(queries_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"-- CONSTRAINTS E ÍNDICES\\n\")\n",
        "            f.write('\\n'.join(cypher_queries['constraints']))\n",
        "            f.write('\\n\\n')\n",
        "            f.write('\\n'.join(cypher_queries['indexes']))\n",
        "\n",
        "            f.write(\"\\n\\n-- ENTIDADES\\n\")\n",
        "            f.write('\\n'.join(cypher_queries['entities']))\n",
        "\n",
        "            f.write(\"\\n\\n-- RELAÇÕES\\n\")\n",
        "            f.write('\\n'.join(cypher_queries['relations']))\n",
        "\n",
        "        logger.info(f\"✅ Resultados salvos em: {output_file.absolute()}\")\n",
        "        return str(output_file)\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Função principal com configurações otimizadas\"\"\"\n",
        "\n",
        "    # 🔧 CONFIGURAÇÕES\n",
        "    json_file_path = \"bula_1755192097944_llm_optimized.json\"\n",
        "    llm_model = \"llama3.1:8b\"\n",
        "    llm_base_url = \"http://localhost:11434\"\n",
        "\n",
        "    json_file = Path(json_file_path)\n",
        "\n",
        "    if not json_file.exists():\n",
        "        print(f\"❌ ERRO: Arquivo não encontrado: {json_file.absolute()}\")\n",
        "        return 1\n",
        "\n",
        "    try:\n",
        "        print(\"🚀 Iniciando extração otimizada para LLM brasileiro...\")\n",
        "        print(f\"📄 Arquivo: {json_file.name}\")\n",
        "        print(f\"🤖 Modelo: {llm_model}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Inicializa extrator otimizado\n",
        "        extractor = OptimizedBulaExtractor(model_name=llm_model, base_url=llm_base_url)\n",
        "\n",
        "        # Processa o arquivo\n",
        "        output_data = extractor.process_bula_json(json_file)\n",
        "\n",
        "        # Salva resultados\n",
        "        result_file = extractor.save_results(output_data)\n",
        "\n",
        "        # Resumo final\n",
        "        stats = output_data['estatisticas']\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"🎉 EXTRAÇÃO CONCLUÍDA COM SUCESSO!\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"📊 Entidades extraídas: {len(output_data['entidades'])}\")\n",
        "        print(f\"🔗 Relações criadas: {len(output_data['relacoes'])}\")\n",
        "        print(f\"📞 Chamadas LLM: {stats['estatisticas_llm']['total_chamadas_llm']}\")\n",
        "        print(f\"⏱️ Tempo total: {stats['estatisticas_llm']['tempo_processamento']:.1f}s\")\n",
        "        print(f\"🔄 Velocidade: {stats['estatisticas_llm']['frases_por_segundo']:.1f} frases/s\")\n",
        "\n",
        "        print(\"\\n📈 DISTRIBUIÇÃO DE ENTIDADES:\")\n",
        "        for tipo, count in stats['distribuicao_entidades'].items():\n",
        "            print(f\"  • {tipo}: {count}\")\n",
        "\n",
        "        if stats['distribuicao_relacoes']:\n",
        "            print(\"\\n🔗 DISTRIBUIÇÃO DE RELAÇÕES:\")\n",
        "            for tipo, count in stats['distribuicao_relacoes'].items():\n",
        "                print(f\"  • {tipo}: {count}\")\n",
        "\n",
        "        print(f\"\\n💾 Arquivos gerados:\")\n",
        "        print(f\"  • JSON: {result_file}\")\n",
        "        print(f\"  • Cypher: {result_file.replace('.json', '.cypher')}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        return 0\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ ERRO CRÍTICO: {e}\")\n",
        "        logger.error(f\"Erro na execução: {e}\", exc_info=True)\n",
        "        return 1\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    exit(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQi57_skgnGO",
        "outputId": "5ef87dac-2c91-4e48-cf9b-fea8869eaed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Iniciando extração otimizada para LLM brasileiro...\n",
            "📄 Arquivo: bula_1755192097944_llm_optimized.json\n",
            "🤖 Modelo: llama3.1:8b\n",
            "============================================================\n",
            "\n",
            "📊 Processando 13 seções...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rSeções:   0%|          | 0/13 [00:00<?, ?seção/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  🔍 INDICAÇÕES: 2 frases\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Processando INDICAÇÕES:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Processando INDICAÇÕES:  50%|█████     | 1/2 [00:10<00:10, 10.15s/it]\u001b[A\n",
            "Processando INDICAÇÕES: 100%|██████████| 2/2 [00:20<00:00, 10.34s/it]\u001b[A\n",
            "Seções:   8%|▊         | 1/13 [00:20<04:07, 20.64s/seção]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  🔍 RESULTADOS DE EFICÁCIA: 22 frases\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Processando RESULTADOS DE EFICÁCIA:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
            "Processando RESULTADOS DE EFICÁCIA:   5%|▍         | 1/22 [00:06<02:23,  6.85s/it]\u001b[A\n",
            "Processando RESULTADOS DE EFICÁCIA:   9%|▉         | 2/22 [00:15<02:36,  7.83s/it]\u001b[A\n",
            "Processando RESULTADOS DE EFICÁCIA:  14%|█▎        | 3/22 [00:27<03:07,  9.87s/it]\u001b[A\n",
            "Processando RESULTADOS DE EFICÁCIA:  18%|█▊        | 4/22 [00:36<02:51,  9.53s/it]\u001b[A\n",
            "Processando RESULTADOS DE EFICÁCIA:  23%|██▎       | 5/22 [00:42<02:20,  8.28s/it]\u001b[A\n",
            "Processando RESULTADOS DE EFICÁCIA:  27%|██▋       | 6/22 [00:52<02:22,  8.88s/it]\u001b[A\n",
            "Processando RESULTADOS DE EFICÁCIA:  32%|███▏      | 7/22 [01:04<02:27,  9.82s/it]\u001b[A\n",
            "Processando RESULTADOS DE EFICÁCIA:  36%|███▋      | 8/22 [01:16<02:26, 10.47s/it]\u001b[A\n",
            "Processando RESULTADOS DE EFICÁCIA:  41%|████      | 9/22 [01:28<02:20, 10.85s/it]\u001b[A\n",
            "Processando RESULTADOS DE EFICÁCIA:  45%|████▌     | 10/22 [01:38<02:06, 10.58s/it]\u001b[A\n",
            "Processando RESULTADOS DE EFICÁCIA:  50%|█████     | 11/22 [01:49<01:58, 10.80s/it]\u001b[A\n",
            "Processando RESULTADOS DE EFICÁCIA:  55%|█████▍    | 12/22 [01:58<01:43, 10.34s/it]\u001b[A\n",
            "Processando RESULTADOS DE EFICÁCIA:  59%|█████▉    | 13/22 [02:12<01:42, 11.38s/it]\u001b[A\n",
            "Processando RESULTADOS DE EFICÁCIA:  64%|██████▎   | 14/22 [02:23<01:30, 11.28s/it]\u001b[A\n",
            "Processando RESULTADOS DE EFICÁCIA:  68%|██████▊   | 15/22 [02:35<01:21, 11.65s/it]\u001b[A\n",
            "Processando RESULTADOS DE EFICÁCIA:  73%|███████▎  | 16/22 [02:48<01:12, 12.06s/it]\u001b[A\n",
            "Processando RESULTADOS DE EFICÁCIA:  77%|███████▋  | 17/22 [02:55<00:52, 10.41s/it]\u001b[A\n",
            "Processando RESULTADOS DE EFICÁCIA:  82%|████████▏ | 18/22 [03:01<00:36,  9.19s/it]\u001b[A\n",
            "Processando RESULTADOS DE EFICÁCIA:  86%|████████▋ | 19/22 [03:15<00:31, 10.52s/it]\u001b[A\n",
            "Processando RESULTADOS DE EFICÁCIA:  91%|█████████ | 20/22 [03:25<00:20, 10.32s/it]\u001b[A\n",
            "Processando RESULTADOS DE EFICÁCIA:  95%|█████████▌| 21/22 [03:37<00:10, 10.77s/it]\u001b[A\n",
            "Processando RESULTADOS DE EFICÁCIA: 100%|██████████| 22/22 [03:45<00:00,  9.94s/it]\u001b[A\n",
            "Seções:  15%|█▌        | 2/13 [04:05<25:50, 140.96s/seção]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  🔍 CARACTERÍSTICAS FARMACOLÓGICAS: 19 frases\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Processando CARACTERÍSTICAS FARMACOLÓGICAS:   0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "Processando CARACTERÍSTICAS FARMACOLÓGICAS:   5%|▌         | 1/19 [00:11<03:35, 11.98s/it]\u001b[A\n",
            "Processando CARACTERÍSTICAS FARMACOLÓGICAS:  11%|█         | 2/19 [00:25<03:35, 12.70s/it]\u001b[A\n",
            "Processando CARACTERÍSTICAS FARMACOLÓGICAS:  16%|█▌        | 3/19 [00:34<02:56, 11.00s/it]\u001b[A\n",
            "Processando CARACTERÍSTICAS FARMACOLÓGICAS:  21%|██        | 4/19 [00:40<02:18,  9.24s/it]\u001b[A\n",
            "Processando CARACTERÍSTICAS FARMACOLÓGICAS:  26%|██▋       | 5/19 [00:47<01:56,  8.34s/it]\u001b[A\n",
            "Processando CARACTERÍSTICAS FARMACOLÓGICAS:  32%|███▏      | 6/19 [00:53<01:39,  7.65s/it]\u001b[A\n",
            "Processando CARACTERÍSTICAS FARMACOLÓGICAS:  37%|███▋      | 7/19 [01:07<01:55,  9.62s/it]\u001b[A\n",
            "Processando CARACTERÍSTICAS FARMACOLÓGICAS:  42%|████▏     | 8/19 [01:17<01:48,  9.89s/it]\u001b[A\n",
            "Processando CARACTERÍSTICAS FARMACOLÓGICAS:  47%|████▋     | 9/19 [01:31<01:51, 11.16s/it]\u001b[A\n",
            "Processando CARACTERÍSTICAS FARMACOLÓGICAS:  53%|█████▎    | 10/19 [01:39<01:31, 10.21s/it]\u001b[A\n",
            "Processando CARACTERÍSTICAS FARMACOLÓGICAS:  58%|█████▊    | 11/19 [01:48<01:17,  9.74s/it]\u001b[A\n",
            "Processando CARACTERÍSTICAS FARMACOLÓGICAS:  63%|██████▎   | 12/19 [01:55<01:01,  8.85s/it]\u001b[A\n",
            "Processando CARACTERÍSTICAS FARMACOLÓGICAS:  68%|██████▊   | 13/19 [02:09<01:02, 10.50s/it]\u001b[A\n",
            "Processando CARACTERÍSTICAS FARMACOLÓGICAS:  74%|███████▎  | 14/19 [02:25<01:00, 12.09s/it]\u001b[A\n",
            "Processando CARACTERÍSTICAS FARMACOLÓGICAS:  79%|███████▉  | 15/19 [02:38<00:49, 12.33s/it]\u001b[A\n",
            "Processando CARACTERÍSTICAS FARMACOLÓGICAS:  84%|████████▍ | 16/19 [02:51<00:37, 12.46s/it]\u001b[A\n",
            "Processando CARACTERÍSTICAS FARMACOLÓGICAS:  89%|████████▉ | 17/19 [03:02<00:24, 12.25s/it]\u001b[A\n",
            "Processando CARACTERÍSTICAS FARMACOLÓGICAS:  95%|█████████▍| 18/19 [03:15<00:12, 12.30s/it]\u001b[A\n",
            "Processando CARACTERÍSTICAS FARMACOLÓGICAS: 100%|██████████| 19/19 [03:26<00:00, 11.85s/it]\u001b[A\n",
            "Seções:  23%|██▎       | 3/13 [07:31<28:27, 170.71s/seção]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  🔍 CONTRAINDICAÇÕES: 1 frases\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Processando CONTRAINDICAÇÕES:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Processando CONTRAINDICAÇÕES: 100%|██████████| 1/1 [00:09<00:00,  9.50s/it]\u001b[A\n",
            "Seções:  31%|███       | 4/13 [07:41<16:03, 107.07s/seção]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  🔍 ADVERTÊNCIAS E PRECAUÇÕES: 35 frases\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:   0%|          | 0/35 [00:00<?, ?it/s]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:   3%|▎         | 1/35 [00:07<04:22,  7.72s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:   6%|▌         | 2/35 [00:14<04:05,  7.44s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:   9%|▊         | 3/35 [00:21<03:40,  6.89s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  11%|█▏        | 4/35 [00:29<03:52,  7.51s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  14%|█▍        | 5/35 [00:36<03:38,  7.29s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  17%|█▋        | 6/35 [00:42<03:16,  6.77s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  20%|██        | 7/35 [00:50<03:26,  7.37s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  23%|██▎       | 8/35 [00:58<03:19,  7.37s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  26%|██▌       | 9/35 [01:06<03:16,  7.55s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  29%|██▊       | 10/35 [01:14<03:17,  7.91s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  31%|███▏      | 11/35 [01:24<03:21,  8.39s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  34%|███▍      | 12/35 [01:33<03:14,  8.45s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  37%|███▋      | 13/35 [01:43<03:21,  9.17s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  40%|████      | 14/35 [01:52<03:09,  9.02s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  43%|████▎     | 15/35 [02:01<02:58,  8.93s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  46%|████▌     | 16/35 [02:09<02:43,  8.62s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  49%|████▊     | 17/35 [02:16<02:26,  8.16s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  51%|█████▏    | 18/35 [02:22<02:11,  7.73s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  54%|█████▍    | 19/35 [02:34<02:21,  8.85s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  57%|█████▋    | 20/35 [02:44<02:18,  9.25s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  60%|██████    | 21/35 [02:51<01:59,  8.55s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  63%|██████▎   | 22/35 [03:05<02:13, 10.23s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  66%|██████▌   | 23/35 [03:12<01:50,  9.20s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  69%|██████▊   | 24/35 [03:20<01:37,  8.86s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  71%|███████▏  | 25/35 [03:27<01:23,  8.37s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  74%|███████▍  | 26/35 [03:37<01:18,  8.68s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  77%|███████▋  | 27/35 [03:45<01:09,  8.63s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  80%|████████  | 28/35 [03:51<00:54,  7.84s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  83%|████████▎ | 29/35 [04:05<00:58,  9.75s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  86%|████████▌ | 30/35 [04:16<00:50, 10.02s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  89%|████████▊ | 31/35 [04:23<00:36,  9.12s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  91%|█████████▏| 32/35 [04:30<00:25,  8.55s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  94%|█████████▍| 33/35 [04:36<00:15,  7.81s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES:  97%|█████████▋| 34/35 [04:48<00:08,  8.86s/it]\u001b[A\n",
            "Processando ADVERTÊNCIAS E PRECAUÇÕES: 100%|██████████| 35/35 [04:58<00:00,  9.40s/it]\u001b[A\n",
            "Seções:  38%|███▊      | 5/13 [12:40<23:29, 176.22s/seção]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  🔍 INTERAÇÕES MEDICAMENTOSAS: 12 frases\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Processando INTERAÇÕES MEDICAMENTOSAS:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
            "Processando INTERAÇÕES MEDICAMENTOSAS:   8%|▊         | 1/12 [00:09<01:49,  9.99s/it]\u001b[A\n",
            "Processando INTERAÇÕES MEDICAMENTOSAS:  17%|█▋        | 2/12 [00:17<01:28,  8.82s/it]\u001b[A\n",
            "Processando INTERAÇÕES MEDICAMENTOSAS:  25%|██▌       | 3/12 [00:26<01:18,  8.71s/it]\u001b[A\n",
            "Processando INTERAÇÕES MEDICAMENTOSAS:  33%|███▎      | 4/12 [00:32<01:01,  7.63s/it]\u001b[A\n",
            "Processando INTERAÇÕES MEDICAMENTOSAS:  42%|████▏     | 5/12 [00:45<01:07,  9.57s/it]\u001b[A\n",
            "Processando INTERAÇÕES MEDICAMENTOSAS:  50%|█████     | 6/12 [01:01<01:09, 11.64s/it]\u001b[A\n",
            "Processando INTERAÇÕES MEDICAMENTOSAS:  58%|█████▊    | 7/12 [01:06<00:47,  9.56s/it]\u001b[A"
          ]
        }
      ]
    }
  ]
}